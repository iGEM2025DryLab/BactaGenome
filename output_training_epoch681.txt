nohup: ignoring input
ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
INFO:__main__:Loaded config from configs/training/phase1_regulondb.yaml
INFO:__main__:Creating RegulonDB datasets...
INFO:bactagenome.data.regulondb_dataset:Enabled AlphaGenome-style augmentation: shift_range=±256bp, reverse_prob=0.5
INFO:bactagenome.data.regulondb_dataset:Loading genome sequence from ./data/raw/EcoliGene/U00096_details(1).fasta
INFO:bactagenome.data.regulondb_dataset:Loaded genome sequence of length 4641652 bp
INFO:bactagenome.data.regulondb_dataset:Loading existing processed RegulonDB data...
INFO:__main__:Loaded config from configs/training/phase1_regulondb.yaml
INFO:__main__:Loaded config from configs/training/phase1_regulondb.yaml
INFO:__main__:Loaded config from configs/training/phase1_regulondb.yaml
INFO:__main__:Creating RegulonDB datasets...
INFO:bactagenome.data.regulondb_dataset:Enabled AlphaGenome-style augmentation: shift_range=±256bp, reverse_prob=0.5
INFO:bactagenome.data.regulondb_dataset:Loading genome sequence from ./data/raw/EcoliGene/U00096_details(1).fasta
INFO:bactagenome.data.regulondb_dataset:Loaded genome sequence of length 4641652 bp
INFO:bactagenome.data.regulondb_dataset:Loading existing processed RegulonDB data...
INFO:__main__:Creating RegulonDB datasets...
INFO:bactagenome.data.regulondb_dataset:Enabled AlphaGenome-style augmentation: shift_range=±256bp, reverse_prob=0.5
INFO:bactagenome.data.regulondb_dataset:Loading genome sequence from ./data/raw/EcoliGene/U00096_details(1).fasta
INFO:bactagenome.data.regulondb_dataset:Loaded genome sequence of length 4641652 bp
INFO:bactagenome.data.regulondb_dataset:Loading existing processed RegulonDB data...
INFO:__main__:Creating RegulonDB datasets...
INFO:bactagenome.data.regulondb_dataset:Enabled AlphaGenome-style augmentation: shift_range=±256bp, reverse_prob=0.5
INFO:bactagenome.data.regulondb_dataset:Loading genome sequence from ./data/raw/EcoliGene/U00096_details(1).fasta
INFO:bactagenome.data.regulondb_dataset:Loaded genome sequence of length 4641652 bp
INFO:bactagenome.data.regulondb_dataset:Loading existing processed RegulonDB data...
INFO:bactagenome.data.regulondb_dataset:Loaded 116 windows and 3 target modalities
INFO:bactagenome.data.regulondb_dataset:Split 'train': 89 windows
INFO:bactagenome.data.regulondb_dataset:Data augmentation disabled
INFO:bactagenome.data.regulondb_dataset:Loading genome sequence from ./data/raw/EcoliGene/U00096_details(1).fasta
INFO:bactagenome.data.regulondb_dataset:Loaded genome sequence of length 4641652 bp
INFO:bactagenome.data.regulondb_dataset:Loading existing processed RegulonDB data...
INFO:bactagenome.data.regulondb_dataset:Loaded 116 windows and 3 target modalities
INFO:bactagenome.data.regulondb_dataset:Split 'train': 89 windows
INFO:bactagenome.data.regulondb_dataset:Data augmentation disabled
INFO:bactagenome.data.regulondb_dataset:Loading genome sequence from ./data/raw/EcoliGene/U00096_details(1).fasta
INFO:bactagenome.data.regulondb_dataset:Loaded genome sequence of length 4641652 bp
INFO:bactagenome.data.regulondb_dataset:Loading existing processed RegulonDB data...
INFO:bactagenome.data.regulondb_dataset:Loaded 116 windows and 3 target modalities
INFO:bactagenome.data.regulondb_dataset:Split 'train': 89 windows
INFO:bactagenome.data.regulondb_dataset:Data augmentation disabled
INFO:bactagenome.data.regulondb_dataset:Loading genome sequence from ./data/raw/EcoliGene/U00096_details(1).fasta
INFO:bactagenome.data.regulondb_dataset:Loaded genome sequence of length 4641652 bp
INFO:bactagenome.data.regulondb_dataset:Loading existing processed RegulonDB data...
INFO:bactagenome.data.regulondb_dataset:Loaded 116 windows and 3 target modalities
INFO:bactagenome.data.regulondb_dataset:Split 'train': 89 windows
INFO:bactagenome.data.regulondb_dataset:Data augmentation disabled
INFO:bactagenome.data.regulondb_dataset:Loading genome sequence from ./data/raw/EcoliGene/U00096_details(1).fasta
INFO:bactagenome.data.regulondb_dataset:Loaded genome sequence of length 4641652 bp
INFO:bactagenome.data.regulondb_dataset:Loading existing processed RegulonDB data...
INFO:bactagenome.data.regulondb_dataset:Loaded 116 windows and 3 target modalities
INFO:bactagenome.data.regulondb_dataset:Split 'val': 27 windows
INFO:__main__:Train dataset: 89 samples
INFO:__main__:Val dataset: 27 samples
INFO:__main__:Creating model...
INFO:bactagenome.data.regulondb_dataset:Loaded 116 windows and 3 target modalities
INFO:bactagenome.data.regulondb_dataset:Split 'val': 27 windows
INFO:__main__:Train dataset: 89 samples
INFO:__main__:Val dataset: 27 samples
INFO:__main__:Creating model...
INFO:bactagenome.data.regulondb_dataset:Loaded 116 windows and 3 target modalities
INFO:bactagenome.data.regulondb_dataset:Split 'val': 27 windows
INFO:__main__:Train dataset: 89 samples
INFO:__main__:Val dataset: 27 samples
INFO:__main__:Creating model...
INFO:bactagenome.data.regulondb_dataset:Loaded 116 windows and 3 target modalities
INFO:bactagenome.data.regulondb_dataset:Split 'val': 27 windows
INFO:__main__:Train dataset: 89 samples
INFO:__main__:Val dataset: 27 samples
INFO:__main__:Creating model...
INFO:__main__:Model created with 274,983,244 parameters
INFO:__main__:Organism E_coli_K12: Standard heads (no target info available)
INFO:__main__:Model created with 274,983,244 parameters
INFO:__main__:Organism E_coli_K12: Standard heads (no target info available)
INFO:__main__:Model created with 274,983,244 parameters
INFO:__main__:Organism E_coli_K12: Standard heads (no target info available)
INFO:__main__:Model created with 274,983,244 parameters
INFO:__main__:Organism E_coli_K12: Standard heads (no target info available)
INFO:__main__:Starting RegulonDB training...
INFO:__main__:Epoch 1/681
Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s]INFO:__main__:Starting RegulonDB training...
INFO:__main__:Epoch 1/681
INFO:__main__:Starting RegulonDB training...
INFO:__main__:Epoch 1/681
INFO:__main__:Starting RegulonDB training...
INFO:__main__:Epoch 1/681
Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 1:   0%|          | 0/11 [00:02<?, ?it/s, loss=20763.5977, avg_loss=20763.5977]Epoch 1:   9%|▉         | 1/11 [00:02<00:26,  2.67s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:   0%|          | 0/11 [00:02<?, ?it/s, loss=20688.9004, avg_loss=20688.9004]Epoch 1:   9%|▉         | 1/11 [00:02<00:26,  2.67s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:   0%|          | 0/11 [00:02<?, ?it/s, loss=20965.0098, avg_loss=20965.0098]Epoch 1:   9%|▉         | 1/11 [00:02<00:26,  2.68s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:   0%|          | 0/11 [00:02<?, ?it/s, loss=20738.9023, avg_loss=20738.9023]Epoch 1:   9%|▉         | 1/11 [00:02<00:26,  2.68s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  18%|█▊        | 2/11 [00:04<00:17,  1.94s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:  18%|█▊        | 2/11 [00:04<00:17,  1.94s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  18%|█▊        | 2/11 [00:04<00:17,  1.94s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:  18%|█▊        | 2/11 [00:04<00:17,  1.95s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:  27%|██▋       | 3/11 [00:05<00:13,  1.71s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  27%|██▋       | 3/11 [00:05<00:13,  1.71s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:  27%|██▋       | 3/11 [00:05<00:13,  1.72s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:  27%|██▋       | 3/11 [00:05<00:13,  1.72s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:  36%|███▋      | 4/11 [00:06<00:11,  1.61s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  36%|███▋      | 4/11 [00:06<00:11,  1.61s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:  36%|███▋      | 4/11 [00:07<00:11,  1.62s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:  36%|███▋      | 4/11 [00:07<00:11,  1.61s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:  45%|████▌     | 5/11 [00:08<00:09,  1.51s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  45%|████▌     | 5/11 [00:08<00:09,  1.51s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:  45%|████▌     | 5/11 [00:08<00:09,  1.52s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:  45%|████▌     | 5/11 [00:08<00:09,  1.51s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:  55%|█████▍    | 6/11 [00:09<00:06,  1.39s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  55%|█████▍    | 6/11 [00:09<00:06,  1.39s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:  55%|█████▍    | 6/11 [00:09<00:06,  1.39s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:  55%|█████▍    | 6/11 [00:09<00:06,  1.39s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:  64%|██████▎   | 7/11 [00:10<00:05,  1.31s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  64%|██████▎   | 7/11 [00:10<00:05,  1.30s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:  64%|██████▎   | 7/11 [00:10<00:05,  1.31s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:  64%|██████▎   | 7/11 [00:10<00:05,  1.31s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:  73%|███████▎  | 8/11 [00:11<00:03,  1.15s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:  73%|███████▎  | 8/11 [00:11<00:03,  1.16s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  73%|███████▎  | 8/11 [00:11<00:03,  1.15s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:  73%|███████▎  | 8/11 [00:11<00:03,  1.16s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:  82%|████████▏ | 9/11 [00:12<00:02,  1.17s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  82%|████████▏ | 9/11 [00:12<00:02,  1.17s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:  82%|████████▏ | 9/11 [00:12<00:02,  1.17s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:  82%|████████▏ | 9/11 [00:12<00:02,  1.17s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:  91%|█████████ | 10/11 [00:14<00:01,  1.26s/it, loss=20763.5977, avg_loss=20763.5977]Epoch 1:  91%|█████████ | 10/11 [00:14<00:01,  1.26s/it, loss=20688.9004, avg_loss=20688.9004]Epoch 1:  91%|█████████ | 10/11 [00:14<00:01,  1.27s/it, loss=20738.9023, avg_loss=20738.9023]Epoch 1:  91%|█████████ | 10/11 [00:14<00:01,  1.27s/it, loss=20965.0098, avg_loss=20965.0098]Epoch 1:  91%|█████████ | 10/11 [00:15<00:01,  1.27s/it, loss=33.8672, avg_loss=2381.6472]    Epoch 1: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.8672, avg_loss=2381.6472]Epoch 1: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=33.8672, avg_loss=2381.6472]
INFO:__main__:=== EPOCH 1 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 2381.647179
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 91.685665
INFO:__main__:   • gene_density: 2277.316418
INFO:__main__:   • operon_membership: 12.645187
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
/home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
Epoch 1:  91%|█████████ | 10/11 [00:15<00:01,  1.26s/it, loss=33.3815, avg_loss=2381.1966]    Epoch 1: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.3815, avg_loss=2381.1966]Epoch 1: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=33.3815, avg_loss=2381.1966]
Epoch 1:  91%|█████████ | 10/11 [00:15<00:01,  1.26s/it, loss=30.5611, avg_loss=2372.7833]    Epoch 1: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=30.5611, avg_loss=2372.7833]Epoch 1: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=30.5611, avg_loss=2372.7833]
INFO:__main__:=== EPOCH 1 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 2381.196648
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 90.832475
INFO:__main__:   • gene_density: 2277.508621
INFO:__main__:   • operon_membership: 12.855476
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 1 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 2372.783339
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 88.176486
INFO:__main__:   • gene_density: 2272.318304
INFO:__main__:   • operon_membership: 12.288441
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
/home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
Epoch 1:  91%|█████████ | 10/11 [00:15<00:01,  1.27s/it, loss=35.5965, avg_loss=2398.9952]    Epoch 1: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.5965, avg_loss=2398.9952]Epoch 1: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=35.5965, avg_loss=2398.9952]
INFO:__main__:=== EPOCH 1 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 2398.995240
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 92.385397
INFO:__main__:   • gene_density: 2293.556742
INFO:__main__:   • operon_membership: 13.053152
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
/home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
INFO:__main__:Epoch 2/681
INFO:__main__:Epoch 2/681
INFO:__main__:Epoch 2/681
INFO:__main__:Epoch 2/681
Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 2:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 2:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0714, avg_loss=34.0714]Epoch 2:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8315, avg_loss=36.8315]Epoch 2:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9982, avg_loss=36.9982]Epoch 2:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.5359, avg_loss=33.5359]Epoch 2:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  82%|████████▏ | 9/11 [00:12<00:02,  1.19s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:  82%|████████▏ | 9/11 [00:12<00:02,  1.19s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:  82%|████████▏ | 9/11 [00:12<00:02,  1.19s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  82%|████████▏ | 9/11 [00:12<00:02,  1.19s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:  91%|█████████ | 10/11 [00:13<00:01,  1.20s/it, loss=36.9982, avg_loss=36.9982]Epoch 2:  91%|█████████ | 10/11 [00:13<00:01,  1.21s/it, loss=36.8315, avg_loss=36.8315]Epoch 2:  91%|█████████ | 10/11 [00:13<00:01,  1.21s/it, loss=34.0714, avg_loss=34.0714]Epoch 2:  91%|█████████ | 10/11 [00:13<00:01,  1.21s/it, loss=33.5359, avg_loss=33.5359]Epoch 2:  91%|█████████ | 10/11 [00:15<00:01,  1.21s/it, loss=36.7231, avg_loss=35.8930]Epoch 2: 100%|██████████| 11/11 [00:15<00:00,  1.33s/it, loss=36.7231, avg_loss=35.8930]Epoch 2: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=36.7231, avg_loss=35.8930]
Epoch 2:  91%|█████████ | 10/11 [00:15<00:01,  1.21s/it, loss=37.5935, avg_loss=35.3321]Epoch 2: 100%|██████████| 11/11 [00:15<00:00,  1.33s/it, loss=37.5935, avg_loss=35.3321]Epoch 2: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=37.5935, avg_loss=35.3321]
INFO:__main__:=== EPOCH 2 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.892960
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.478821
INFO:__main__:   • gene_density: 1.188565
INFO:__main__:   • operon_membership: 12.225573
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 2 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.332116
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.070003
INFO:__main__:   • gene_density: 1.191347
INFO:__main__:   • operon_membership: 12.070766
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 2:  91%|█████████ | 10/11 [00:15<00:01,  1.20s/it, loss=36.7288, avg_loss=35.9593]Epoch 2: 100%|██████████| 11/11 [00:15<00:00,  1.33s/it, loss=36.7288, avg_loss=35.9593]Epoch 2: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=36.7288, avg_loss=35.9593]
INFO:__main__:=== EPOCH 2 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.959326
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.080518
INFO:__main__:   • gene_density: 1.171993
INFO:__main__:   • operon_membership: 10.706815
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 2:  91%|█████████ | 10/11 [00:15<00:01,  1.21s/it, loss=37.2436, avg_loss=35.8533]Epoch 2: 100%|██████████| 11/11 [00:15<00:00,  1.34s/it, loss=37.2436, avg_loss=35.8533]Epoch 2: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=37.2436, avg_loss=35.8533]
INFO:__main__:=== EPOCH 2 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.853313
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.999500
INFO:__main__:   • gene_density: 1.180516
INFO:__main__:   • operon_membership: 11.673298
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 3/681
INFO:__main__:Epoch 3/681
INFO:__main__:Epoch 3/681
INFO:__main__:Epoch 3/681
Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 3:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 3:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.4402, avg_loss=32.4402]Epoch 3:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.9693, avg_loss=38.9693]Epoch 3:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1681, avg_loss=35.1681]Epoch 3:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.9082, avg_loss=32.9082]Epoch 3:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  82%|████████▏ | 9/11 [00:12<00:02,  1.32s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:  82%|████████▏ | 9/11 [00:12<00:02,  1.32s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  82%|████████▏ | 9/11 [00:12<00:02,  1.32s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=35.1681, avg_loss=35.1681]Epoch 3:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=38.9693, avg_loss=38.9693]Epoch 3:  91%|█████████ | 10/11 [00:13<00:01,  1.16s/it, loss=32.9082, avg_loss=32.9082]Epoch 3:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=32.4402, avg_loss=32.4402]Epoch 3:  91%|█████████ | 10/11 [00:15<00:01,  1.17s/it, loss=35.6294, avg_loss=36.2722]Epoch 3: 100%|██████████| 11/11 [00:15<00:00,  1.28s/it, loss=35.6294, avg_loss=36.2722]Epoch 3: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.6294, avg_loss=36.2722]
Epoch 3:  91%|█████████ | 10/11 [00:15<00:01,  1.17s/it, loss=35.7331, avg_loss=34.9688]Epoch 3: 100%|██████████| 11/11 [00:15<00:00,  1.28s/it, loss=35.7331, avg_loss=34.9688]Epoch 3: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.7331, avg_loss=34.9688]
INFO:__main__:=== EPOCH 3 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.272210
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.633945
INFO:__main__:   • gene_density: 1.178267
INFO:__main__:   • operon_membership: 11.459998
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 3 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.968828
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.533307
INFO:__main__:   • gene_density: 1.186967
INFO:__main__:   • operon_membership: 12.248554
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 3:  91%|█████████ | 10/11 [00:15<00:01,  1.17s/it, loss=33.0023, avg_loss=35.6453]Epoch 3: 100%|██████████| 11/11 [00:15<00:00,  1.28s/it, loss=33.0023, avg_loss=35.6453]Epoch 3: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=33.0023, avg_loss=35.6453]
INFO:__main__:=== EPOCH 3 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.645304
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.119826
INFO:__main__:   • gene_density: 1.179273
INFO:__main__:   • operon_membership: 11.346205
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 3:  91%|█████████ | 10/11 [00:15<00:01,  1.16s/it, loss=34.9686, avg_loss=36.0380]Epoch 3: 100%|██████████| 11/11 [00:15<00:00,  1.29s/it, loss=34.9686, avg_loss=36.0380]Epoch 3: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=34.9686, avg_loss=36.0380]
INFO:__main__:=== EPOCH 3 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.037981
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.244505
INFO:__main__:   • gene_density: 1.187086
INFO:__main__:   • operon_membership: 11.606390
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 4/681
INFO:__main__:Epoch 4/681
INFO:__main__:Epoch 4/681
INFO:__main__:Epoch 4/681
Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 4:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 4:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.4439, avg_loss=33.4439]Epoch 4:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8111, avg_loss=35.8111]Epoch 4:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.6095, avg_loss=35.6095]Epoch 4:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.8001, avg_loss=37.8001]Epoch 4:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  91%|█████████ | 10/11 [00:14<00:01,  1.32s/it, loss=33.4439, avg_loss=33.4439]Epoch 4:  91%|█████████ | 10/11 [00:14<00:01,  1.32s/it, loss=35.6095, avg_loss=35.6095]Epoch 4:  91%|█████████ | 10/11 [00:14<00:01,  1.32s/it, loss=35.8111, avg_loss=35.8111]Epoch 4:  91%|█████████ | 10/11 [00:14<00:01,  1.32s/it, loss=37.8001, avg_loss=37.8001]Epoch 4:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=34.4038, avg_loss=35.4570]Epoch 4: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=34.4038, avg_loss=35.4570]Epoch 4: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.4038, avg_loss=35.4570]
INFO:__main__:=== EPOCH 4 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.456990
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.106855
INFO:__main__:   • gene_density: 1.175840
INFO:__main__:   • operon_membership: 12.174294
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 4:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=34.8086, avg_loss=35.1640]Epoch 4: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=34.8086, avg_loss=35.1640]Epoch 4:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=35.2519, avg_loss=36.7996]Epoch 4: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=35.2519, avg_loss=36.7996]Epoch 4: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.8086, avg_loss=35.1640]
Epoch 4: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.2519, avg_loss=36.7996]
Epoch 4:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=40.0430, avg_loss=35.6413]Epoch 4: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=40.0430, avg_loss=35.6413]Epoch 4: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=40.0430, avg_loss=35.6413]
INFO:__main__:=== EPOCH 4 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.163990
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.073909
INFO:__main__:   • gene_density: 1.185133
INFO:__main__:   • operon_membership: 10.904948
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 4 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.799573
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.789159
INFO:__main__:   • gene_density: 1.177083
INFO:__main__:   • operon_membership: 11.833330
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 4 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.641268
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.722028
INFO:__main__:   • gene_density: 1.191288
INFO:__main__:   • operon_membership: 11.727952
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 5/681
INFO:__main__:Epoch 5/681
INFO:__main__:Epoch 5/681
INFO:__main__:Epoch 5/681
Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 5:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 5:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9298, avg_loss=35.9298]Epoch 5:   9%|▉         | 1/11 [00:01<00:16,  1.62s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2293, avg_loss=34.2293]Epoch 5:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.6507, avg_loss=39.6507]Epoch 5:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1670, avg_loss=37.1670]Epoch 5:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.9298, avg_loss=35.9298]Epoch 5:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=39.6507, avg_loss=39.6507]Epoch 5:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=34.2293, avg_loss=34.2293]Epoch 5:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=37.1670, avg_loss=37.1670]Epoch 5:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=37.7929, avg_loss=36.2632]Epoch 5: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.7929, avg_loss=36.2632]Epoch 5: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=37.7929, avg_loss=36.2632]
INFO:__main__:=== EPOCH 5 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.263247
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.822888
INFO:__main__:   • gene_density: 1.178030
INFO:__main__:   • operon_membership: 11.262328
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 5:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=35.3718, avg_loss=35.1060]Epoch 5: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.3718, avg_loss=35.1060]Epoch 5:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=35.8564, avg_loss=36.1064]Epoch 5: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.8564, avg_loss=36.1064]Epoch 5: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=35.3718, avg_loss=35.1060]
Epoch 5: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=35.8564, avg_loss=36.1064]
INFO:__main__:=== EPOCH 5 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.106388
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 5 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 23.003320
INFO:__main__:   • gene_density: 1.175781
INFO:__main__:   • operon_membership: 11.927287
INFO:__main__:🔢 Total Loss: 35.105961
INFO:__main__:👥 Samples processed: 22
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 22.239254
INFO:__main__:   • gene_density: 1.195490
INFO:__main__:   • operon_membership: 11.671217
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 5:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=36.4095, avg_loss=35.7785]Epoch 5: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.4095, avg_loss=35.7785]Epoch 5: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=36.4095, avg_loss=35.7785]
INFO:__main__:=== EPOCH 5 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.778515
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.769133
INFO:__main__:   • gene_density: 1.183357
INFO:__main__:   • operon_membership: 11.826024
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.47it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.45it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.47it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:00,  2.03it/s]Validation:  50%|█████     | 2/4 [00:01<00:00,  2.02it/s]Validation:  50%|█████     | 2/4 [00:01<00:00,  2.03it/s]Validation:  50%|█████     | 2/4 [00:01<00:00,  2.06it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.39it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.37it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.18it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.18it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.18it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.19it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.11it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.11it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.12it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.10it/s]

INFO:__main__:=== EPOCH 5 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 5 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:=== EPOCH 5 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 5 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/best_model_regulondb.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/best_model_regulondb.pt
INFO:__main__:🏆 New best model saved: checkpoints/phase1_regulondb/best_model_regulondb.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/best_model_regulondb.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/best_model_regulondb.pt
INFO:__main__:🏆 New best model saved: checkpoints/phase1_regulondb/best_model_regulondb.pt
INFO:__main__:🏆 New best model saved: checkpoints/phase1_regulondb/best_model_regulondb.pt
INFO:__main__:🏆 New best model saved: checkpoints/phase1_regulondb/best_model_regulondb.pt
INFO:__main__:Epoch 6/681
INFO:__main__:Epoch 6/681
INFO:__main__:Epoch 6/681
INFO:__main__:Epoch 6/681
Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 6:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 6:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8986, avg_loss=36.8986]Epoch 6:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7334, avg_loss=35.7334]Epoch 6:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.7169, avg_loss=31.7169]Epoch 6:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9777, avg_loss=35.9777]Epoch 6:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  64%|██████▎   | 7/11 [00:09<00:05,  1.27s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:  64%|██████▎   | 7/11 [00:09<00:05,  1.27s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:  64%|██████▎   | 7/11 [00:09<00:05,  1.27s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:  64%|██████▎   | 7/11 [00:09<00:05,  1.27s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  73%|███████▎  | 8/11 [00:10<00:03,  1.13s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:  73%|███████▎  | 8/11 [00:10<00:03,  1.13s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:  73%|███████▎  | 8/11 [00:10<00:03,  1.13s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:  82%|████████▏ | 9/11 [00:11<00:02,  1.11s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:  82%|████████▏ | 9/11 [00:11<00:02,  1.11s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:  82%|████████▏ | 9/11 [00:11<00:02,  1.11s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:  82%|████████▏ | 9/11 [00:11<00:02,  1.11s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  91%|█████████ | 10/11 [00:12<00:01,  1.22s/it, loss=31.7169, avg_loss=31.7169]Epoch 6:  91%|█████████ | 10/11 [00:12<00:01,  1.22s/it, loss=36.8986, avg_loss=36.8986]Epoch 6:  91%|█████████ | 10/11 [00:12<00:01,  1.22s/it, loss=35.7334, avg_loss=35.7334]Epoch 6:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=35.9777, avg_loss=35.9777]Epoch 6:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=35.4198, avg_loss=35.7310]Epoch 6: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.4198, avg_loss=35.7310]Epoch 6: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=35.4198, avg_loss=35.7310]
INFO:__main__:=== EPOCH 6 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.730951
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.590052
INFO:__main__:   • gene_density: 1.184482
INFO:__main__:   • operon_membership: 11.956418
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 6:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=34.5068, avg_loss=36.3785]Epoch 6:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=37.5358, avg_loss=35.7807]Epoch 6: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.5068, avg_loss=36.3785]Epoch 6: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=37.5358, avg_loss=35.7807]Epoch 6: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=34.5068, avg_loss=36.3785]
Epoch 6: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=37.5358, avg_loss=35.7807]
INFO:__main__:=== EPOCH 6 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 6 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.378480
INFO:__main__:🔢 Total Loss: 35.780732
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.653848
INFO:__main__:   • gene_expression: 22.965685
INFO:__main__:   • gene_density: 1.169567
INFO:__main__:   • gene_density: 1.190578
INFO:__main__:   • operon_membership: 11.555065
INFO:__main__:   • operon_membership: 11.624470
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 6:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=33.2393, avg_loss=34.8629]Epoch 6: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=33.2393, avg_loss=34.8629]Epoch 6: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=33.2393, avg_loss=34.8629]
INFO:__main__:=== EPOCH 6 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.862854
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.206530
INFO:__main__:   • gene_density: 1.184304
INFO:__main__:   • operon_membership: 11.472020
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 7/681
INFO:__main__:Epoch 7/681
INFO:__main__:Epoch 7/681
INFO:__main__:Epoch 7/681
Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 7:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 7:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1091, avg_loss=37.1091]Epoch 7:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8784, avg_loss=36.8784]Epoch 7:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.0513, avg_loss=39.0513]Epoch 7:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.5908, avg_loss=32.5908]Epoch 7:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  82%|████████▏ | 9/11 [00:12<00:02,  1.20s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:  82%|████████▏ | 9/11 [00:12<00:02,  1.20s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:  82%|████████▏ | 9/11 [00:12<00:02,  1.20s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  82%|████████▏ | 9/11 [00:12<00:02,  1.20s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=37.1091, avg_loss=37.1091]Epoch 7:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=36.8784, avg_loss=36.8784]Epoch 7:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=39.0513, avg_loss=39.0513]Epoch 7:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=32.5908, avg_loss=32.5908]Epoch 7:  91%|█████████ | 10/11 [00:15<00:01,  1.17s/it, loss=35.0217, avg_loss=34.8416]Epoch 7:  91%|█████████ | 10/11 [00:15<00:01,  1.17s/it, loss=35.1573, avg_loss=35.5507]Epoch 7: 100%|██████████| 11/11 [00:15<00:00,  1.31s/it, loss=35.0217, avg_loss=34.8416]Epoch 7: 100%|██████████| 11/11 [00:15<00:00,  1.31s/it, loss=35.1573, avg_loss=35.5507]Epoch 7:  91%|█████████ | 10/11 [00:15<00:01,  1.17s/it, loss=36.4255, avg_loss=36.4310]Epoch 7: 100%|██████████| 11/11 [00:15<00:00,  1.31s/it, loss=36.4255, avg_loss=36.4310]Epoch 7: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.0217, avg_loss=34.8416]Epoch 7: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.1573, avg_loss=35.5507]

Epoch 7: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.4255, avg_loss=36.4310]
INFO:__main__:=== EPOCH 7 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.841584
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.937632
INFO:__main__:   • gene_density: 1.188625
INFO:__main__:   • operon_membership: 11.715329
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 7 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.550726
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.606035
INFO:__main__:   • gene_density: 1.195608
INFO:__main__:=== EPOCH 7 TRAINING LOSSES ===
INFO:__main__:   • operon_membership: 11.749083
INFO:__main__:👥 Samples processed: 22
INFO:__main__:🔢 Total Loss: 36.430990
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.695804
INFO:__main__:   • gene_density: 1.167081
INFO:__main__:   • operon_membership: 11.568105
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 7:  91%|█████████ | 10/11 [00:15<00:01,  1.17s/it, loss=35.5320, avg_loss=36.2733]Epoch 7: 100%|██████████| 11/11 [00:15<00:00,  1.31s/it, loss=35.5320, avg_loss=36.2733]Epoch 7: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.5320, avg_loss=36.2733]
INFO:__main__:=== EPOCH 7 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.273321
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.640688
INFO:__main__:   • gene_density: 1.180635
INFO:__main__:   • operon_membership: 11.451999
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 8/681
INFO:__main__:Epoch 8/681
INFO:__main__:Epoch 8/681
INFO:__main__:Epoch 8/681
Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 8:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 8:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.1586, avg_loss=39.1586]Epoch 8:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.7238, avg_loss=33.7238]Epoch 8:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9859, avg_loss=33.9859]Epoch 8:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.2767, avg_loss=39.2767]Epoch 8:   9%|▉         | 1/11 [00:01<00:17,  1.76s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  82%|████████▏ | 9/11 [00:13<00:02,  1.34s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:  82%|████████▏ | 9/11 [00:13<00:02,  1.34s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:  82%|████████▏ | 9/11 [00:13<00:02,  1.34s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:  82%|████████▏ | 9/11 [00:13<00:02,  1.34s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  91%|█████████ | 10/11 [00:13<00:01,  1.20s/it, loss=39.1586, avg_loss=39.1586]Epoch 8:  91%|█████████ | 10/11 [00:13<00:01,  1.19s/it, loss=33.7238, avg_loss=33.7238]Epoch 8:  91%|█████████ | 10/11 [00:13<00:01,  1.19s/it, loss=39.2767, avg_loss=39.2767]Epoch 8:  91%|█████████ | 10/11 [00:13<00:01,  1.20s/it, loss=33.9859, avg_loss=33.9859]Epoch 8:  91%|█████████ | 10/11 [00:15<00:01,  1.19s/it, loss=36.9603, avg_loss=35.3029]Epoch 8: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=36.9603, avg_loss=35.3029]Epoch 8: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=36.9603, avg_loss=35.3029]
INFO:__main__:=== EPOCH 8 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.302895
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.728922
INFO:__main__:   • gene_density: 1.176906
INFO:__main__:   • operon_membership: 11.397067
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 8:  91%|█████████ | 10/11 [00:15<00:01,  1.20s/it, loss=37.4357, avg_loss=36.0165]Epoch 8: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=37.4357, avg_loss=36.0165]Epoch 8: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=37.4357, avg_loss=36.0165]
INFO:__main__:=== EPOCH 8 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.016500
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.801275
INFO:__main__:   • gene_density: 1.181404
INFO:__main__:   • operon_membership: 12.033821
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 8:  91%|█████████ | 10/11 [00:15<00:01,  1.20s/it, loss=34.1172, avg_loss=35.8032]Epoch 8: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=34.1172, avg_loss=35.8032]Epoch 8: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.1172, avg_loss=35.8032]
INFO:__main__:=== EPOCH 8 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.803227
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.032264
INFO:__main__:   • gene_density: 1.191761
INFO:__main__:   • operon_membership: 11.579202
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 8:  91%|█████████ | 10/11 [00:15<00:01,  1.19s/it, loss=34.9178, avg_loss=36.0510]Epoch 8: 100%|██████████| 11/11 [00:15<00:00,  1.26s/it, loss=34.9178, avg_loss=36.0510]Epoch 8: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.9178, avg_loss=36.0510]
INFO:__main__:=== EPOCH 8 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.051031
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.190619
INFO:__main__:   • gene_density: 1.179392
INFO:__main__:   • operon_membership: 11.681020
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 9/681
INFO:__main__:Epoch 9/681
INFO:__main__:Epoch 9/681
INFO:__main__:Epoch 9/681
Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 9:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 9:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9992, avg_loss=36.9992]Epoch 9:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5307, avg_loss=37.5307]Epoch 9:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9221, avg_loss=35.9221]Epoch 9:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.8716, avg_loss=38.8716]Epoch 9:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  73%|███████▎  | 8/11 [00:12<00:04,  1.48s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:  73%|███████▎  | 8/11 [00:12<00:04,  1.48s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:  73%|███████▎  | 8/11 [00:12<00:04,  1.48s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:  73%|███████▎  | 8/11 [00:12<00:04,  1.48s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  82%|████████▏ | 9/11 [00:13<00:02,  1.41s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:  82%|████████▏ | 9/11 [00:13<00:02,  1.41s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:  82%|████████▏ | 9/11 [00:13<00:02,  1.41s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:  82%|████████▏ | 9/11 [00:13<00:02,  1.41s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=35.9221, avg_loss=35.9221]Epoch 9:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=36.9992, avg_loss=36.9992]Epoch 9:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=37.5307, avg_loss=37.5307]Epoch 9:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=38.8716, avg_loss=38.8716]Epoch 9:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=33.9557, avg_loss=35.4105]Epoch 9:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=37.2006, avg_loss=35.2123]Epoch 9: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=33.9557, avg_loss=35.4105]Epoch 9: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=37.2006, avg_loss=35.2123]Epoch 9: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=33.9557, avg_loss=35.4105]Epoch 9: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=37.2006, avg_loss=35.2123]

INFO:__main__:=== EPOCH 9 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 9 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.410548
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.212335
INFO:__main__:   • gene_expression: 22.459807
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.178030
INFO:__main__:   • gene_expression: 22.278927
INFO:__main__:   • operon_membership: 11.772711
INFO:__main__:   • gene_density: 1.197088
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.736321
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 9:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=35.3452, avg_loss=36.4869]Epoch 9: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=35.3452, avg_loss=36.4869]Epoch 9:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=33.2355, avg_loss=35.9996]Epoch 9: 100%|██████████| 11/11 [00:15<00:00,  1.24s/it, loss=33.2355, avg_loss=35.9996]Epoch 9: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.3452, avg_loss=36.4869]
Epoch 9: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=33.2355, avg_loss=35.9996]
INFO:__main__:=== EPOCH 9 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.486881
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.175134
INFO:__main__:   • gene_density: 1.172230
INFO:__main__:   • operon_membership: 11.139517
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 9 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.999578
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.845400
INFO:__main__:   • gene_density: 1.185369
INFO:__main__:   • operon_membership: 11.968809
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 10/681
INFO:__main__:Epoch 10/681
INFO:__main__:Epoch 10/681
INFO:__main__:Epoch 10/681
Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 10:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 10:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1097, avg_loss=35.1097]Epoch 10:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.1886, avg_loss=39.1886]Epoch 10:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6961, avg_loss=36.6961]Epoch 10:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1460, avg_loss=35.1460]Epoch 10:   9%|▉         | 1/11 [00:01<00:14,  1.48s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:  36%|███▋      | 4/11 [00:05<00:10,  1.43s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=36.6961, avg_loss=36.6961]Epoch 10:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=35.1097, avg_loss=35.1097]Epoch 10:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=39.1886, avg_loss=39.1886]Epoch 10:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=35.1460, avg_loss=35.1460]Epoch 10:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=33.4389, avg_loss=36.2445]Epoch 10: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.4389, avg_loss=36.2445]Epoch 10:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=35.0100, avg_loss=35.3692]Epoch 10: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=35.0100, avg_loss=35.3692]Epoch 10: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=33.4389, avg_loss=36.2445]
Epoch 10: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.0100, avg_loss=35.3692]
INFO:__main__:=== EPOCH 10 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.244456
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.793633
INFO:__main__:=== EPOCH 10 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.195431
INFO:__main__:   • operon_membership: 11.255392
INFO:__main__:🔢 Total Loss: 35.369206
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.432455
INFO:__main__:   • gene_density: 1.189749
INFO:__main__:   • operon_membership: 11.747002
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 10:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=33.1164, avg_loss=35.8331]Epoch 10: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.1164, avg_loss=35.8331]Epoch 10: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=33.1164, avg_loss=35.8331]
INFO:__main__:=== EPOCH 10 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.833114
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.141852
INFO:__main__:   • gene_density: 1.173651
INFO:__main__:   • operon_membership: 11.517612
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 10:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=37.1046, avg_loss=35.7006]Epoch 10: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.1046, avg_loss=35.7006]Epoch 10: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=37.1046, avg_loss=35.7006]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 10 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.700623
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.606599
INFO:__main__:   • gene_density: 1.173118
INFO:__main__:   • operon_membership: 11.920906
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.42it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.42it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.44it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.42it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.83it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.83it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.84it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.85it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.24it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.26it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.24it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.25it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.16it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.16it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.04it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.04it/s]

Validation: 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]
INFO:__main__:=== EPOCH 10 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 10 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:=== EPOCH 10 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:=== EPOCH 10 VALIDATION LOSSES ===
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_10.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_10.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_10.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_10.pt
INFO:__main__:Epoch 11/681
INFO:__main__:Epoch 11/681
INFO:__main__:Epoch 11/681
INFO:__main__:Epoch 11/681
Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 11:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 11:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1562, avg_loss=38.1562]Epoch 11:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.0862, avg_loss=37.0862]Epoch 11:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.0530, avg_loss=39.0530]Epoch 11:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0757, avg_loss=33.0757]Epoch 11:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:  18%|█▊        | 2/11 [00:03<00:14,  1.61s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:  73%|███████▎  | 8/11 [00:10<00:03,  1.17s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=37.0862, avg_loss=37.0862]Epoch 11:  91%|█████████ | 10/11 [00:13<00:01,  1.32s/it, loss=38.1562, avg_loss=38.1562]Epoch 11:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=39.0530, avg_loss=39.0530]Epoch 11:  91%|█████████ | 10/11 [00:13<00:01,  1.32s/it, loss=33.0757, avg_loss=33.0757]Epoch 11:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=31.3561, avg_loss=35.9543]Epoch 11: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=31.3561, avg_loss=35.9543]Epoch 11:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=37.0802, avg_loss=36.0658]Epoch 11:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=38.2281, avg_loss=35.7293]Epoch 11: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.0802, avg_loss=36.0658]Epoch 11: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=38.2281, avg_loss=35.7293]Epoch 11: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=31.3561, avg_loss=35.9543]
Epoch 11: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.0802, avg_loss=36.0658]
Epoch 11: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=38.2281, avg_loss=35.7293]
INFO:__main__:=== EPOCH 11 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.954347
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.959100
INFO:__main__:   • gene_density: 1.178563
INFO:__main__:   • operon_membership: 11.816684
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 11 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 11 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.065769
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.729329
INFO:__main__:   • gene_expression: 23.674855
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.185784
INFO:__main__:   • gene_expression: 22.216199
INFO:__main__:   • operon_membership: 11.205130
INFO:__main__:   • gene_density: 1.183890
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 12.329241
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 11:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=36.0887, avg_loss=35.4805]Epoch 11: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=36.0887, avg_loss=35.4805]Epoch 11: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.0887, avg_loss=35.4805]
INFO:__main__:=== EPOCH 11 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.480496
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.968347
INFO:__main__:   • gene_density: 1.183239
INFO:__main__:   • operon_membership: 11.328911
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 12/681
INFO:__main__:Epoch 12/681
INFO:__main__:Epoch 12/681
INFO:__main__:Epoch 12/681
Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 12:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 12:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.6507, avg_loss=39.6507]Epoch 12:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5310, avg_loss=34.5310]Epoch 12:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.4420, avg_loss=32.4420]Epoch 12:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8359, avg_loss=35.8359]Epoch 12:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  73%|███████▎  | 8/11 [00:10<00:03,  1.22s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:  73%|███████▎  | 8/11 [00:10<00:03,  1.23s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:  73%|███████▎  | 8/11 [00:10<00:03,  1.23s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:  73%|███████▎  | 8/11 [00:10<00:03,  1.22s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=34.5310, avg_loss=34.5310]Epoch 12:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=39.6507, avg_loss=39.6507]Epoch 12:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=32.4420, avg_loss=32.4420]Epoch 12:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=35.8359, avg_loss=35.8359]Epoch 12:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=37.8448, avg_loss=35.8402]Epoch 12:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=33.2731, avg_loss=35.6281]Epoch 12:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=37.3689, avg_loss=36.0610]Epoch 12: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=37.8448, avg_loss=35.8402]Epoch 12: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=33.2731, avg_loss=35.6281]Epoch 12: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=37.3689, avg_loss=36.0610]Epoch 12: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.3689, avg_loss=36.0610]Epoch 12: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=33.2731, avg_loss=35.6281]Epoch 12: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.8448, avg_loss=35.8402]


INFO:__main__:=== EPOCH 12 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 12 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 12 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.840197
INFO:__main__:🔢 Total Loss: 36.060986
INFO:__main__:🔢 Total Loss: 35.628073
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.086973
INFO:__main__:   • gene_expression: 23.545931
INFO:__main__:   • gene_expression: 22.483839
INFO:__main__:   • gene_density: 1.183594
INFO:__main__:   • gene_density: 1.190814
INFO:__main__:   • gene_density: 1.183239
INFO:__main__:   • operon_membership: 11.569630
INFO:__main__:   • operon_membership: 11.324241
INFO:__main__:   • operon_membership: 11.960995
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 12:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=33.1435, avg_loss=35.8139]Epoch 12: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=33.1435, avg_loss=35.8139]Epoch 12: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=33.1435, avg_loss=35.8139]
INFO:__main__:=== EPOCH 12 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.813912
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.848415
INFO:__main__:   • gene_density: 1.176787
INFO:__main__:   • operon_membership: 11.788710
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 13/681
INFO:__main__:Epoch 13/681
INFO:__main__:Epoch 13/681
INFO:__main__:Epoch 13/681
Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 13:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 13:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4222, avg_loss=35.4222]Epoch 13:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6471, avg_loss=33.6471]Epoch 13:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.3943, avg_loss=36.3943]Epoch 13:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:   0%|          | 0/11 [00:01<?, ?it/s, loss=41.1626, avg_loss=41.1626]Epoch 13:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  82%|████████▏ | 9/11 [00:12<00:02,  1.29s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:  82%|████████▏ | 9/11 [00:12<00:02,  1.29s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:  82%|████████▏ | 9/11 [00:12<00:02,  1.28s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  82%|████████▏ | 9/11 [00:12<00:02,  1.29s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=33.6471, avg_loss=33.6471]Epoch 13:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=36.3943, avg_loss=36.3943]Epoch 13:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=41.1626, avg_loss=41.1626]Epoch 13:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=35.4222, avg_loss=35.4222]Epoch 13:  91%|█████████ | 10/11 [00:15<00:01,  1.15s/it, loss=34.4320, avg_loss=36.0381]Epoch 13: 100%|██████████| 11/11 [00:15<00:00,  1.29s/it, loss=34.4320, avg_loss=36.0381]Epoch 13: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.4320, avg_loss=36.0381]
INFO:__main__:=== EPOCH 13 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.038144
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.446877
INFO:__main__:   • gene_density: 1.172467
INFO:__main__:   • operon_membership: 11.418799
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 13:  91%|█████████ | 10/11 [00:15<00:01,  1.15s/it, loss=36.8337, avg_loss=36.1201]Epoch 13: 100%|██████████| 11/11 [00:15<00:00,  1.29s/it, loss=36.8337, avg_loss=36.1201]Epoch 13:  91%|█████████ | 10/11 [00:15<00:01,  1.15s/it, loss=33.9955, avg_loss=35.0248]Epoch 13: 100%|██████████| 11/11 [00:15<00:00,  1.29s/it, loss=33.9955, avg_loss=35.0248]Epoch 13: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.8337, avg_loss=36.1201]
Epoch 13: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.9955, avg_loss=35.0248]
INFO:__main__:=== EPOCH 13 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.120131
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.970129
INFO:__main__:   • gene_density: 1.200521
INFO:__main__:   • operon_membership: 11.949482
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 13 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.024777
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.719847
INFO:__main__:   • gene_density: 1.178267
INFO:__main__:   • operon_membership: 11.126663
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 13:  91%|█████████ | 10/11 [00:15<00:01,  1.15s/it, loss=36.3914, avg_loss=35.7612]Epoch 13: 100%|██████████| 11/11 [00:15<00:00,  1.29s/it, loss=36.3914, avg_loss=35.7612]Epoch 13: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.3914, avg_loss=35.7612]
INFO:__main__:=== EPOCH 13 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.761168
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.567253
INFO:__main__:   • gene_density: 1.177202
INFO:__main__:   • operon_membership: 12.016713
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 14/681
INFO:__main__:Epoch 14/681
INFO:__main__:Epoch 14/681
INFO:__main__:Epoch 14/681
Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 14:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 14:   0%|          | 0/11 [00:01<?, ?it/s, loss=41.0881, avg_loss=41.0881]Epoch 14:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.5883, avg_loss=38.5883]Epoch 14:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4080, avg_loss=34.4080]Epoch 14:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9457, avg_loss=35.9457]Epoch 14:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:  82%|████████▏ | 9/11 [00:12<00:02,  1.18s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:  82%|████████▏ | 9/11 [00:12<00:02,  1.18s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:  82%|████████▏ | 9/11 [00:12<00:02,  1.18s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:  82%|████████▏ | 9/11 [00:12<00:02,  1.18s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  91%|█████████ | 10/11 [00:13<00:01,  1.07s/it, loss=41.0881, avg_loss=41.0881]Epoch 14:  91%|█████████ | 10/11 [00:13<00:01,  1.07s/it, loss=34.4080, avg_loss=34.4080]Epoch 14:  91%|█████████ | 10/11 [00:13<00:01,  1.07s/it, loss=35.9457, avg_loss=35.9457]Epoch 14:  91%|█████████ | 10/11 [00:13<00:01,  1.07s/it, loss=38.5883, avg_loss=38.5883]Epoch 14:  91%|█████████ | 10/11 [00:14<00:01,  1.07s/it, loss=35.2307, avg_loss=36.2318]Epoch 14:  91%|█████████ | 10/11 [00:14<00:01,  1.07s/it, loss=34.0960, avg_loss=35.1695]Epoch 14: 100%|██████████| 11/11 [00:14<00:00,  1.04s/it, loss=35.2307, avg_loss=36.2318]Epoch 14: 100%|██████████| 11/11 [00:14<00:00,  1.04s/it, loss=34.0960, avg_loss=35.1695]Epoch 14:  91%|█████████ | 10/11 [00:14<00:01,  1.07s/it, loss=34.1811, avg_loss=35.5447]Epoch 14: 100%|██████████| 11/11 [00:14<00:00,  1.04s/it, loss=34.1811, avg_loss=35.5447]Epoch 14: 100%|██████████| 11/11 [00:14<00:00,  1.29s/it, loss=35.2307, avg_loss=36.2318]
Epoch 14: 100%|██████████| 11/11 [00:14<00:00,  1.29s/it, loss=34.0960, avg_loss=35.1695]
Epoch 14: 100%|██████████| 11/11 [00:14<00:00,  1.29s/it, loss=34.1811, avg_loss=35.5447]
Epoch 14:  91%|█████████ | 10/11 [00:14<00:01,  1.07s/it, loss=35.1959, avg_loss=36.2014]Epoch 14: 100%|██████████| 11/11 [00:14<00:00,  1.04s/it, loss=35.1959, avg_loss=36.2014]INFO:__main__:=== EPOCH 14 TRAINING LOSSES ===
Epoch 14: 100%|██████████| 11/11 [00:14<00:00,  1.29s/it, loss=35.1959, avg_loss=36.2014]INFO:__main__:=== EPOCH 14 TRAINING LOSSES ===

INFO:__main__:🔢 Total Loss: 36.231763
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.169514
INFO:__main__:   • gene_expression: 23.974162
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.167791
INFO:__main__:   • gene_expression: 22.363175
INFO:__main__:   • operon_membership: 11.089811
INFO:__main__:   • gene_density: 1.189867
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.616470
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 14 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.544678
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.615559
INFO:__main__:   • gene_density: 1.187204
INFO:__main__:   • operon_membership: 11.741916
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 14 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.201445
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.021644
INFO:__main__:   • gene_density: 1.187086
INFO:__main__:   • operon_membership: 11.992715
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 15/681
INFO:__main__:Epoch 15/681
INFO:__main__:Epoch 15/681
INFO:__main__:Epoch 15/681
Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 15:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 15:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=38.5039, avg_loss=38.5039]Epoch 15:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=36.0570, avg_loss=36.0570]Epoch 15:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:   9%|▉         | 1/11 [00:01<00:10,  1.10s/it, loss=35.3005, avg_loss=35.3005]Epoch 15:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:   9%|▉         | 1/11 [00:01<00:10,  1.10s/it, loss=35.5301, avg_loss=35.5301]Epoch 15:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=35.5301, avg_loss=35.5301]Epoch 15:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=36.0570, avg_loss=36.0570]Epoch 15:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=35.3005, avg_loss=35.3005]Epoch 15:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=38.5039, avg_loss=38.5039]Epoch 15:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=34.8122, avg_loss=35.6716]Epoch 15:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=37.0882, avg_loss=36.7324]Epoch 15:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=36.0324, avg_loss=35.3114]Epoch 15: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=34.8122, avg_loss=35.6716]Epoch 15:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=35.9774, avg_loss=35.1999]Epoch 15: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=37.0882, avg_loss=36.7324]Epoch 15: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=36.0324, avg_loss=35.3114]Epoch 15: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=35.9774, avg_loss=35.1999]Epoch 15: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=34.8122, avg_loss=35.6716]
Epoch 15: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=37.0882, avg_loss=36.7324]
Epoch 15: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=36.0324, avg_loss=35.3114]
Epoch 15: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=35.9774, avg_loss=35.1999]
INFO:__main__:=== EPOCH 15 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 15 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.671559
INFO:__main__:=== EPOCH 15 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 15 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.311397
INFO:__main__:🔢 Total Loss: 36.732434
INFO:__main__:   • gene_expression: 23.025420
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.199866
INFO:__main__:   • gene_density: 1.173887
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.287517
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • operon_membership: 11.472252
INFO:__main__:   • gene_expression: 23.886776
INFO:__main__:   • gene_density: 1.196792
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_expression: 22.205494
INFO:__main__:   • gene_density: 1.183179
INFO:__main__:   • operon_membership: 11.827088
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.179214
INFO:__main__:   • operon_membership: 11.662478
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.815158
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.76it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.76it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.76it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.76it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.35it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.35it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.35it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.35it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.39it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.39it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.39it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.39it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.36it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.36it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.36it/s]
INFO:__main__:=== EPOCH 15 VALIDATION LOSSES ===
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.36it/s]INFO:__main__:=== EPOCH 15 VALIDATION LOSSES ===

INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:=== EPOCH 15 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:=== EPOCH 15 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 16/681
INFO:__main__:Epoch 16/681
INFO:__main__:Epoch 16/681
INFO:__main__:Epoch 16/681
Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 16:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 16:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=34.9648, avg_loss=34.9648]Epoch 16:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=36.4016, avg_loss=36.4016]Epoch 16:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=35.2714, avg_loss=35.2714]Epoch 16:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=33.9588, avg_loss=33.9588]Epoch 16:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:  64%|██████▎   | 7/11 [00:06<00:03,  1.20it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=33.9588, avg_loss=33.9588]Epoch 16:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=35.2714, avg_loss=35.2714]Epoch 16:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=34.9648, avg_loss=34.9648]Epoch 16:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=36.4016, avg_loss=36.4016]Epoch 16:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=33.7081, avg_loss=34.9558]Epoch 16: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=33.7081, avg_loss=34.9558]Epoch 16: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=33.7081, avg_loss=34.9558]
Epoch 16:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=33.1081, avg_loss=36.5245]Epoch 16: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=33.1081, avg_loss=36.5245]Epoch 16: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=33.1081, avg_loss=36.5245]
INFO:__main__:=== EPOCH 16 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.955827
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.195148
INFO:__main__:   • gene_density: 1.187027
INFO:__main__:   • operon_membership: 11.573653
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 16 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.524543
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.209779
INFO:__main__:   • gene_density: 1.180102
INFO:__main__:   • operon_membership: 11.134662
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 16:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=35.5312, avg_loss=35.2399]Epoch 16: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=35.5312, avg_loss=35.2399]Epoch 16: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=35.5312, avg_loss=35.2399]
INFO:__main__:=== EPOCH 16 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.239923
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.562077
INFO:__main__:   • gene_density: 1.173591
INFO:__main__:   • operon_membership: 12.504254
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 16:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=33.9254, avg_loss=36.3900]Epoch 16: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=33.9254, avg_loss=36.3900]Epoch 16: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=33.9254, avg_loss=36.3900]
INFO:__main__:=== EPOCH 16 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.390045
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.793001
INFO:__main__:   • gene_density: 1.195076
INFO:__main__:   • operon_membership: 11.401969
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 17/681
INFO:__main__:Epoch 17/681
INFO:__main__:Epoch 17/681
INFO:__main__:Epoch 17/681
Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 17:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 17:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=34.1609, avg_loss=34.1609]Epoch 17:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=33.0655, avg_loss=33.0655]Epoch 17:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=34.2764, avg_loss=34.2764]Epoch 17:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=33.6732, avg_loss=33.6732]Epoch 17:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=34.2764, avg_loss=34.2764]Epoch 17:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=34.1609, avg_loss=34.1609]Epoch 17:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=33.6732, avg_loss=33.6732]Epoch 17:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=33.0655, avg_loss=33.0655]Epoch 17:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=34.7771, avg_loss=36.2766]Epoch 17: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=34.7771, avg_loss=36.2766]Epoch 17: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=34.7771, avg_loss=36.2766]
INFO:__main__:=== EPOCH 17 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.276588
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.154856
INFO:__main__:   • gene_density: 1.180990
INFO:__main__:   • operon_membership: 11.940743
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 17:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=36.8191, avg_loss=35.6564]Epoch 17:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=36.1373, avg_loss=35.0142]Epoch 17:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=35.0823, avg_loss=36.0463]Epoch 17: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=36.1373, avg_loss=35.0142]Epoch 17: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=36.8191, avg_loss=35.6564]Epoch 17: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=35.0823, avg_loss=36.0463]Epoch 17: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=36.1373, avg_loss=35.0142]
Epoch 17: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=35.0823, avg_loss=36.0463]
Epoch 17: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=36.8191, avg_loss=35.6564]
INFO:__main__:=== EPOCH 17 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 17 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.014219
INFO:__main__:🔢 Total Loss: 36.046277
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.600863
INFO:__main__:   • gene_expression: 23.193292
INFO:__main__:   • gene_density: 1.186494
INFO:__main__:   • gene_density: 1.181167
INFO:__main__:   • operon_membership: 11.226862
INFO:__main__:   • operon_membership: 11.671818
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 17 TRAINING LOSSES ===
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 35.656370
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.804691
INFO:__main__:   • gene_density: 1.183653
INFO:__main__:   • operon_membership: 11.668026
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 18/681
INFO:__main__:Epoch 18/681
INFO:__main__:Epoch 18/681
INFO:__main__:Epoch 18/681
Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 18:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 18:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=36.4016, avg_loss=36.4016]Epoch 18:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:   9%|▉         | 1/11 [00:01<00:10,  1.10s/it, loss=37.7841, avg_loss=37.7841]Epoch 18:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:   9%|▉         | 1/11 [00:01<00:10,  1.10s/it, loss=39.2803, avg_loss=39.2803]Epoch 18:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:   9%|▉         | 1/11 [00:01<00:11,  1.10s/it, loss=35.5279, avg_loss=35.5279]Epoch 18:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, loss=35.5279, avg_loss=35.5279]Epoch 18:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, loss=37.7841, avg_loss=37.7841]Epoch 18:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, loss=36.4016, avg_loss=36.4016]Epoch 18:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, loss=39.2803, avg_loss=39.2803]Epoch 18:  91%|█████████ | 10/11 [00:09<00:00,  1.20it/s, loss=37.1091, avg_loss=35.6665]Epoch 18: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=37.1091, avg_loss=35.6665]Epoch 18: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=37.1091, avg_loss=35.6665]
Epoch 18:  91%|█████████ | 10/11 [00:09<00:00,  1.20it/s, loss=34.4446, avg_loss=35.6699]INFO:__main__:=== EPOCH 18 TRAINING LOSSES ===
Epoch 18: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=34.4446, avg_loss=35.6699]INFO:__main__:🔢 Total Loss: 35.666473
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.320226
INFO:__main__:   • gene_density: 1.173947
INFO:__main__:   • operon_membership: 11.172301
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 18: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=34.4446, avg_loss=35.6699]
INFO:__main__:=== EPOCH 18 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.669915
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.940224
INFO:__main__:   • gene_density: 1.192057
INFO:__main__:   • operon_membership: 11.537633
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 18:  91%|█████████ | 10/11 [00:09<00:00,  1.20it/s, loss=35.5290, avg_loss=34.9732]Epoch 18:  91%|█████████ | 10/11 [00:09<00:00,  1.20it/s, loss=39.2026, avg_loss=36.9446]Epoch 18: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=35.5290, avg_loss=34.9732]Epoch 18: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=39.2026, avg_loss=36.9446]Epoch 18: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=35.5290, avg_loss=34.9732]
Epoch 18: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=39.2026, avg_loss=36.9446]
INFO:__main__:=== EPOCH 18 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 18 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.973171
INFO:__main__:🔢 Total Loss: 36.944553
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.644617
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.186257
INFO:__main__:   • gene_expression: 23.929530
INFO:__main__:   • operon_membership: 12.142297
INFO:__main__:   • gene_density: 1.180398
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.834625
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 19/681
INFO:__main__:Epoch 19/681
INFO:__main__:Epoch 19/681
INFO:__main__:Epoch 19/681
Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 19:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 19:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=35.1078, avg_loss=35.1078]Epoch 19:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=36.8822, avg_loss=36.8822]Epoch 19:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=32.9919, avg_loss=32.9919]Epoch 19:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=37.2738, avg_loss=37.2738]Epoch 19:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, loss=36.8822, avg_loss=36.8822]Epoch 19:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, loss=35.1078, avg_loss=35.1078]Epoch 19:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, loss=37.2738, avg_loss=37.2738]Epoch 19:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=32.9919, avg_loss=32.9919]Epoch 19:  91%|█████████ | 10/11 [00:09<00:00,  1.20it/s, loss=37.2262, avg_loss=35.9366]Epoch 19: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=37.2262, avg_loss=35.9366]Epoch 19: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=37.2262, avg_loss=35.9366]
Epoch 19:  91%|█████████ | 10/11 [00:09<00:00,  1.20it/s, loss=34.6688, avg_loss=35.1642]Epoch 19: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=34.6688, avg_loss=35.1642]INFO:__main__:=== EPOCH 19 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.936596
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.066064
INFO:__main__:   • gene_density: 1.188033
INFO:__main__:   • operon_membership: 11.682499
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 19: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=34.6688, avg_loss=35.1642]
INFO:__main__:=== EPOCH 19 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.164162
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.093359
INFO:__main__:   • gene_density: 1.178385
INFO:__main__:   • operon_membership: 10.892418
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 19:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=33.1722, avg_loss=35.1527]Epoch 19: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=33.1722, avg_loss=35.1527]Epoch 19: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=33.1722, avg_loss=35.1527]
INFO:__main__:=== EPOCH 19 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.152742
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.941400
INFO:__main__:   • gene_density: 1.190282
INFO:__main__:   • operon_membership: 12.021059
INFO:__main__:👥 Samples processed: 22
Epoch 19:  91%|█████████ | 10/11 [00:09<00:00,  1.20it/s, loss=39.8540, avg_loss=36.8026]INFO:__main__:========================================
Epoch 19: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=39.8540, avg_loss=36.8026]Epoch 19: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=39.8540, avg_loss=36.8026]
INFO:__main__:=== EPOCH 19 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.802572
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.633622
INFO:__main__:   • gene_density: 1.176373
INFO:__main__:   • operon_membership: 11.992576
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 20/681
INFO:__main__:Epoch 20/681
INFO:__main__:Epoch 20/681
INFO:__main__:Epoch 20/681
Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 20:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 20:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:   9%|▉         | 1/11 [00:01<00:11,  1.11s/it, loss=35.4009, avg_loss=35.4009]Epoch 20:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:   9%|▉         | 1/11 [00:01<00:11,  1.11s/it, loss=33.7207, avg_loss=33.7207]Epoch 20:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:   9%|▉         | 1/11 [00:01<00:11,  1.11s/it, loss=34.7794, avg_loss=34.7794]Epoch 20:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:   9%|▉         | 1/11 [00:01<00:11,  1.11s/it, loss=35.7425, avg_loss=35.7425]Epoch 20:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:  64%|██████▎   | 7/11 [00:06<00:03,  1.20it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:  64%|██████▎   | 7/11 [00:06<00:03,  1.20it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:  64%|██████▎   | 7/11 [00:06<00:03,  1.20it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=34.7794, avg_loss=34.7794]Epoch 20:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=35.7425, avg_loss=35.7425]Epoch 20:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=33.7207, avg_loss=33.7207]Epoch 20:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=35.4009, avg_loss=35.4009]Epoch 20:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=35.8727, avg_loss=35.0238]Epoch 20: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=35.8727, avg_loss=35.0238]Epoch 20: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=35.8727, avg_loss=35.0238]
INFO:__main__:=== EPOCH 20 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.023769
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.639188
INFO:__main__:   • gene_density: 1.197206
INFO:__main__:   • operon_membership: 11.187375
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 20:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=34.7660, avg_loss=36.4491]Epoch 20: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=34.7660, avg_loss=36.4491]Epoch 20: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=34.7660, avg_loss=36.4491]
Epoch 20:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=33.8579, avg_loss=35.7095]Epoch 20:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=34.8089, avg_loss=35.8759]Epoch 20: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=33.8579, avg_loss=35.7095]Epoch 20: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=34.8089, avg_loss=35.8759]Epoch 20: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=33.8579, avg_loss=35.7095]
Epoch 20: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=34.8089, avg_loss=35.8759]
INFO:__main__:=== EPOCH 20 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.449063
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.891834
INFO:__main__:   • gene_density: 1.170514
INFO:__main__:   • operon_membership: 12.386715
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 20 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.709491
INFO:__main__:=== EPOCH 20 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.875877
INFO:__main__:   • gene_expression: 23.149381
INFO:__main__:   • gene_density: 1.179688
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • operon_membership: 11.380421
INFO:__main__:   • gene_expression: 23.020773
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_density: 1.184718
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 11.670384
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.77it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.79it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.79it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.79it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.37it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.35it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.37it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.37it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.63it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.64it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.35it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.35it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.33it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]INFO:__main__:=== EPOCH 20 VALIDATION LOSSES ===

INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 20 VALIDATION LOSSES ===
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:========================================
INFO:__main__:=== EPOCH 20 VALIDATION LOSSES ===
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 20 VALIDATION LOSSES ===
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_20.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_20.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_20.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_20.pt
INFO:__main__:Epoch 21/681
INFO:__main__:Epoch 21/681
INFO:__main__:Epoch 21/681
INFO:__main__:Epoch 21/681
Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 21:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 21:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=36.1245, avg_loss=36.1245]Epoch 21:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=39.0110, avg_loss=39.0110]Epoch 21:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:   9%|▉         | 1/11 [00:01<00:11,  1.13s/it, loss=33.1578, avg_loss=33.1578]Epoch 21:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:   9%|▉         | 1/11 [00:01<00:11,  1.13s/it, loss=33.7606, avg_loss=33.7606]Epoch 21:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=39.0110, avg_loss=39.0110]Epoch 21:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=33.1578, avg_loss=33.1578]Epoch 21:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=36.1245, avg_loss=36.1245]Epoch 21:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=33.7606, avg_loss=33.7606]Epoch 21:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=35.7596, avg_loss=36.0230]Epoch 21:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=38.9248, avg_loss=35.9163]Epoch 21: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=35.7596, avg_loss=36.0230]Epoch 21: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=38.9248, avg_loss=35.9163]Epoch 21: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=35.7596, avg_loss=36.0230]
Epoch 21: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=38.9248, avg_loss=35.9163]
INFO:__main__:=== EPOCH 21 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.023009
INFO:__main__:=== EPOCH 21 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.771669
INFO:__main__:🔢 Total Loss: 35.916295
INFO:__main__:   • gene_density: 1.188388
INFO:__main__:   • operon_membership: 12.062952
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_expression: 23.130597
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.178800
INFO:__main__:   • operon_membership: 11.606899
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 21:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=37.4973, avg_loss=36.0250]Epoch 21: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=37.4973, avg_loss=36.0250]Epoch 21: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=37.4973, avg_loss=36.0250]Epoch 21:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=37.1037, avg_loss=35.3100]
Epoch 21: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=37.1037, avg_loss=35.3100]Epoch 21: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=37.1037, avg_loss=35.3100]
INFO:__main__:=== EPOCH 21 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.024995
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.041219
INFO:__main__:   • gene_density: 1.182351
INFO:__main__:   • operon_membership: 11.801425
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 21 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.310028
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.879343
INFO:__main__:   • gene_density: 1.181581
INFO:__main__:   • operon_membership: 11.249103
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 22/681
INFO:__main__:Epoch 22/681
INFO:__main__:Epoch 22/681
INFO:__main__:Epoch 22/681
Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 22:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 22:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:   9%|▉         | 1/11 [00:01<00:10,  1.07s/it, loss=34.0626, avg_loss=34.0626]Epoch 22:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=37.6089, avg_loss=37.6089]Epoch 22:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=39.0267, avg_loss=39.0267]Epoch 22:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:   9%|▉         | 1/11 [00:01<00:10,  1.08s/it, loss=34.9145, avg_loss=34.9145]Epoch 22:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:  45%|████▌     | 5/11 [00:04<00:05,  1.17it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:  64%|██████▎   | 7/11 [00:06<00:03,  1.19it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=34.0626, avg_loss=34.0626]Epoch 22:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=37.6089, avg_loss=37.6089]Epoch 22:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=39.0267, avg_loss=39.0267]Epoch 22:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=34.9145, avg_loss=34.9145]Epoch 22:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=37.9230, avg_loss=36.0306]Epoch 22:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=36.8567, avg_loss=34.9226]Epoch 22: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=37.9230, avg_loss=36.0306]Epoch 22: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=36.8567, avg_loss=34.9226]Epoch 22: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=37.9230, avg_loss=36.0306]
Epoch 22: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=36.8567, avg_loss=34.9226]
INFO:__main__:=== EPOCH 22 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.030589
INFO:__main__:=== EPOCH 22 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.175849
INFO:__main__:🔢 Total Loss: 34.922572
INFO:__main__:   • gene_density: 1.199100
INFO:__main__:   • operon_membership: 12.655640
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_expression: 22.554120
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.179273
INFO:__main__:   • operon_membership: 11.189178
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 22:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=37.1424, avg_loss=36.3919]Epoch 22: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=37.1424, avg_loss=36.3919]Epoch 22:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=34.4772, avg_loss=35.6610]Epoch 22: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=34.4772, avg_loss=35.6610]Epoch 22: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=37.1424, avg_loss=36.3919]
Epoch 22: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=34.4772, avg_loss=35.6610]
INFO:__main__:=== EPOCH 22 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 22 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.391925
INFO:__main__:🔢 Total Loss: 35.661044
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.872657
INFO:__main__:   • gene_expression: 23.193145
INFO:__main__:   • gene_density: 1.157434
INFO:__main__:   • gene_density: 1.196555
INFO:__main__:   • operon_membership: 11.361833
INFO:__main__:   • operon_membership: 11.271344
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:Epoch 23/681
INFO:__main__:Epoch 23/681
INFO:__main__:Epoch 23/681
INFO:__main__:Epoch 23/681
Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 23:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 23:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=34.6434, avg_loss=34.6434]Epoch 23:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=37.1597, avg_loss=37.1597]Epoch 23:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=37.0207, avg_loss=37.0207]Epoch 23:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=33.6958, avg_loss=33.6958]Epoch 23:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:  18%|█▊        | 2/11 [00:01<00:08,  1.07it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:  27%|██▋       | 3/11 [00:02<00:07,  1.13it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:  36%|███▋      | 4/11 [00:03<00:06,  1.16it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:  45%|████▌     | 5/11 [00:04<00:05,  1.18it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:  55%|█████▍    | 6/11 [00:05<00:04,  1.19it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:  64%|██████▎   | 7/11 [00:06<00:03,  1.20it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:  64%|██████▎   | 7/11 [00:06<00:03,  1.20it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:  64%|██████▎   | 7/11 [00:06<00:03,  1.20it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:  64%|██████▎   | 7/11 [00:06<00:03,  1.20it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:  73%|███████▎  | 8/11 [00:06<00:02,  1.21it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:  73%|███████▎  | 8/11 [00:06<00:02,  1.20it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:  82%|████████▏ | 9/11 [00:07<00:01,  1.21it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:  82%|████████▏ | 9/11 [00:07<00:01,  1.20it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=33.6958, avg_loss=33.6958]Epoch 23:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=34.6434, avg_loss=34.6434]Epoch 23:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=37.1597, avg_loss=37.1597]Epoch 23:  91%|█████████ | 10/11 [00:08<00:00,  1.21it/s, loss=37.0207, avg_loss=37.0207]Epoch 23:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=35.9504, avg_loss=36.4352]Epoch 23: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=35.9504, avg_loss=36.4352]Epoch 23:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=34.2077, avg_loss=35.4687]Epoch 23: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=34.2077, avg_loss=35.4687]Epoch 23: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=35.9504, avg_loss=36.4352]
Epoch 23: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=34.2077, avg_loss=35.4687]
INFO:__main__:=== EPOCH 23 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.435228
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.078920
INFO:__main__:   • gene_density: 1.189690
INFO:__main__:   • operon_membership: 12.166619
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 23 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.468671
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.503140
INFO:__main__:   • gene_density: 1.185606
INFO:__main__:   • operon_membership: 11.779924
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 23:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=30.7914, avg_loss=34.2003]Epoch 23: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=30.7914, avg_loss=34.2003]Epoch 23: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=30.7914, avg_loss=34.2003]
INFO:__main__:=== EPOCH 23 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.200273
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.612259
INFO:__main__:   • gene_density: 1.189098
INFO:__main__:   • operon_membership: 11.398917
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 23:  91%|█████████ | 10/11 [00:09<00:00,  1.21it/s, loss=38.3374, avg_loss=36.9060]Epoch 23: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=38.3374, avg_loss=36.9060]Epoch 23: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=38.3374, avg_loss=36.9060]
INFO:__main__:=== EPOCH 23 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.906000
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.384061
INFO:__main__:   • gene_density: 1.171342
INFO:__main__:   • operon_membership: 11.350597
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 24/681
INFO:__main__:Epoch 24/681
INFO:__main__:Epoch 24/681
INFO:__main__:Epoch 24/681
Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 24:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 24:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:   9%|▉         | 1/11 [00:01<00:11,  1.10s/it, loss=36.5985, avg_loss=36.5985]Epoch 24:   0%|          | 0/11 [00:01<?, ?it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:   9%|▉         | 1/11 [00:01<00:11,  1.11s/it, loss=30.9475, avg_loss=30.9475]Epoch 24:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:   9%|▉         | 1/11 [00:01<00:11,  1.11s/it, loss=35.2618, avg_loss=35.2618]Epoch 24:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:   9%|▉         | 1/11 [00:01<00:11,  1.11s/it, loss=37.4355, avg_loss=37.4355]Epoch 24:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:  18%|█▊        | 2/11 [00:01<00:08,  1.06it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:  27%|██▋       | 3/11 [00:02<00:07,  1.12it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:  36%|███▋      | 4/11 [00:03<00:06,  1.15it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:  55%|█████▍    | 6/11 [00:05<00:04,  1.18it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, loss=30.9475, avg_loss=30.9475]Epoch 24:  91%|█████████ | 10/11 [00:08<00:00,  1.20it/s, loss=37.4355, avg_loss=37.4355]Epoch 24:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=36.5985, avg_loss=36.5985]Epoch 24:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=35.2618, avg_loss=35.2618]Epoch 24:  91%|█████████ | 10/11 [00:09<00:00,  1.20it/s, loss=41.0323, avg_loss=35.4145]Epoch 24: 100%|██████████| 11/11 [00:09<00:00,  1.12it/s, loss=41.0323, avg_loss=35.4145]Epoch 24: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=41.0323, avg_loss=35.4145]
Epoch 24:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=37.5629, avg_loss=36.0568]Epoch 24: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=37.5629, avg_loss=36.0568]Epoch 24: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=37.5629, avg_loss=36.0568]
INFO:__main__:=== EPOCH 24 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.414501
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.642207
INFO:__main__:   • gene_density: 1.189808
INFO:__main__:   • operon_membership: 11.582485
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 24 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.056831
Epoch 24:  91%|█████████ | 10/11 [00:09<00:00,  1.20it/s, loss=34.6015, avg_loss=35.7610]INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.814802
INFO:__main__:   • gene_density: 1.184718
INFO:__main__:   • operon_membership: 12.057310
Epoch 24: 100%|██████████| 11/11 [00:09<00:00,  1.12it/s, loss=34.6015, avg_loss=35.7610]INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 24: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=34.6015, avg_loss=35.7610]
INFO:__main__:=== EPOCH 24 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.760996
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.325040
INFO:__main__:   • gene_density: 1.177143
INFO:__main__:   • operon_membership: 11.258813
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 24:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=36.5944, avg_loss=36.0613]Epoch 24: 100%|██████████| 11/11 [00:09<00:00,  1.12it/s, loss=36.5944, avg_loss=36.0613]Epoch 24: 100%|██████████| 11/11 [00:09<00:00,  1.14it/s, loss=36.5944, avg_loss=36.0613]
INFO:__main__:=== EPOCH 24 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.061325
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.152156
INFO:__main__:   • gene_density: 1.180339
INFO:__main__:   • operon_membership: 11.728830
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 25/681
INFO:__main__:Epoch 25/681
INFO:__main__:Epoch 25/681
INFO:__main__:Epoch 25/681
Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 25:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 25:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0455, avg_loss=34.0455]Epoch 25:   9%|▉         | 1/11 [00:01<00:11,  1.18s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.0923, avg_loss=37.0923]Epoch 25:   9%|▉         | 1/11 [00:01<00:11,  1.18s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3100, avg_loss=34.3100]Epoch 25:   9%|▉         | 1/11 [00:01<00:11,  1.18s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3365, avg_loss=34.3365]Epoch 25:   9%|▉         | 1/11 [00:01<00:11,  1.20s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:  18%|█▊        | 2/11 [00:02<00:12,  1.36s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  27%|██▋       | 3/11 [00:04<00:11,  1.39s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:  27%|██▋       | 3/11 [00:04<00:11,  1.39s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  36%|███▋      | 4/11 [00:05<00:09,  1.41s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  64%|██████▎   | 7/11 [00:09<00:05,  1.45s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:  64%|██████▎   | 7/11 [00:09<00:05,  1.45s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:  64%|██████▎   | 7/11 [00:09<00:05,  1.46s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:  64%|██████▎   | 7/11 [00:09<00:05,  1.45s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  82%|████████▏ | 9/11 [00:12<00:02,  1.46s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:  82%|████████▏ | 9/11 [00:12<00:02,  1.46s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:  82%|████████▏ | 9/11 [00:12<00:02,  1.46s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:  82%|████████▏ | 9/11 [00:12<00:02,  1.46s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  91%|█████████ | 10/11 [00:14<00:01,  1.47s/it, loss=34.3100, avg_loss=34.3100]Epoch 25:  91%|█████████ | 10/11 [00:14<00:01,  1.47s/it, loss=34.0455, avg_loss=34.0455]Epoch 25:  91%|█████████ | 10/11 [00:14<00:01,  1.47s/it, loss=37.0923, avg_loss=37.0923]Epoch 25:  91%|█████████ | 10/11 [00:14<00:01,  1.47s/it, loss=34.3365, avg_loss=34.3365]Epoch 25:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=36.2730, avg_loss=36.8194]Epoch 25: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=36.2730, avg_loss=36.8194]Epoch 25: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=36.2730, avg_loss=36.8194]
Epoch 25:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=32.6726, avg_loss=35.1469]Epoch 25: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=32.6726, avg_loss=35.1469]Epoch 25: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=32.6726, avg_loss=35.1469]
INFO:__main__:=== EPOCH 25 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.819437
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.458557
INFO:__main__:   • gene_density: 1.180575
INFO:__main__:   • operon_membership: 12.180305
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 25 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.146928
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.338729
INFO:__main__:   • gene_density: 1.179983
INFO:__main__:   • operon_membership: 11.628215
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 25:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=33.7483, avg_loss=35.6657]Epoch 25: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=33.7483, avg_loss=35.6657]Epoch 25: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=33.7483, avg_loss=35.6657]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 25 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.665719
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.442124
INFO:__main__:   • gene_density: 1.189867
INFO:__main__:   • operon_membership: 12.033729
INFO:__main__:👥 Samples processed: 22
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 25:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=37.8894, avg_loss=35.5220]Epoch 25: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=37.8894, avg_loss=35.5220]Epoch 25: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=37.8894, avg_loss=35.5220]
INFO:__main__:=== EPOCH 25 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.521966
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.472072
INFO:__main__:   • gene_density: 1.178977
INFO:__main__:   • operon_membership: 10.870917
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.39it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.39it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.39it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.38it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.96it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.31it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.31it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.33it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.31it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.16it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.16it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.16it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.17it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.06it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.06it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.06it/s]


Validation: 100%|██████████| 4/4 [00:01<00:00,  2.07it/s]
INFO:__main__:=== EPOCH 25 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 25 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:=== EPOCH 25 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 25 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:Epoch 26/681
INFO:__main__:Epoch 26/681
INFO:__main__:Epoch 26/681
INFO:__main__:Epoch 26/681
Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 26:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 26:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.2195, avg_loss=36.2195]Epoch 26:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.2459, avg_loss=36.2459]Epoch 26:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6616, avg_loss=33.6616]Epoch 26:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.9392, avg_loss=37.9392]Epoch 26:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=33.6616, avg_loss=33.6616]Epoch 26:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=36.2459, avg_loss=36.2459]Epoch 26:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=36.2195, avg_loss=36.2195]Epoch 26:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=37.9392, avg_loss=37.9392]Epoch 26:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=36.4353, avg_loss=35.4458]Epoch 26: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.4353, avg_loss=35.4458]Epoch 26:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=37.2438, avg_loss=36.4833]Epoch 26: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.2438, avg_loss=36.4833]Epoch 26: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=36.4353, avg_loss=35.4458]
Epoch 26: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=37.2438, avg_loss=36.4833]
Epoch 26:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.2287, avg_loss=35.4899]Epoch 26: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.2287, avg_loss=35.4899]Epoch 26: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=35.2287, avg_loss=35.4899]
INFO:__main__:=== EPOCH 26 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.445834
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.954197
INFO:__main__:   • gene_density: 1.188151
INFO:__main__:=== EPOCH 26 TRAINING LOSSES ===
INFO:__main__:   • operon_membership: 12.303486
INFO:__main__:👥 Samples processed: 22
INFO:__main__:🔢 Total Loss: 36.483318
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.788274
INFO:__main__:   • gene_density: 1.179096
INFO:__main__:   • operon_membership: 11.515947
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 26 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.489892
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.417292
INFO:__main__:   • gene_density: 1.179628
INFO:__main__:   • operon_membership: 10.892972
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 26:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=36.5420, avg_loss=35.6409]Epoch 26: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.5420, avg_loss=35.6409]Epoch 26: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=36.5420, avg_loss=35.6409]
INFO:__main__:=== EPOCH 26 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.640922
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.694690
INFO:__main__:   • gene_density: 1.181937
INFO:__main__:   • operon_membership: 11.764295
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 27/681
INFO:__main__:Epoch 27/681
INFO:__main__:Epoch 27/681
INFO:__main__:Epoch 27/681
Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 27:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 27:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1704, avg_loss=36.1704]Epoch 27:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.0350, avg_loss=38.0350]Epoch 27:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8231, avg_loss=33.8231]Epoch 27:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.9974, avg_loss=37.9974]Epoch 27:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  18%|█▊        | 2/11 [00:02<00:10,  1.18s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:  18%|█▊        | 2/11 [00:02<00:10,  1.18s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  18%|█▊        | 2/11 [00:02<00:10,  1.19s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:  18%|█▊        | 2/11 [00:02<00:10,  1.19s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:  27%|██▋       | 3/11 [00:03<00:10,  1.29s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:  27%|██▋       | 3/11 [00:03<00:10,  1.29s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  27%|██▋       | 3/11 [00:03<00:10,  1.30s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:  27%|██▋       | 3/11 [00:03<00:10,  1.30s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:  82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=38.0350, avg_loss=38.0350]Epoch 27:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=33.8231, avg_loss=33.8231]Epoch 27:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=37.9974, avg_loss=37.9974]Epoch 27:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=36.1704, avg_loss=36.1704]Epoch 27:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=34.1883, avg_loss=36.6371]Epoch 27: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=34.1883, avg_loss=36.6371]Epoch 27: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=34.1883, avg_loss=36.6371]
INFO:__main__:=== EPOCH 27 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.637119
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.022423
INFO:__main__:   • gene_density: 1.186967
INFO:__main__:   • operon_membership: 12.427729
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 27:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=34.8740, avg_loss=35.6331]Epoch 27: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=34.8740, avg_loss=35.6331]Epoch 27: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=34.8740, avg_loss=35.6331]
Epoch 27:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=37.5632, avg_loss=34.7395]Epoch 27: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=37.5632, avg_loss=34.7395]Epoch 27: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.5632, avg_loss=34.7395]
INFO:__main__:=== EPOCH 27 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.633077
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.864106
INFO:__main__:   • gene_density: 1.182233
INFO:__main__:   • operon_membership: 11.586739
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 27 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.739466
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.417974
INFO:__main__:   • gene_density: 1.183594
INFO:__main__:   • operon_membership: 11.137899
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 27:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=37.8339, avg_loss=36.1444]Epoch 27: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=37.8339, avg_loss=36.1444]Epoch 27: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=37.8339, avg_loss=36.1444]
INFO:__main__:=== EPOCH 27 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.144448
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.474566
INFO:__main__:   • gene_density: 1.180753
INFO:__main__:   • operon_membership: 11.489129
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 28/681
INFO:__main__:Epoch 28/681
INFO:__main__:Epoch 28/681
INFO:__main__:Epoch 28/681
Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 28:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 28:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8389, avg_loss=33.8389]Epoch 28:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2289, avg_loss=34.2289]Epoch 28:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.0213, avg_loss=37.0213]Epoch 28:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0762, avg_loss=33.0762]Epoch 28:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:  18%|█▊        | 2/11 [00:02<00:09,  1.11s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  18%|█▊        | 2/11 [00:02<00:09,  1.11s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:  27%|██▋       | 3/11 [00:03<00:08,  1.11s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  36%|███▋      | 4/11 [00:04<00:08,  1.22s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:  36%|███▋      | 4/11 [00:04<00:08,  1.22s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  55%|█████▍    | 6/11 [00:07<00:06,  1.34s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:  55%|█████▍    | 6/11 [00:07<00:06,  1.34s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:  55%|█████▍    | 6/11 [00:07<00:06,  1.34s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  73%|███████▎  | 8/11 [00:10<00:04,  1.39s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:  73%|███████▎  | 8/11 [00:10<00:04,  1.39s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=34.2289, avg_loss=34.2289]Epoch 28:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=37.0213, avg_loss=37.0213]Epoch 28:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=33.8389, avg_loss=33.8389]Epoch 28:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=33.0762, avg_loss=33.0762]Epoch 28:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=35.6324, avg_loss=34.9806]Epoch 28: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.6324, avg_loss=34.9806]Epoch 28:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=38.4287, avg_loss=36.0618]Epoch 28: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=38.4287, avg_loss=36.0618]Epoch 28: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.6324, avg_loss=34.9806]
Epoch 28:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=35.2795, avg_loss=36.5257]Epoch 28: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.2795, avg_loss=36.5257]Epoch 28: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=38.4287, avg_loss=36.0618]
Epoch 28: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.2795, avg_loss=36.5257]
INFO:__main__:=== EPOCH 28 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.980580
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.500384
INFO:__main__:   • gene_density: 1.182173
INFO:__main__:   • operon_membership: 11.298024
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 28 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.061819
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.663647
INFO:__main__:   • gene_density: 1.193359
INFO:__main__:   • operon_membership: 12.204812
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 28 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.525664
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.653994
INFO:__main__:   • gene_density: 1.175900
INFO:__main__:   • operon_membership: 11.695770
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 28:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=35.1097, avg_loss=35.5837]Epoch 28: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.1097, avg_loss=35.5837]Epoch 28: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.1097, avg_loss=35.5837]
INFO:__main__:=== EPOCH 28 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.583746
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.948276
INFO:__main__:   • gene_density: 1.182824
INFO:__main__:   • operon_membership: 11.452646
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 29/681
INFO:__main__:Epoch 29/681
INFO:__main__:Epoch 29/681
INFO:__main__:Epoch 29/681
Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 29:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 29:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8043, avg_loss=33.8043]Epoch 29:   9%|▉         | 1/11 [00:01<00:16,  1.62s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.6503, avg_loss=35.6503]Epoch 29:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.6563, avg_loss=35.6563]Epoch 29:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7705, avg_loss=36.7705]Epoch 29:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  18%|█▊        | 2/11 [00:02<00:12,  1.37s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:  18%|█▊        | 2/11 [00:02<00:12,  1.37s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:  18%|█▊        | 2/11 [00:02<00:12,  1.37s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:  18%|█▊        | 2/11 [00:02<00:12,  1.38s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  27%|██▋       | 3/11 [00:03<00:09,  1.25s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  27%|██▋       | 3/11 [00:03<00:09,  1.25s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:  27%|██▋       | 3/11 [00:03<00:09,  1.25s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  45%|████▌     | 5/11 [00:06<00:06,  1.15s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:  45%|████▌     | 5/11 [00:06<00:06,  1.15s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:  45%|████▌     | 5/11 [00:06<00:06,  1.15s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:  45%|████▌     | 5/11 [00:06<00:06,  1.16s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  73%|███████▎  | 8/11 [00:10<00:04,  1.37s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:  73%|███████▎  | 8/11 [00:10<00:04,  1.37s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:  73%|███████▎  | 8/11 [00:10<00:04,  1.37s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:  73%|███████▎  | 8/11 [00:10<00:04,  1.37s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=33.8043, avg_loss=33.8043]Epoch 29:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=35.6503, avg_loss=35.6503]Epoch 29:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=35.6563, avg_loss=35.6563]Epoch 29:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=36.7705, avg_loss=36.7705]Epoch 29:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.8789, avg_loss=35.3873]Epoch 29:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=38.7071, avg_loss=35.6601]Epoch 29: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.8789, avg_loss=35.3873]Epoch 29: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=38.7071, avg_loss=35.6601]Epoch 29: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.8789, avg_loss=35.3873]Epoch 29: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=38.7071, avg_loss=35.6601]

INFO:__main__:=== EPOCH 29 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 29 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.660067
INFO:__main__:🔢 Total Loss: 35.387340
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.431344
INFO:__main__:   • gene_expression: 22.962009
INFO:__main__:   • gene_density: 1.186671
INFO:__main__:   • gene_density: 1.180990
INFO:__main__:   • operon_membership: 12.042052
INFO:__main__:   • operon_membership: 11.244341
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 29:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=37.5776, avg_loss=36.9442]Epoch 29: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=37.5776, avg_loss=36.9442]Epoch 29: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.5776, avg_loss=36.9442]
INFO:__main__:=== EPOCH 29 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.944156
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.311575
INFO:__main__:   • gene_density: 1.183120
INFO:__main__:   • operon_membership: 12.449461
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 29:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=33.0957, avg_loss=34.9856]Epoch 29: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=33.0957, avg_loss=34.9856]Epoch 29: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=33.0957, avg_loss=34.9856]
INFO:__main__:=== EPOCH 29 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.985598
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.795048
INFO:__main__:   • gene_density: 1.180871
INFO:__main__:   • operon_membership: 11.009679
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 30/681
INFO:__main__:Epoch 30/681
INFO:__main__:Epoch 30/681
INFO:__main__:Epoch 30/681
Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 30:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 30:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9980, avg_loss=35.9980]Epoch 30:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.1675, avg_loss=32.1675]Epoch 30:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.8157, avg_loss=31.8157]Epoch 30:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.7743, avg_loss=32.7743]Epoch 30:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  45%|████▌     | 5/11 [00:06<00:06,  1.16s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:  45%|████▌     | 5/11 [00:06<00:06,  1.16s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:  45%|████▌     | 5/11 [00:06<00:06,  1.16s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:  45%|████▌     | 5/11 [00:06<00:06,  1.16s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  64%|██████▎   | 7/11 [00:08<00:04,  1.23s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:  64%|██████▎   | 7/11 [00:08<00:04,  1.23s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:  64%|██████▎   | 7/11 [00:08<00:04,  1.23s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:  64%|██████▎   | 7/11 [00:09<00:04,  1.23s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=32.1675, avg_loss=32.1675]Epoch 30:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=31.8157, avg_loss=31.8157]Epoch 30:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=35.9980, avg_loss=35.9980]Epoch 30:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=32.7743, avg_loss=32.7743]Epoch 30:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.7048, avg_loss=35.9078]Epoch 30: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=35.7048, avg_loss=35.9078]Epoch 30: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.7048, avg_loss=35.9078]
INFO:__main__:=== EPOCH 30 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.907805
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.346075
INFO:__main__:   • gene_density: 1.186435
INFO:__main__:   • operon_membership: 12.375294
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 30:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=36.1778, avg_loss=36.4172]Epoch 30: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=36.1778, avg_loss=36.4172]Epoch 30: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=36.1778, avg_loss=36.4172]
Epoch 30:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=37.1766, avg_loss=35.3066]Epoch 30: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=37.1766, avg_loss=35.3066]INFO:__main__:=== EPOCH 30 TRAINING LOSSES ===
Epoch 30: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.1766, avg_loss=35.3066]
INFO:__main__:🔢 Total Loss: 36.417188
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.363318
INFO:__main__:   • gene_density: 1.189098
INFO:__main__:   • operon_membership: 11.864772
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 30 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.306596
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.311548
INFO:__main__:   • gene_density: 1.168797
INFO:__main__:   • operon_membership: 10.826250
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 30:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=34.7872, avg_loss=35.5517]Epoch 30: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=34.7872, avg_loss=35.5517]Epoch 30: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.7872, avg_loss=35.5517]
INFO:__main__:=== EPOCH 30 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.551678
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.792889
INFO:__main__:   • gene_density: 1.182824
INFO:__main__:   • operon_membership: 11.575965
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.26it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.26it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.60it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.60it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.60it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.59it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
INFO:__main__:=== EPOCH 30 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 30 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 30 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
INFO:__main__:=== EPOCH 30 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_30.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_30.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_30.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_30.pt
INFO:__main__:Epoch 31/681
INFO:__main__:Epoch 31/681
INFO:__main__:Epoch 31/681
INFO:__main__:Epoch 31/681
Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 31:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 31:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6277, avg_loss=33.6277]Epoch 31:   9%|▉         | 1/11 [00:01<00:17,  1.76s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9530, avg_loss=35.9530]Epoch 31:   9%|▉         | 1/11 [00:01<00:17,  1.77s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5106, avg_loss=34.5106]Epoch 31:   9%|▉         | 1/11 [00:01<00:17,  1.77s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5648, avg_loss=34.5648]Epoch 31:   9%|▉         | 1/11 [00:01<00:17,  1.78s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:  18%|█▊        | 2/11 [00:03<00:14,  1.60s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  82%|████████▏ | 9/11 [00:13<00:02,  1.42s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:  82%|████████▏ | 9/11 [00:13<00:02,  1.41s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:  82%|████████▏ | 9/11 [00:13<00:02,  1.42s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:  82%|████████▏ | 9/11 [00:13<00:02,  1.41s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=33.6277, avg_loss=33.6277]Epoch 31:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=35.9530, avg_loss=35.9530]Epoch 31:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=34.5106, avg_loss=34.5106]Epoch 31:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=34.5648, avg_loss=34.5648]Epoch 31:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=34.6487, avg_loss=36.0593]Epoch 31: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=34.6487, avg_loss=36.0593]Epoch 31: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=34.6487, avg_loss=36.0593]
INFO:__main__:=== EPOCH 31 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.059334
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.389808
INFO:__main__:   • gene_density: 1.195194
INFO:__main__:   • operon_membership: 11.474332
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 31:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=34.9746, avg_loss=35.1133]Epoch 31: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=34.9746, avg_loss=35.1133]Epoch 31: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=34.9746, avg_loss=35.1133]
Epoch 31:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=34.5715, avg_loss=35.4948]Epoch 31: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=34.5715, avg_loss=35.4948]Epoch 31: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=34.5715, avg_loss=35.4948]
Epoch 31:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=40.0584, avg_loss=36.4506]Epoch 31: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=40.0584, avg_loss=36.4506]INFO:__main__:=== EPOCH 31 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.113264
Epoch 31: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=40.0584, avg_loss=36.4506]
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.319565
INFO:__main__:   • gene_density: 1.185784
INFO:__main__:   • operon_membership: 11.607916
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 31 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.494791
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.639877
INFO:__main__:   • gene_density: 1.173710
INFO:__main__:   • operon_membership: 11.681204
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 31 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.450557
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.449188
INFO:__main__:   • gene_density: 1.175900
INFO:__main__:   • operon_membership: 11.825469
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 32/681
INFO:__main__:Epoch 32/681
INFO:__main__:Epoch 32/681
INFO:__main__:Epoch 32/681
Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 32:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 32:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2519, avg_loss=35.2519]Epoch 32:   9%|▉         | 1/11 [00:01<00:15,  1.51s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.7054, avg_loss=34.7054]Epoch 32:   9%|▉         | 1/11 [00:01<00:15,  1.51s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2937, avg_loss=34.2937]Epoch 32:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8875, avg_loss=33.8875]Epoch 32:   9%|▉         | 1/11 [00:01<00:15,  1.53s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  18%|█▊        | 2/11 [00:02<00:13,  1.46s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:  18%|█▊        | 2/11 [00:02<00:13,  1.46s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:  18%|█▊        | 2/11 [00:02<00:13,  1.46s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:  18%|█▊        | 2/11 [00:02<00:13,  1.47s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=35.2519, avg_loss=35.2519]Epoch 32:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=34.7054, avg_loss=34.7054]Epoch 32:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=34.2937, avg_loss=34.2937]Epoch 32:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=33.8875, avg_loss=33.8875]Epoch 32:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=37.4452, avg_loss=35.9426]Epoch 32: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.4452, avg_loss=35.9426]Epoch 32: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=37.4452, avg_loss=35.9426]
INFO:__main__:=== EPOCH 32 TRAINING LOSSES ===
Epoch 32:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.0837, avg_loss=35.7748]INFO:__main__:🔢 Total Loss: 35.942567
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.484662
Epoch 32: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.0837, avg_loss=35.7748]INFO:__main__:   • gene_density: 1.192057
INFO:__main__:   • operon_membership: 12.265847
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 32: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=35.0837, avg_loss=35.7748]
INFO:__main__:=== EPOCH 32 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.774815
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.470541
INFO:__main__:   • gene_density: 1.189216
INFO:__main__:   • operon_membership: 11.115057
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 32:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=33.1980, avg_loss=35.9784]Epoch 32: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=33.1980, avg_loss=35.9784]Epoch 32: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=33.1980, avg_loss=35.9784]
INFO:__main__:=== EPOCH 32 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.978363
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.012758
INFO:__main__:   • gene_density: 1.180871
INFO:__main__:   • operon_membership: 11.784733
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 32:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=33.9736, avg_loss=35.1079]Epoch 32: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=33.9736, avg_loss=35.1079]Epoch 32: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=33.9736, avg_loss=35.1079]
INFO:__main__:=== EPOCH 32 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.107887
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.533676
INFO:__main__:   • gene_density: 1.174183
INFO:__main__:   • operon_membership: 11.400026
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 33/681
INFO:__main__:Epoch 33/681
INFO:__main__:Epoch 33/681
INFO:__main__:Epoch 33/681
Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 33:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 33:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.1216, avg_loss=33.1216]Epoch 33:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1307, avg_loss=34.1307]Epoch 33:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3928, avg_loss=34.3928]Epoch 33:   9%|▉         | 1/11 [00:01<00:12,  1.30s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9769, avg_loss=36.9769]Epoch 33:   9%|▉         | 1/11 [00:01<00:12,  1.30s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  18%|█▊        | 2/11 [00:02<00:09,  1.03s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:  18%|█▊        | 2/11 [00:02<00:09,  1.03s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:  18%|█▊        | 2/11 [00:02<00:09,  1.03s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:  18%|█▊        | 2/11 [00:02<00:09,  1.03s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:  27%|██▋       | 3/11 [00:03<00:09,  1.15s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:  27%|██▋       | 3/11 [00:03<00:09,  1.15s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  36%|███▋      | 4/11 [00:04<00:08,  1.26s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:  36%|███▋      | 4/11 [00:04<00:08,  1.27s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:  36%|███▋      | 4/11 [00:04<00:08,  1.27s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:  36%|███▋      | 4/11 [00:04<00:08,  1.27s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  55%|█████▍    | 6/11 [00:07<00:06,  1.38s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:  55%|█████▍    | 6/11 [00:07<00:06,  1.38s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:  55%|█████▍    | 6/11 [00:07<00:06,  1.38s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=34.1307, avg_loss=34.1307]Epoch 33:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=33.1216, avg_loss=33.1216]Epoch 33:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=34.3928, avg_loss=34.3928]Epoch 33:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=36.9769, avg_loss=36.9769]Epoch 33:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=35.5054, avg_loss=36.0534]Epoch 33: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.5054, avg_loss=36.0534]Epoch 33: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.5054, avg_loss=36.0534]
INFO:__main__:=== EPOCH 33 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.053442
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.284883
INFO:__main__:   • gene_density: 1.163411
INFO:__main__:   • operon_membership: 12.605147
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 33:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=38.3610, avg_loss=36.1740]Epoch 33: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=38.3610, avg_loss=36.1740]Epoch 33:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=39.0008, avg_loss=35.3473]Epoch 33: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=39.0008, avg_loss=35.3473]Epoch 33: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.3610, avg_loss=36.1740]
Epoch 33: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=39.0008, avg_loss=35.3473]
INFO:__main__:=== EPOCH 33 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.173957
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.944840
INFO:__main__:   • gene_density: 1.190163
INFO:__main__:   • operon_membership: 12.038954
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 33 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.347276
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.979609
INFO:__main__:   • gene_density: 1.184778
INFO:__main__:   • operon_membership: 11.182890
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 33:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=35.2618, avg_loss=35.4355]Epoch 33: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.2618, avg_loss=35.4355]Epoch 33: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.2618, avg_loss=35.4355]
INFO:__main__:=== EPOCH 33 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.435498
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.369047
INFO:__main__:   • gene_density: 1.197384
INFO:__main__:   • operon_membership: 10.869067
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 34/681
INFO:__main__:Epoch 34/681
INFO:__main__:Epoch 34/681
INFO:__main__:Epoch 34/681
Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 34:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 34:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6089, avg_loss=37.6089]Epoch 34:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0640, avg_loss=35.0640]Epoch 34:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.8083, avg_loss=32.8083]Epoch 34:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.1950, avg_loss=33.1950]Epoch 34:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:  18%|█▊        | 2/11 [00:02<00:11,  1.28s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  27%|██▋       | 3/11 [00:03<00:09,  1.15s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  27%|██▋       | 3/11 [00:03<00:09,  1.15s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:  27%|██▋       | 3/11 [00:03<00:09,  1.15s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:  36%|███▋      | 4/11 [00:04<00:07,  1.02s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:  36%|███▋      | 4/11 [00:04<00:07,  1.02s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  36%|███▋      | 4/11 [00:04<00:07,  1.02s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:  36%|███▋      | 4/11 [00:04<00:07,  1.02s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:  45%|████▌     | 5/11 [00:05<00:06,  1.16s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:  45%|████▌     | 5/11 [00:05<00:06,  1.16s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:  45%|████▌     | 5/11 [00:05<00:06,  1.16s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:  45%|████▌     | 5/11 [00:05<00:07,  1.17s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  64%|██████▎   | 7/11 [00:08<00:05,  1.31s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:  64%|██████▎   | 7/11 [00:08<00:05,  1.32s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:  64%|██████▎   | 7/11 [00:08<00:05,  1.32s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:  64%|██████▎   | 7/11 [00:08<00:05,  1.32s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=35.0640, avg_loss=35.0640]Epoch 34:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=32.8083, avg_loss=32.8083]Epoch 34:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=37.6089, avg_loss=37.6089]Epoch 34:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=33.1950, avg_loss=33.1950]Epoch 34:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.6512, avg_loss=35.2147]Epoch 34:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=32.7942, avg_loss=35.3902]Epoch 34: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=35.6512, avg_loss=35.2147]Epoch 34: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=32.7942, avg_loss=35.3902]Epoch 34: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=35.6512, avg_loss=35.2147]
Epoch 34: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=32.7942, avg_loss=35.3902]
INFO:__main__:=== EPOCH 34 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.214683
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 34 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 22.682923
INFO:__main__:   • gene_density: 1.187914
INFO:__main__:🔢 Total Loss: 35.390150
INFO:__main__:   • operon_membership: 11.343846
INFO:__main__:👥 Samples processed: 22
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 22.368738
INFO:__main__:   • gene_density: 1.184245
INFO:__main__:   • operon_membership: 11.837168
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 34:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=38.4309, avg_loss=36.7815]Epoch 34: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=38.4309, avg_loss=36.7815]Epoch 34: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.4309, avg_loss=36.7815]
INFO:__main__:=== EPOCH 34 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.781503
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.736817
INFO:__main__:   • gene_density: 1.198686
INFO:__main__:   • operon_membership: 11.845999
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 34:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=38.9985, avg_loss=35.6719]Epoch 34: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=38.9985, avg_loss=35.6719]Epoch 34: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.9985, avg_loss=35.6719]
INFO:__main__:=== EPOCH 34 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.671860
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.912697
INFO:__main__:   • gene_density: 1.161281
INFO:__main__:   • operon_membership: 11.597882
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 35/681
INFO:__main__:Epoch 35/681
INFO:__main__:Epoch 35/681
INFO:__main__:Epoch 35/681
Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 35:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 35:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5425, avg_loss=36.5425]Epoch 35:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1983, avg_loss=37.1983]Epoch 35:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4049, avg_loss=34.4049]Epoch 35:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.6895, avg_loss=39.6895]Epoch 35:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  27%|██▋       | 3/11 [00:04<00:11,  1.41s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:  27%|██▋       | 3/11 [00:04<00:11,  1.41s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:  27%|██▋       | 3/11 [00:04<00:11,  1.41s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:  27%|██▋       | 3/11 [00:04<00:11,  1.41s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  45%|████▌     | 5/11 [00:06<00:06,  1.17s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:  45%|████▌     | 5/11 [00:06<00:06,  1.17s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:  45%|████▌     | 5/11 [00:06<00:06,  1.16s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  45%|████▌     | 5/11 [00:06<00:07,  1.17s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:  55%|█████▍    | 6/11 [00:07<00:05,  1.14s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  64%|██████▎   | 7/11 [00:08<00:04,  1.23s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:  64%|██████▎   | 7/11 [00:08<00:04,  1.23s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:  64%|██████▎   | 7/11 [00:08<00:04,  1.23s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:  64%|██████▎   | 7/11 [00:08<00:04,  1.24s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:  73%|███████▎  | 8/11 [00:10<00:03,  1.31s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=34.4049, avg_loss=34.4049]Epoch 35:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=37.1983, avg_loss=37.1983]Epoch 35:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=36.5425, avg_loss=36.5425]Epoch 35:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=39.6895, avg_loss=39.6895]Epoch 35:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.0509, avg_loss=35.6430]Epoch 35:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.2309, avg_loss=35.3476]Epoch 35: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=35.0509, avg_loss=35.6430]Epoch 35: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=35.2309, avg_loss=35.3476]Epoch 35: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.0509, avg_loss=35.6430]Epoch 35: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.2309, avg_loss=35.3476]

INFO:__main__:=== EPOCH 35 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 35 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.642965
INFO:__main__:🔢 Total Loss: 35.347643
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.627181
INFO:__main__:   • gene_expression: 22.239535
INFO:__main__:   • gene_density: 1.196141
INFO:__main__:   • gene_density: 1.178741
INFO:__main__:   • operon_membership: 11.819643
INFO:__main__:   • operon_membership: 11.929368
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 35:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=34.0677, avg_loss=35.2758]Epoch 35: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=34.0677, avg_loss=35.2758]Epoch 35: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.0677, avg_loss=35.2758]
INFO:__main__:=== EPOCH 35 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.275767
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.717591
INFO:__main__:   • gene_density: 1.183535
INFO:__main__:   • operon_membership: 11.374641
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 35:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=41.2885, avg_loss=36.7986]Epoch 35: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=41.2885, avg_loss=36.7986]Epoch 35: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=41.2885, avg_loss=36.7986]
INFO:__main__:=== EPOCH 35 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.798554
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.112385
INFO:__main__:   • gene_density: 1.173828
INFO:__main__:   • operon_membership: 11.512341
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.26it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.60it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.59it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.59it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.59it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]

Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]
INFO:__main__:=== EPOCH 35 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 35 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 35 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]
INFO:__main__:=== EPOCH 35 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 36/681
INFO:__main__:Epoch 36/681
INFO:__main__:Epoch 36/681
INFO:__main__:Epoch 36/681
Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 36:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 36:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0146, avg_loss=33.0146]Epoch 36:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6925, avg_loss=33.6925]Epoch 36:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.8137, avg_loss=37.8137]Epoch 36:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0831, avg_loss=35.0831]Epoch 36:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:  45%|████▌     | 5/11 [00:06<00:06,  1.09s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:  45%|████▌     | 5/11 [00:06<00:06,  1.09s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:  45%|████▌     | 5/11 [00:06<00:06,  1.09s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:  45%|████▌     | 5/11 [00:06<00:06,  1.09s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:  55%|█████▍    | 6/11 [00:07<00:06,  1.22s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:  55%|█████▍    | 6/11 [00:07<00:06,  1.22s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  73%|███████▎  | 8/11 [00:10<00:04,  1.33s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:  73%|███████▎  | 8/11 [00:10<00:03,  1.33s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:  73%|███████▎  | 8/11 [00:10<00:04,  1.33s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:  73%|███████▎  | 8/11 [00:10<00:03,  1.33s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  82%|████████▏ | 9/11 [00:11<00:02,  1.37s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:  82%|████████▏ | 9/11 [00:11<00:02,  1.37s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:  82%|████████▏ | 9/11 [00:11<00:02,  1.37s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:  82%|████████▏ | 9/11 [00:11<00:02,  1.37s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=33.6925, avg_loss=33.6925]Epoch 36:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=33.0146, avg_loss=33.0146]Epoch 36:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=37.8137, avg_loss=37.8137]Epoch 36:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=35.0831, avg_loss=35.0831]Epoch 36:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=35.6612, avg_loss=34.8877]Epoch 36:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=37.6421, avg_loss=35.6491]Epoch 36: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=35.6612, avg_loss=34.8877]Epoch 36: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=37.6421, avg_loss=35.6491]Epoch 36: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.6421, avg_loss=35.6491]Epoch 36: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.6612, avg_loss=34.8877]

INFO:__main__:=== EPOCH 36 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 36 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.649054
INFO:__main__:🔢 Total Loss: 34.887678
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.969670
INFO:__main__:   • gene_expression: 21.801842
INFO:__main__:   • gene_density: 1.185724
INFO:__main__:   • gene_density: 1.179865
INFO:__main__:   • operon_membership: 11.493660
INFO:__main__:   • operon_membership: 11.905971
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 36:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=32.5824, avg_loss=35.8498]Epoch 36: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=32.5824, avg_loss=35.8498]Epoch 36: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=32.5824, avg_loss=35.8498]
INFO:__main__:=== EPOCH 36 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.849828
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.222423
INFO:__main__:   • gene_density: 1.184422
INFO:__main__:   • operon_membership: 11.442982
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 36:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=33.8672, avg_loss=36.4829]Epoch 36: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=33.8672, avg_loss=36.4829]Epoch 36: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=33.8672, avg_loss=36.4829]
INFO:__main__:=== EPOCH 36 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.482855
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.644134
INFO:__main__:   • gene_density: 1.183179
INFO:__main__:   • operon_membership: 11.655542
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 37/681
INFO:__main__:Epoch 37/681
INFO:__main__:Epoch 37/681
INFO:__main__:Epoch 37/681
Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 37:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 37:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9414, avg_loss=35.9414]Epoch 37:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.8906, avg_loss=38.8906]Epoch 37:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5898, avg_loss=34.5898]Epoch 37:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0267, avg_loss=35.0267]Epoch 37:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:  55%|█████▍    | 6/11 [00:07<00:05,  1.15s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:  64%|██████▎   | 7/11 [00:08<00:04,  1.06s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:  64%|██████▎   | 7/11 [00:08<00:04,  1.06s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:  64%|██████▎   | 7/11 [00:08<00:04,  1.06s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:  64%|██████▎   | 7/11 [00:08<00:04,  1.07s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  73%|███████▎  | 8/11 [00:10<00:03,  1.20s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:  73%|███████▎  | 8/11 [00:10<00:03,  1.20s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:  73%|███████▎  | 8/11 [00:10<00:03,  1.20s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:  73%|███████▎  | 8/11 [00:10<00:03,  1.20s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  82%|████████▏ | 9/11 [00:11<00:02,  1.28s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:  82%|████████▏ | 9/11 [00:11<00:02,  1.28s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:  82%|████████▏ | 9/11 [00:11<00:02,  1.28s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:  82%|████████▏ | 9/11 [00:11<00:02,  1.28s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  91%|█████████ | 10/11 [00:13<00:01,  1.33s/it, loss=34.5898, avg_loss=34.5898]Epoch 37:  91%|█████████ | 10/11 [00:13<00:01,  1.33s/it, loss=35.9414, avg_loss=35.9414]Epoch 37:  91%|█████████ | 10/11 [00:13<00:01,  1.33s/it, loss=38.8906, avg_loss=38.8906]Epoch 37:  91%|█████████ | 10/11 [00:13<00:01,  1.33s/it, loss=35.0267, avg_loss=35.0267]Epoch 37:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=35.3312, avg_loss=35.5113]Epoch 37: 100%|██████████| 11/11 [00:14<00:00,  1.41s/it, loss=35.3312, avg_loss=35.5113]Epoch 37:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=34.0196, avg_loss=35.3744]Epoch 37: 100%|██████████| 11/11 [00:14<00:00,  1.41s/it, loss=34.0196, avg_loss=35.3744]Epoch 37: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=35.3312, avg_loss=35.5113]
Epoch 37: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=34.0196, avg_loss=35.3744]
Epoch 37:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=36.3873, avg_loss=36.0712]Epoch 37: 100%|██████████| 11/11 [00:14<00:00,  1.41s/it, loss=36.3873, avg_loss=36.0712]Epoch 37: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=36.3873, avg_loss=36.0712]
INFO:__main__:=== EPOCH 37 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.511280
INFO:__main__:=== EPOCH 37 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.248355
INFO:__main__:🔢 Total Loss: 35.374390
INFO:__main__:   • gene_density: 1.182588
INFO:__main__:   • operon_membership: 12.080337
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_expression: 23.518589
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.197443
INFO:__main__:   • operon_membership: 10.658357
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 37 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.071227
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.879950
INFO:__main__:   • gene_density: 1.150983
INFO:__main__:   • operon_membership: 12.040295
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 37:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=33.9397, avg_loss=36.0764]Epoch 37: 100%|██████████| 11/11 [00:14<00:00,  1.41s/it, loss=33.9397, avg_loss=36.0764]Epoch 37: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=33.9397, avg_loss=36.0764]
INFO:__main__:=== EPOCH 37 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.076374
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.973627
INFO:__main__:   • gene_density: 1.200521
INFO:__main__:   • operon_membership: 11.902226
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 38/681
INFO:__main__:Epoch 38/681
INFO:__main__:Epoch 38/681
INFO:__main__:Epoch 38/681
Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 38:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 38:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5833, avg_loss=36.5833]Epoch 38:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3966, avg_loss=34.3966]Epoch 38:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0116, avg_loss=36.0116]Epoch 38:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.7463, avg_loss=31.7463]Epoch 38:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  64%|██████▎   | 7/11 [00:09<00:05,  1.27s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:  64%|██████▎   | 7/11 [00:09<00:05,  1.27s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:  64%|██████▎   | 7/11 [00:09<00:05,  1.28s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:  64%|██████▎   | 7/11 [00:09<00:05,  1.27s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:  82%|████████▏ | 9/11 [00:11<00:02,  1.07s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:  82%|████████▏ | 9/11 [00:11<00:02,  1.07s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:  82%|████████▏ | 9/11 [00:11<00:02,  1.07s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:  82%|████████▏ | 9/11 [00:11<00:02,  1.07s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  91%|█████████ | 10/11 [00:12<00:01,  1.18s/it, loss=34.3966, avg_loss=34.3966]Epoch 38:  91%|█████████ | 10/11 [00:12<00:01,  1.19s/it, loss=36.0116, avg_loss=36.0116]Epoch 38:  91%|█████████ | 10/11 [00:12<00:01,  1.18s/it, loss=36.5833, avg_loss=36.5833]Epoch 38:  91%|█████████ | 10/11 [00:12<00:01,  1.19s/it, loss=31.7463, avg_loss=31.7463]Epoch 38:  91%|█████████ | 10/11 [00:14<00:01,  1.18s/it, loss=36.7942, avg_loss=35.4560]Epoch 38: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=36.7942, avg_loss=35.4560]Epoch 38: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.7942, avg_loss=35.4560]
INFO:__main__:=== EPOCH 38 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.455989
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.466669
INFO:__main__:   • gene_density: 1.177675
INFO:__main__:   • operon_membership: 11.811644
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 38:  91%|█████████ | 10/11 [00:14<00:01,  1.18s/it, loss=33.2497, avg_loss=35.4807]Epoch 38:  91%|█████████ | 10/11 [00:14<00:01,  1.19s/it, loss=30.9960, avg_loss=36.0664]Epoch 38: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=33.2497, avg_loss=35.4807]Epoch 38: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=30.9960, avg_loss=36.0664]Epoch 38: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=33.2497, avg_loss=35.4807]
Epoch 38: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=30.9960, avg_loss=36.0664]
INFO:__main__:=== EPOCH 38 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.480722
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 38 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 22.181692
INFO:__main__:   • gene_density: 1.191643
INFO:__main__:🔢 Total Loss: 36.066374
INFO:__main__:   • operon_membership: 12.107387
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_expression: 23.707073
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.167673
INFO:__main__:   • operon_membership: 11.191629
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 38:  91%|█████████ | 10/11 [00:14<00:01,  1.19s/it, loss=36.5938, avg_loss=35.9122]Epoch 38: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=36.5938, avg_loss=35.9122]Epoch 38: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.5938, avg_loss=35.9122]
INFO:__main__:=== EPOCH 38 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.912171
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.049774
INFO:__main__:   • gene_density: 1.196082
INFO:__main__:   • operon_membership: 11.666316
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 39/681
INFO:__main__:Epoch 39/681
INFO:__main__:Epoch 39/681
INFO:__main__:Epoch 39/681
Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 39:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 39:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.3950, avg_loss=36.3950]Epoch 39:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.3132, avg_loss=38.3132]Epoch 39:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.4544, avg_loss=31.4544]Epoch 39:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.2671, avg_loss=36.2671]Epoch 39:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:  73%|███████▎  | 8/11 [00:11<00:04,  1.38s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:  73%|███████▎  | 8/11 [00:11<00:04,  1.38s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=31.4544, avg_loss=31.4544]Epoch 39:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=36.3950, avg_loss=36.3950]Epoch 39:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=36.2671, avg_loss=36.2671]Epoch 39:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=38.3132, avg_loss=38.3132]Epoch 39:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=33.4253, avg_loss=36.0556]Epoch 39: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=33.4253, avg_loss=36.0556]Epoch 39:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=37.5629, avg_loss=35.6735]Epoch 39: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=33.4253, avg_loss=36.0556]
Epoch 39: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=37.5629, avg_loss=35.6735]Epoch 39: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=37.5629, avg_loss=35.6735]
INFO:__main__:=== EPOCH 39 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.055641
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.100442
INFO:__main__:   • gene_density: 1.185724
INFO:__main__:   • operon_membership: 11.769474
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 39 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.673537
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.668702
INFO:__main__:   • gene_density: 1.194070
INFO:__main__:   • operon_membership: 11.810765
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 39:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=38.8465, avg_loss=35.9963]Epoch 39: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=38.8465, avg_loss=35.9963]Epoch 39: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.8465, avg_loss=35.9963]
INFO:__main__:=== EPOCH 39 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.996288
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.333696
INFO:__main__:   • gene_density: 1.165187
INFO:__main__:   • operon_membership: 11.497405
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 39:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=32.7423, avg_loss=35.2767]Epoch 39: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=32.7423, avg_loss=35.2767]Epoch 39: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=32.7423, avg_loss=35.2767]
INFO:__main__:=== EPOCH 39 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.276669
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.491926
INFO:__main__:   • gene_density: 1.184363
INFO:__main__:   • operon_membership: 11.600379
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 40/681
INFO:__main__:Epoch 40/681
INFO:__main__:Epoch 40/681
INFO:__main__:Epoch 40/681
Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 40:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 40:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0072, avg_loss=34.0072]Epoch 40:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4813, avg_loss=35.4813]Epoch 40:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.8905, avg_loss=34.8905]Epoch 40:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.4025, avg_loss=32.4025]Epoch 40:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.4813, avg_loss=35.4813]Epoch 40:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=34.0072, avg_loss=34.0072]Epoch 40:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=34.8905, avg_loss=34.8905]Epoch 40:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=32.4025, avg_loss=32.4025]Epoch 40:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=36.6205, avg_loss=36.7595]Epoch 40: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=36.6205, avg_loss=36.7595]Epoch 40:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=34.6834, avg_loss=35.9031]Epoch 40: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=34.6834, avg_loss=35.9031]Epoch 40: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=36.6205, avg_loss=36.7595]
Epoch 40: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=34.6834, avg_loss=35.9031]
INFO:__main__:=== EPOCH 40 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.759480
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.012299
INFO:__main__:   • gene_density: 1.180279
INFO:__main__:=== EPOCH 40 TRAINING LOSSES ===
INFO:__main__:   • operon_membership: 11.566902
INFO:__main__:👥 Samples processed: 22
INFO:__main__:🔢 Total Loss: 35.903091
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.154014
INFO:__main__:   • gene_density: 1.189157
INFO:__main__:   • operon_membership: 11.559920
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 40:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=34.5163, avg_loss=34.7050]Epoch 40: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=34.5163, avg_loss=34.7050]Epoch 40: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=34.5163, avg_loss=34.7050]
Epoch 40:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=33.3065, avg_loss=35.7865]Epoch 40: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.3065, avg_loss=35.7865]Epoch 40: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=33.3065, avg_loss=35.7865]
INFO:__main__:=== EPOCH 40 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.705010
INFO:__main__:📊 Individual Modality Losses:
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:   • gene_expression: 21.098782
INFO:__main__:   • gene_density: 1.185665
INFO:__main__:   • operon_membership: 12.420562
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 40 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.786529
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.513973
INFO:__main__:   • gene_density: 1.178445
INFO:__main__:   • operon_membership: 11.094111
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.74it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.74it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.75it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.75it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.31it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.31it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.32it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.32it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.61it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  1.99it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  1.99it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  1.99it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.09it/s]
INFO:__main__:=== EPOCH 40 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 40 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:=== EPOCH 40 VALIDATION LOSSES ===
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:01<00:00,  1.96it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.06it/s]
INFO:__main__:=== EPOCH 40 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_40.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_40.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_40.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_40.pt
INFO:__main__:Epoch 41/681
INFO:__main__:Epoch 41/681
INFO:__main__:Epoch 41/681
INFO:__main__:Epoch 41/681
Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 41:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 41:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.7678, avg_loss=33.7678]Epoch 41:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.7943, avg_loss=32.7943]Epoch 41:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3434, avg_loss=34.3434]Epoch 41:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7064, avg_loss=37.7064]Epoch 41:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  45%|████▌     | 5/11 [00:07<00:08,  1.35s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:  45%|████▌     | 5/11 [00:07<00:08,  1.35s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:  45%|████▌     | 5/11 [00:07<00:08,  1.35s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:  45%|████▌     | 5/11 [00:07<00:08,  1.35s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  55%|█████▍    | 6/11 [00:08<00:06,  1.22s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  55%|█████▍    | 6/11 [00:08<00:06,  1.22s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:  55%|█████▍    | 6/11 [00:08<00:06,  1.22s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:  55%|█████▍    | 6/11 [00:08<00:06,  1.22s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:  64%|██████▎   | 7/11 [00:09<00:04,  1.11s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:  64%|██████▎   | 7/11 [00:09<00:04,  1.11s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:  64%|██████▎   | 7/11 [00:09<00:04,  1.11s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:  64%|██████▎   | 7/11 [00:09<00:04,  1.12s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  73%|███████▎  | 8/11 [00:10<00:03,  1.23s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:  73%|███████▎  | 8/11 [00:10<00:03,  1.23s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:  73%|███████▎  | 8/11 [00:10<00:03,  1.23s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:  73%|███████▎  | 8/11 [00:10<00:03,  1.23s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  82%|████████▏ | 9/11 [00:11<00:02,  1.30s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:  82%|████████▏ | 9/11 [00:11<00:02,  1.30s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:  82%|████████▏ | 9/11 [00:11<00:02,  1.30s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:  82%|████████▏ | 9/11 [00:11<00:02,  1.30s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  91%|█████████ | 10/11 [00:13<00:01,  1.34s/it, loss=33.7678, avg_loss=33.7678]Epoch 41:  91%|█████████ | 10/11 [00:13<00:01,  1.34s/it, loss=32.7943, avg_loss=32.7943]Epoch 41:  91%|█████████ | 10/11 [00:13<00:01,  1.35s/it, loss=34.3434, avg_loss=34.3434]Epoch 41:  91%|█████████ | 10/11 [00:13<00:01,  1.35s/it, loss=37.7064, avg_loss=37.7064]Epoch 41:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=34.1811, avg_loss=35.2297]Epoch 41: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=34.1811, avg_loss=35.2297]Epoch 41: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.1811, avg_loss=35.2297]
INFO:__main__:=== EPOCH 41 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.229704
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.845524
INFO:__main__:   • gene_density: 1.204013
INFO:__main__:   • operon_membership: 12.180167
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 41:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=38.5530, avg_loss=36.6246]Epoch 41: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=38.5530, avg_loss=36.6246]Epoch 41:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=34.9637, avg_loss=35.6983]Epoch 41: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=34.9637, avg_loss=35.6983]Epoch 41: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=38.5530, avg_loss=36.6246]
Epoch 41: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.9637, avg_loss=35.6983]
INFO:__main__:=== EPOCH 41 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.624584
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.173070
INFO:__main__:   • gene_density: 1.166667
INFO:__main__:   • operon_membership: 11.284846
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 41 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.698283
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.487157
INFO:__main__:   • gene_density: 1.183594
INFO:__main__:   • operon_membership: 12.027533
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 41:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=33.7393, avg_loss=35.7411]Epoch 41: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=33.7393, avg_loss=35.7411]Epoch 41: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=33.7393, avg_loss=35.7411]
INFO:__main__:=== EPOCH 41 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.741079
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.428452
INFO:__main__:   • gene_density: 1.177734
INFO:__main__:   • operon_membership: 11.134894
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 42/681
INFO:__main__:Epoch 42/681
INFO:__main__:Epoch 42/681
INFO:__main__:Epoch 42/681
Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 42:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 42:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.5809, avg_loss=33.5809]Epoch 42:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.2320, avg_loss=36.2320]Epoch 42:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7983, avg_loss=35.7983]Epoch 42:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7055, avg_loss=35.7055]Epoch 42:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  55%|█████▍    | 6/11 [00:08<00:06,  1.37s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:  55%|█████▍    | 6/11 [00:08<00:06,  1.37s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:  55%|█████▍    | 6/11 [00:08<00:06,  1.37s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:  55%|█████▍    | 6/11 [00:08<00:06,  1.37s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  64%|██████▎   | 7/11 [00:09<00:05,  1.27s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  64%|██████▎   | 7/11 [00:09<00:05,  1.28s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:  64%|██████▎   | 7/11 [00:09<00:05,  1.28s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:  64%|██████▎   | 7/11 [00:09<00:05,  1.28s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:  73%|███████▎  | 8/11 [00:10<00:03,  1.13s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:  82%|████████▏ | 9/11 [00:11<00:02,  1.17s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:  82%|████████▏ | 9/11 [00:11<00:02,  1.17s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:  82%|████████▏ | 9/11 [00:11<00:02,  1.17s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:  82%|████████▏ | 9/11 [00:11<00:02,  1.18s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  91%|█████████ | 10/11 [00:13<00:01,  1.25s/it, loss=33.5809, avg_loss=33.5809]Epoch 42:  91%|█████████ | 10/11 [00:13<00:01,  1.25s/it, loss=36.2320, avg_loss=36.2320]Epoch 42:  91%|█████████ | 10/11 [00:13<00:01,  1.25s/it, loss=35.7983, avg_loss=35.7983]Epoch 42:  91%|█████████ | 10/11 [00:13<00:01,  1.26s/it, loss=35.7055, avg_loss=35.7055]Epoch 42:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=38.1562, avg_loss=36.4248]Epoch 42: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=38.1562, avg_loss=36.4248]Epoch 42: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=38.1562, avg_loss=36.4248]
INFO:__main__:=== EPOCH 42 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.424787
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.941085
INFO:__main__:   • gene_density: 1.191643
INFO:__main__:   • operon_membership: 11.292059
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 42:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=38.2772, avg_loss=36.1902]Epoch 42: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=38.2772, avg_loss=36.1902]Epoch 42:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=36.4889, avg_loss=34.7659]Epoch 42: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=36.4889, avg_loss=34.7659]Epoch 42: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=38.2772, avg_loss=36.1902]
Epoch 42: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=36.4889, avg_loss=34.7659]
INFO:__main__:=== EPOCH 42 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.190164
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.820845
INFO:__main__:   • gene_density: 1.190400
INFO:__main__:   • operon_membership: 12.178918
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 42 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.765914
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.281738
INFO:__main__:   • gene_density: 1.172881
INFO:__main__:   • operon_membership: 11.311294
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 42:  91%|█████████ | 10/11 [00:14<00:01,  1.26s/it, loss=39.0267, avg_loss=35.5093]Epoch 42: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=39.0267, avg_loss=35.5093]Epoch 42: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=39.0267, avg_loss=35.5093]
INFO:__main__:=== EPOCH 42 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.509280
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.446426
INFO:__main__:   • gene_density: 1.178800
INFO:__main__:   • operon_membership: 11.884054
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 43/681
INFO:__main__:Epoch 43/681
INFO:__main__:Epoch 43/681
INFO:__main__:Epoch 43/681
Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 43:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 43:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5776, avg_loss=37.5776]Epoch 43:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6010, avg_loss=33.6010]Epoch 43:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4238, avg_loss=35.4238]Epoch 43:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.0850, avg_loss=32.0850]Epoch 43:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=32.0850, avg_loss=32.0850]Epoch 43:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=33.6010, avg_loss=33.6010]Epoch 43:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=35.4238, avg_loss=35.4238]Epoch 43:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=37.5776, avg_loss=37.5776]Epoch 43:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=37.3851, avg_loss=36.6966]Epoch 43:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=34.3580, avg_loss=34.5054]Epoch 43: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=37.3851, avg_loss=36.6966]Epoch 43: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=34.3580, avg_loss=34.5054]Epoch 43: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.3851, avg_loss=36.6966]
Epoch 43: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.3580, avg_loss=34.5054]
INFO:__main__:=== EPOCH 43 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 43 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.696569
INFO:__main__:🔢 Total Loss: 34.505356
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.262206
INFO:__main__:   • gene_expression: 21.534906
INFO:__main__:   • gene_density: 1.181700
INFO:__main__:   • gene_density: 1.171106
INFO:__main__:   • operon_membership: 11.252664
INFO:__main__:   • operon_membership: 11.799344
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 43:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=36.9547, avg_loss=36.1512]Epoch 43: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=36.9547, avg_loss=36.1512]Epoch 43: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=36.9547, avg_loss=36.1512]
INFO:__main__:=== EPOCH 43 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.151206
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.316629
INFO:__main__:   • gene_density: 1.192768
INFO:__main__:   • operon_membership: 11.641809
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 43:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=37.9398, avg_loss=35.6461]Epoch 43: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=37.9398, avg_loss=35.6461]Epoch 43: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.9398, avg_loss=35.6461]
INFO:__main__:=== EPOCH 43 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.646096
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.436352
INFO:__main__:   • gene_density: 1.187204
INFO:__main__:   • operon_membership: 12.022539
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 44/681
INFO:__main__:Epoch 44/681
INFO:__main__:Epoch 44/681
INFO:__main__:Epoch 44/681
Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 44:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 44:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9072, avg_loss=35.9072]Epoch 44:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5250, avg_loss=34.5250]Epoch 44:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7103, avg_loss=35.7103]Epoch 44:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.7145, avg_loss=32.7145]Epoch 44:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=35.7103, avg_loss=35.7103]Epoch 44:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=35.9072, avg_loss=35.9072]Epoch 44:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=34.5250, avg_loss=34.5250]Epoch 44:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=32.7145, avg_loss=32.7145]Epoch 44:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=39.8219, avg_loss=35.3071]Epoch 44: 100%|██████████| 11/11 [00:15<00:00,  1.21s/it, loss=39.8219, avg_loss=35.3071]Epoch 44: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=39.8219, avg_loss=35.3071]
INFO:__main__:=== EPOCH 44 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.307097
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.699773
INFO:__main__:   • gene_density: 1.185843
INFO:__main__:   • operon_membership: 11.421481
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 44:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=41.0618, avg_loss=36.0566]Epoch 44: 100%|██████████| 11/11 [00:15<00:00,  1.21s/it, loss=41.0618, avg_loss=36.0566]Epoch 44:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=37.9629, avg_loss=35.5403]Epoch 44: 100%|██████████| 11/11 [00:15<00:00,  1.21s/it, loss=37.9629, avg_loss=35.5403]Epoch 44: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=41.0618, avg_loss=36.0566]
Epoch 44: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=37.9629, avg_loss=35.5403]
INFO:__main__:=== EPOCH 44 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.056588
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.537261
INFO:__main__:   • gene_density: 1.176728
INFO:__main__:   • operon_membership: 11.342598
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 44 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.540277
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.918583
INFO:__main__:   • gene_density: 1.188092
INFO:__main__:   • operon_membership: 12.433602
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 44:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=37.4429, avg_loss=35.9623]Epoch 44: 100%|██████████| 11/11 [00:15<00:00,  1.21s/it, loss=37.4429, avg_loss=35.9623]Epoch 44: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=37.4429, avg_loss=35.9623]
INFO:__main__:=== EPOCH 44 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.962348
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.212000
INFO:__main__:   • gene_density: 1.181226
INFO:__main__:   • operon_membership: 11.569122
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 45/681
INFO:__main__:Epoch 45/681
INFO:__main__:Epoch 45/681
INFO:__main__:Epoch 45/681
Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 45:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 45:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1621, avg_loss=35.1621]Epoch 45:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6810, avg_loss=32.6810]Epoch 45:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.9629, avg_loss=37.9629]Epoch 45:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8230, avg_loss=33.8230]Epoch 45:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:  82%|████████▏ | 9/11 [00:13<00:02,  1.47s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:  82%|████████▏ | 9/11 [00:13<00:02,  1.47s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.1621, avg_loss=35.1621]Epoch 45:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=37.9629, avg_loss=37.9629]Epoch 45:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=32.6810, avg_loss=32.6810]Epoch 45:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=33.8230, avg_loss=33.8230]Epoch 45:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=37.4320, avg_loss=35.1646]Epoch 45:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=35.1640, avg_loss=36.1908]Epoch 45:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=36.4748, avg_loss=36.1798]Epoch 45:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=33.7169, avg_loss=35.7268]Epoch 45: 100%|██████████| 11/11 [00:15<00:00,  1.32s/it, loss=37.4320, avg_loss=35.1646]Epoch 45: 100%|██████████| 11/11 [00:15<00:00,  1.32s/it, loss=35.1640, avg_loss=36.1908]Epoch 45: 100%|██████████| 11/11 [00:15<00:00,  1.32s/it, loss=36.4748, avg_loss=36.1798]Epoch 45: 100%|██████████| 11/11 [00:15<00:00,  1.32s/it, loss=33.7169, avg_loss=35.7268]Epoch 45: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=37.4320, avg_loss=35.1646]Epoch 45: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=36.4748, avg_loss=36.1798]Epoch 45: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=35.1640, avg_loss=36.1908]


Epoch 45: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=33.7169, avg_loss=35.7268]
INFO:__main__:=== EPOCH 45 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 45 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 45 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 45 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.179819
INFO:__main__:🔢 Total Loss: 35.164597
INFO:__main__:🔢 Total Loss: 35.726771
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 36.190774
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.066635
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.147540
INFO:__main__:   • gene_expression: 23.447389
INFO:__main__:   • gene_density: 1.173828
INFO:__main__:   • gene_expression: 23.122897
INFO:__main__:   • gene_density: 1.194780
INFO:__main__:   • gene_density: 1.173295
INFO:__main__:   • operon_membership: 11.939355
INFO:__main__:   • gene_density: 1.188447
INFO:__main__:   • operon_membership: 11.822279
INFO:__main__:   • operon_membership: 11.106087
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.879430
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.77it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.77it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.77it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.77it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.27it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.27it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.27it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.19it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.96it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.96it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.96it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.93it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.78it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.78it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.78it/s]
INFO:__main__:=== EPOCH 45 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 45 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 45 VALIDATION LOSSES ===
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.65it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.76it/s]
INFO:__main__:=== EPOCH 45 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 46/681
INFO:__main__:Epoch 46/681
INFO:__main__:Epoch 46/681
INFO:__main__:Epoch 46/681
Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 46:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 46:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.8160, avg_loss=37.8160]Epoch 46:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5760, avg_loss=35.5760]Epoch 46:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6712, avg_loss=32.6712]Epoch 46:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.8894, avg_loss=37.8894]Epoch 46:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=37.8894, avg_loss=37.8894]Epoch 46:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=37.8160, avg_loss=37.8160]Epoch 46:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=35.5760, avg_loss=35.5760]Epoch 46:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=32.6712, avg_loss=32.6712]Epoch 46:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=34.1294, avg_loss=34.7646]Epoch 46:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=37.6105, avg_loss=36.1601]Epoch 46:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=37.6217, avg_loss=37.0827]Epoch 46: 100%|██████████| 11/11 [00:15<00:00,  1.20s/it, loss=34.1294, avg_loss=34.7646]Epoch 46: 100%|██████████| 11/11 [00:15<00:00,  1.21s/it, loss=37.6105, avg_loss=36.1601]Epoch 46: 100%|██████████| 11/11 [00:15<00:00,  1.20s/it, loss=37.6217, avg_loss=37.0827]Epoch 46: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=34.1294, avg_loss=34.7646]Epoch 46: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.6105, avg_loss=36.1601]
Epoch 46: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.6217, avg_loss=37.0827]

INFO:__main__:=== EPOCH 46 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 46 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 46 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 37.082686
INFO:__main__:🔢 Total Loss: 34.764612
INFO:__main__:🔢 Total Loss: 36.160116
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.056006
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.827393
INFO:__main__:   • gene_density: 1.176196
INFO:__main__:   • gene_expression: 23.245056
INFO:__main__:   • gene_density: 1.192945
INFO:__main__:   • operon_membership: 11.850485
INFO:__main__:   • gene_density: 1.182114
INFO:__main__:   • operon_membership: 11.744274
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.732946
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 46:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=38.4340, avg_loss=35.0585]Epoch 46: 100%|██████████| 11/11 [00:15<00:00,  1.21s/it, loss=38.4340, avg_loss=35.0585]Epoch 46: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.4340, avg_loss=35.0585]
INFO:__main__:=== EPOCH 46 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.058529
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.599457
INFO:__main__:   • gene_density: 1.182410
INFO:__main__:   • operon_membership: 11.276661
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 47/681
INFO:__main__:Epoch 47/681
INFO:__main__:Epoch 47/681
INFO:__main__:Epoch 47/681
Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 47:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 47:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8076, avg_loss=33.8076]Epoch 47:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1236, avg_loss=35.1236]Epoch 47:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9376, avg_loss=35.9376]Epoch 47:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4748, avg_loss=36.4748]Epoch 47:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=33.8076, avg_loss=33.8076]Epoch 47:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=35.9376, avg_loss=35.9376]Epoch 47:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=35.1236, avg_loss=35.1236]Epoch 47:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=36.4748, avg_loss=36.4748]Epoch 47:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=34.1757, avg_loss=35.8680]Epoch 47: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=34.1757, avg_loss=35.8680]Epoch 47: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=34.1757, avg_loss=35.8680]
Epoch 47:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=38.9426, avg_loss=36.2147]Epoch 47:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=38.2243, avg_loss=36.3494]Epoch 47: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.9426, avg_loss=36.2147]Epoch 47: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.2243, avg_loss=36.3494]Epoch 47: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=38.9426, avg_loss=36.2147]
Epoch 47: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=38.2243, avg_loss=36.3494]
INFO:__main__:=== EPOCH 47 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.868021
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.775829
INFO:__main__:   • gene_density: 1.191170
INFO:__main__:   • operon_membership: 11.901024
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 47 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 47 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.214720
INFO:__main__:🔢 Total Loss: 36.349445
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.494590
INFO:__main__:   • gene_expression: 23.635274
INFO:__main__:   • gene_density: 1.176255
INFO:__main__:   • gene_density: 1.177971
INFO:__main__:   • operon_membership: 11.543875
INFO:__main__:   • operon_membership: 11.536200
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 47:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=33.4735, avg_loss=34.7196]Epoch 47: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.4735, avg_loss=34.7196]Epoch 47: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=33.4735, avg_loss=34.7196]
INFO:__main__:=== EPOCH 47 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.719624
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.860610
INFO:__main__:   • gene_density: 1.188861
INFO:__main__:   • operon_membership: 11.670153
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 48/681
INFO:__main__:Epoch 48/681
INFO:__main__:Epoch 48/681
INFO:__main__:Epoch 48/681
Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 48:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 48:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1216, avg_loss=38.1216]Epoch 48:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5136, avg_loss=37.5136]Epoch 48:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.5362, avg_loss=33.5362]Epoch 48:   9%|▉         | 1/11 [00:01<00:10,  1.10s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:   9%|▉         | 1/11 [00:01<00:10,  1.10s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9230, avg_loss=36.9230]Epoch 48:   9%|▉         | 1/11 [00:01<00:10,  1.10s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  18%|█▊        | 2/11 [00:02<00:11,  1.24s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:  18%|█▊        | 2/11 [00:02<00:11,  1.24s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:  18%|█▊        | 2/11 [00:02<00:11,  1.24s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  18%|█▊        | 2/11 [00:02<00:11,  1.25s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:  27%|██▋       | 3/11 [00:03<00:10,  1.33s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  27%|██▋       | 3/11 [00:03<00:10,  1.34s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:  27%|██▋       | 3/11 [00:03<00:10,  1.34s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:  27%|██▋       | 3/11 [00:03<00:10,  1.34s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:  36%|███▋      | 4/11 [00:05<00:09,  1.38s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  36%|███▋      | 4/11 [00:05<00:09,  1.38s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:  36%|███▋      | 4/11 [00:05<00:09,  1.38s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:  36%|███▋      | 4/11 [00:05<00:09,  1.38s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:  45%|████▌     | 5/11 [00:06<00:08,  1.40s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:  45%|████▌     | 5/11 [00:06<00:08,  1.41s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  45%|████▌     | 5/11 [00:06<00:08,  1.40s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:  45%|████▌     | 5/11 [00:06<00:08,  1.41s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=38.1216, avg_loss=38.1216]Epoch 48:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=36.9230, avg_loss=36.9230]Epoch 48:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=37.5136, avg_loss=37.5136]Epoch 48:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=33.5362, avg_loss=33.5362]Epoch 48:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=34.3992, avg_loss=35.8487]Epoch 48: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=34.3992, avg_loss=35.8487]Epoch 48:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=37.5006, avg_loss=35.8595]Epoch 48:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=38.8015, avg_loss=35.6812]Epoch 48: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=37.5006, avg_loss=35.8595]Epoch 48: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=38.8015, avg_loss=35.6812]Epoch 48: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=34.3992, avg_loss=35.8487]
Epoch 48: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.5006, avg_loss=35.8595]
Epoch 48: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=38.8015, avg_loss=35.6812]
INFO:__main__:=== EPOCH 48 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.848689
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.728083
INFO:__main__:   • gene_density: 1.201231
INFO:__main__:   • operon_membership: 10.919375
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 48 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.859520
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.558143
INFO:__main__:=== EPOCH 48 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.171934
INFO:__main__:   • operon_membership: 12.129443
INFO:__main__:🔢 Total Loss: 35.681155
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.948641
INFO:__main__:   • gene_density: 1.173473
INFO:__main__:   • operon_membership: 11.559042
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 48:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=38.3053, avg_loss=35.6706]Epoch 48: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=38.3053, avg_loss=35.6706]Epoch 48: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=38.3053, avg_loss=35.6706]
INFO:__main__:=== EPOCH 48 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.670601
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.619587
INFO:__main__:   • gene_density: 1.182173
INFO:__main__:   • operon_membership: 11.868841
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 49/681
INFO:__main__:Epoch 49/681
INFO:__main__:Epoch 49/681
INFO:__main__:Epoch 49/681
Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 49:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 49:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9317, avg_loss=33.9317]Epoch 49:   9%|▉         | 1/11 [00:01<00:13,  1.37s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.3415, avg_loss=33.3415]Epoch 49:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1518, avg_loss=36.1518]Epoch 49:   9%|▉         | 1/11 [00:01<00:13,  1.37s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:   9%|▉         | 1/11 [00:01<00:13,  1.37s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1353, avg_loss=35.1353]Epoch 49:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  18%|█▊        | 2/11 [00:02<00:10,  1.16s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  18%|█▊        | 2/11 [00:02<00:10,  1.16s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:  18%|█▊        | 2/11 [00:02<00:10,  1.16s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:  18%|█▊        | 2/11 [00:02<00:10,  1.16s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:  27%|██▋       | 3/11 [00:03<00:08,  1.01s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  27%|██▋       | 3/11 [00:03<00:08,  1.01s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:  27%|██▋       | 3/11 [00:03<00:08,  1.01s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:  27%|██▋       | 3/11 [00:03<00:08,  1.01s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:  36%|███▋      | 4/11 [00:04<00:08,  1.15s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:  36%|███▋      | 4/11 [00:04<00:08,  1.15s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:  36%|███▋      | 4/11 [00:04<00:08,  1.15s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:  36%|███▋      | 4/11 [00:04<00:08,  1.16s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:  55%|█████▍    | 6/11 [00:07<00:06,  1.34s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  64%|██████▎   | 7/11 [00:08<00:05,  1.38s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:  64%|██████▎   | 7/11 [00:08<00:05,  1.38s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:  64%|██████▎   | 7/11 [00:08<00:05,  1.38s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  82%|████████▏ | 9/11 [00:11<00:02,  1.43s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:  82%|████████▏ | 9/11 [00:11<00:02,  1.43s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:  82%|████████▏ | 9/11 [00:11<00:02,  1.43s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:  82%|████████▏ | 9/11 [00:11<00:02,  1.43s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=36.1518, avg_loss=36.1518]Epoch 49:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=33.3415, avg_loss=33.3415]Epoch 49:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=33.9317, avg_loss=33.9317]Epoch 49:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=35.1353, avg_loss=35.1353]Epoch 49:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=34.7475, avg_loss=35.2063]Epoch 49: 100%|██████████| 11/11 [00:15<00:00,  1.49s/it, loss=34.7475, avg_loss=35.2063]Epoch 49:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=32.9715, avg_loss=35.0435]Epoch 49: 100%|██████████| 11/11 [00:15<00:00,  1.49s/it, loss=32.9715, avg_loss=35.0435]Epoch 49: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.7475, avg_loss=35.2063]
Epoch 49: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=32.9715, avg_loss=35.0435]
Epoch 49:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=36.0611, avg_loss=36.8838]Epoch 49: 100%|██████████| 11/11 [00:15<00:00,  1.50s/it, loss=36.0611, avg_loss=36.8838]Epoch 49: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.0611, avg_loss=36.8838]
INFO:__main__:=== EPOCH 49 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 49 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.206316
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.043512
INFO:__main__:   • gene_expression: 22.543463
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.183712
INFO:__main__:   • gene_expression: 22.055585
INFO:__main__:   • operon_membership: 11.479141
INFO:__main__:   • gene_density: 1.174479
INFO:__main__:   • operon_membership: 11.813447
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 49 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.883780
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.114064
INFO:__main__:   • gene_density: 1.195786
INFO:__main__:   • operon_membership: 11.573931
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 49:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=36.3998, avg_loss=36.1284]Epoch 49: 100%|██████████| 11/11 [00:15<00:00,  1.49s/it, loss=36.3998, avg_loss=36.1284]Epoch 49: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.3998, avg_loss=36.1284]
INFO:__main__:=== EPOCH 49 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.128355
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.071350
INFO:__main__:   • gene_density: 1.176373
INFO:__main__:   • operon_membership: 11.880632
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 50/681
INFO:__main__:Epoch 50/681
INFO:__main__:Epoch 50/681
INFO:__main__:Epoch 50/681
Epoch 50:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 50:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 50:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 50:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 50:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.7383, avg_loss=34.7383]Epoch 50:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.1116, avg_loss=33.1116]Epoch 50:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7048, avg_loss=35.7048]Epoch 50:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6686, avg_loss=32.6686]Epoch 50:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  27%|██▋       | 3/11 [00:04<00:10,  1.27s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:  27%|██▋       | 3/11 [00:04<00:10,  1.27s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:  27%|██▋       | 3/11 [00:04<00:10,  1.27s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:  27%|██▋       | 3/11 [00:04<00:10,  1.27s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  36%|███▋      | 4/11 [00:04<00:07,  1.10s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:  36%|███▋      | 4/11 [00:04<00:07,  1.10s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:  36%|███▋      | 4/11 [00:04<00:07,  1.10s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:  36%|███▋      | 4/11 [00:04<00:07,  1.10s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:  55%|█████▍    | 6/11 [00:07<00:06,  1.26s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  64%|██████▎   | 7/11 [00:09<00:05,  1.32s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:  64%|██████▎   | 7/11 [00:09<00:05,  1.32s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:  64%|██████▎   | 7/11 [00:09<00:05,  1.32s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:  64%|██████▎   | 7/11 [00:09<00:05,  1.32s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=33.1116, avg_loss=33.1116]Epoch 50:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=34.7383, avg_loss=34.7383]Epoch 50:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=35.7048, avg_loss=35.7048]Epoch 50:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=32.6686, avg_loss=32.6686]Epoch 50:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=35.6723, avg_loss=35.8646]Epoch 50:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=35.8284, avg_loss=35.5790]Epoch 50:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=39.2202, avg_loss=36.0194]Epoch 50: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=35.6723, avg_loss=35.8646]Epoch 50: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=35.8284, avg_loss=35.5790]Epoch 50: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=39.2202, avg_loss=36.0194]Epoch 50: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.8284, avg_loss=35.5790]
Epoch 50: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=39.2202, avg_loss=36.0194]Epoch 50: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.6723, avg_loss=35.8646]

INFO:__main__:=== EPOCH 50 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 50 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.578951
INFO:__main__:🔢 Total Loss: 36.019432
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.748046
INFO:__main__:   • gene_expression: 22.379104
INFO:__main__:   • gene_density: 1.174716
INFO:__main__:   • gene_density: 1.179214
INFO:__main__:   • operon_membership: 11.656189
INFO:__main__:   • operon_membership: 12.461113
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 50 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.864552
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.283449
INFO:__main__:   • gene_density: 1.183712
INFO:__main__:   • operon_membership: 11.397391
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 50:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=34.7245, avg_loss=35.4813]Epoch 50: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=34.7245, avg_loss=35.4813]Epoch 50: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.7245, avg_loss=35.4813]
INFO:__main__:=== EPOCH 50 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.481286
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.293508
INFO:__main__:   • gene_density: 1.190814
INFO:__main__:   • operon_membership: 10.996963
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]


INFO:__main__:=== EPOCH 50 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 50 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:=== EPOCH 50 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]
INFO:__main__:=== EPOCH 50 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_50.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_50.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_50.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_50.pt
INFO:__main__:Epoch 51/681
INFO:__main__:Epoch 51/681
INFO:__main__:Epoch 51/681
INFO:__main__:Epoch 51/681
Epoch 51:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 51:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 51:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 51:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 51:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.6775, avg_loss=34.6775]Epoch 51:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.9729, avg_loss=38.9729]Epoch 51:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4255, avg_loss=36.4255]Epoch 51:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3271, avg_loss=35.3271]Epoch 51:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:  82%|████████▏ | 9/11 [00:12<00:02,  1.34s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=36.4255, avg_loss=36.4255]Epoch 51:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=34.6775, avg_loss=34.6775]Epoch 51:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=35.3271, avg_loss=35.3271]Epoch 51:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=38.9729, avg_loss=38.9729]Epoch 51:  91%|█████████ | 10/11 [00:15<00:01,  1.22s/it, loss=39.0296, avg_loss=36.0133]Epoch 51: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=39.0296, avg_loss=36.0133]Epoch 51:  91%|█████████ | 10/11 [00:15<00:01,  1.22s/it, loss=33.3443, avg_loss=35.7805]Epoch 51: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=33.3443, avg_loss=35.7805]Epoch 51:  91%|█████████ | 10/11 [00:15<00:01,  1.22s/it, loss=37.2857, avg_loss=36.1300]Epoch 51: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=39.0296, avg_loss=36.0133]Epoch 51: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=37.2857, avg_loss=36.1300]
Epoch 51: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.3443, avg_loss=35.7805]
Epoch 51: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.2857, avg_loss=36.1300]
INFO:__main__:=== EPOCH 51 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.013269
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.461194
INFO:__main__:   • gene_density: 1.183120
INFO:__main__:   • operon_membership: 11.368954
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 51 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 51 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.780483
INFO:__main__:🔢 Total Loss: 36.130009
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.820754
INFO:__main__:   • gene_expression: 23.554067
INFO:__main__:   • gene_density: 1.188920
INFO:__main__:   • gene_density: 1.194957
INFO:__main__:   • operon_membership: 12.120334
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.031457
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 51:  91%|█████████ | 10/11 [00:15<00:01,  1.22s/it, loss=35.9060, avg_loss=35.1422]Epoch 51: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=35.9060, avg_loss=35.1422]Epoch 51: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.9060, avg_loss=35.1422]
INFO:__main__:=== EPOCH 51 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.142183
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.891896
INFO:__main__:   • gene_density: 1.166667
INFO:__main__:   • operon_membership: 12.083620
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 52/681
INFO:__main__:Epoch 52/681
INFO:__main__:Epoch 52/681
INFO:__main__:Epoch 52/681
Epoch 52:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 52:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 52:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 52:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 52:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3434, avg_loss=34.3434]Epoch 52:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6479, avg_loss=37.6479]Epoch 52:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.0183, avg_loss=38.0183]Epoch 52:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6897, avg_loss=32.6897]Epoch 52:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=37.6479, avg_loss=37.6479]Epoch 52:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=38.0183, avg_loss=38.0183]Epoch 52:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=34.3434, avg_loss=34.3434]Epoch 52:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=32.6897, avg_loss=32.6897]Epoch 52:  91%|█████████ | 10/11 [00:15<00:01,  1.36s/it, loss=35.6275, avg_loss=34.8577]Epoch 52:  91%|█████████ | 10/11 [00:15<00:01,  1.36s/it, loss=36.3674, avg_loss=36.1337]Epoch 52: 100%|██████████| 11/11 [00:15<00:00,  1.29s/it, loss=35.6275, avg_loss=34.8577]Epoch 52: 100%|██████████| 11/11 [00:15<00:00,  1.29s/it, loss=36.3674, avg_loss=36.1337]Epoch 52: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=36.3674, avg_loss=36.1337]Epoch 52: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.6275, avg_loss=34.8577]

INFO:__main__:=== EPOCH 52 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 52 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.133708
INFO:__main__:🔢 Total Loss: 34.857718
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.206719
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.177675
INFO:__main__:   • gene_expression: 22.169184
INFO:__main__:   • operon_membership: 11.749314
INFO:__main__:   • gene_density: 1.182528
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.506006
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 52:  91%|█████████ | 10/11 [00:15<00:01,  1.36s/it, loss=36.4748, avg_loss=35.8159]Epoch 52: 100%|██████████| 11/11 [00:15<00:00,  1.29s/it, loss=36.4748, avg_loss=35.8159]Epoch 52:  91%|█████████ | 10/11 [00:15<00:01,  1.36s/it, loss=42.3343, avg_loss=36.2304]Epoch 52: 100%|██████████| 11/11 [00:15<00:00,  1.29s/it, loss=42.3343, avg_loss=36.2304]Epoch 52: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=36.4748, avg_loss=35.8159]
Epoch 52: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=42.3343, avg_loss=36.2304]
INFO:__main__:=== EPOCH 52 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.815898
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 52 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 22.758139
INFO:__main__:   • gene_density: 1.180457
INFO:__main__:   • operon_membership: 11.877303
INFO:__main__:🔢 Total Loss: 36.230391
INFO:__main__:👥 Samples processed: 22
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 23.494801
INFO:__main__:   • gene_density: 1.191761
INFO:__main__:   • operon_membership: 11.543829
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 53/681
INFO:__main__:Epoch 53/681
INFO:__main__:Epoch 53/681
INFO:__main__:Epoch 53/681
Epoch 53:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 53:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 53:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 53:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 53:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1457, avg_loss=38.1457]Epoch 53:   9%|▉         | 1/11 [00:01<00:13,  1.34s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1174, avg_loss=35.1174]Epoch 53:   9%|▉         | 1/11 [00:01<00:13,  1.34s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1744, avg_loss=35.1744]Epoch 53:   9%|▉         | 1/11 [00:01<00:13,  1.34s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.2193, avg_loss=36.2193]Epoch 53:   9%|▉         | 1/11 [00:01<00:13,  1.36s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  27%|██▋       | 3/11 [00:04<00:11,  1.41s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:  36%|███▋      | 4/11 [00:05<00:09,  1.43s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:  82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:  82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:  82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=35.1174, avg_loss=35.1174]Epoch 53:  91%|█████████ | 10/11 [00:14<00:01,  1.44s/it, loss=38.1457, avg_loss=38.1457]Epoch 53:  91%|█████████ | 10/11 [00:14<00:01,  1.44s/it, loss=35.1744, avg_loss=35.1744]Epoch 53:  91%|█████████ | 10/11 [00:14<00:01,  1.44s/it, loss=36.2193, avg_loss=36.2193]Epoch 53:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=40.6125, avg_loss=35.9105]Epoch 53:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=35.0716, avg_loss=35.9959]Epoch 53: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=40.6125, avg_loss=35.9105]Epoch 53: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.0716, avg_loss=35.9959]Epoch 53:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=34.6895, avg_loss=34.9577]Epoch 53: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.6895, avg_loss=34.9577]Epoch 53: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=40.6125, avg_loss=35.9105]
Epoch 53: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.0716, avg_loss=35.9959]
Epoch 53: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.6895, avg_loss=34.9577]
INFO:__main__:=== EPOCH 53 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.910452
INFO:__main__:=== EPOCH 53 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.448269
INFO:__main__:🔢 Total Loss: 35.995928
INFO:__main__:   • gene_density: 1.192590
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • operon_membership: 12.269593
INFO:__main__:   • gene_expression: 22.930560
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_density: 1.168738
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 11.896631
INFO:__main__:=== EPOCH 53 TRAINING LOSSES ===
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 34.957662
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.909939
INFO:__main__:   • gene_density: 1.178563
INFO:__main__:   • operon_membership: 10.869159
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 53:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=34.4534, avg_loss=36.0023]Epoch 53: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.4534, avg_loss=36.0023]Epoch 53: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.4534, avg_loss=36.0023]
INFO:__main__:=== EPOCH 53 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.002269
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.078851
INFO:__main__:   • gene_density: 1.191998
INFO:__main__:   • operon_membership: 11.731420
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 54/681
INFO:__main__:Epoch 54/681
INFO:__main__:Epoch 54/681
INFO:__main__:Epoch 54/681
Epoch 54:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 54:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 54:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 54:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 54:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8286, avg_loss=33.8286]Epoch 54:   9%|▉         | 1/11 [00:01<00:12,  1.27s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.5915, avg_loss=38.5915]Epoch 54:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2293, avg_loss=34.2293]Epoch 54:   9%|▉         | 1/11 [00:01<00:12,  1.28s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:   9%|▉         | 1/11 [00:01<00:12,  1.28s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8773, avg_loss=35.8773]Epoch 54:   9%|▉         | 1/11 [00:01<00:12,  1.28s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:  18%|█▊        | 2/11 [00:02<00:09,  1.03s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  18%|█▊        | 2/11 [00:02<00:09,  1.04s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  27%|██▋       | 3/11 [00:03<00:09,  1.22s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=34.2293, avg_loss=34.2293]Epoch 54:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=35.8773, avg_loss=35.8773]Epoch 54:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=33.8286, avg_loss=33.8286]Epoch 54:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=38.5915, avg_loss=38.5915]Epoch 54:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.6976, avg_loss=34.5839]Epoch 54: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=35.6976, avg_loss=34.5839]Epoch 54: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.6976, avg_loss=34.5839]
INFO:__main__:=== EPOCH 54 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.583887
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.986304
INFO:__main__:   • gene_density: 1.195845
INFO:__main__:   • operon_membership: 11.401738
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 54:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=34.2077, avg_loss=36.2779]Epoch 54:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=38.0559, avg_loss=35.9998]Epoch 54: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=34.2077, avg_loss=36.2779]Epoch 54: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=38.0559, avg_loss=35.9998]Epoch 54: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=34.2077, avg_loss=36.2779]
Epoch 54: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.0559, avg_loss=35.9998]
INFO:__main__:=== EPOCH 54 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.277923
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.813049
INFO:__main__:   • gene_density: 1.175722
INFO:__main__:   • operon_membership: 12.289151
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 54 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.999756
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.359802
INFO:__main__:   • gene_density: 1.177320
INFO:__main__:   • operon_membership: 11.462634
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 54:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=37.1766, avg_loss=36.2902]Epoch 54: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=37.1766, avg_loss=36.2902]Epoch 54: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.1766, avg_loss=36.2902]
INFO:__main__:=== EPOCH 54 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.290246
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.607148
INFO:__main__:   • gene_density: 1.185369
INFO:__main__:   • operon_membership: 11.497729
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 55/681
INFO:__main__:Epoch 55/681
INFO:__main__:Epoch 55/681
INFO:__main__:Epoch 55/681
Epoch 55:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 55:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 55:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 55:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 55:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6754, avg_loss=33.6754]Epoch 55:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2843, avg_loss=34.2843]Epoch 55:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6842, avg_loss=32.6842]Epoch 55:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.8701, avg_loss=34.8701]Epoch 55:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:  36%|███▋      | 4/11 [00:04<00:07,  1.02s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:  36%|███▋      | 4/11 [00:04<00:07,  1.02s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:  36%|███▋      | 4/11 [00:04<00:07,  1.02s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:  36%|███▋      | 4/11 [00:04<00:07,  1.02s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  45%|████▌     | 5/11 [00:05<00:07,  1.18s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:  45%|████▌     | 5/11 [00:05<00:07,  1.18s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:  45%|████▌     | 5/11 [00:05<00:07,  1.18s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:  45%|████▌     | 5/11 [00:05<00:07,  1.19s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=34.2843, avg_loss=34.2843]Epoch 55:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=32.6842, avg_loss=32.6842]Epoch 55:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=33.6754, avg_loss=33.6754]Epoch 55:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=34.8701, avg_loss=34.8701]Epoch 55:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=36.4642, avg_loss=35.2494]Epoch 55:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.7356, avg_loss=34.4404]Epoch 55: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=36.4642, avg_loss=35.2494]Epoch 55: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.7356, avg_loss=34.4404]Epoch 55: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=36.4642, avg_loss=35.2494]Epoch 55: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=35.7356, avg_loss=34.4404]

INFO:__main__:=== EPOCH 55 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 55 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.440381
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.249440
INFO:__main__:   • gene_expression: 21.552621
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.186257
INFO:__main__:   • gene_expression: 22.874530
INFO:__main__:   • operon_membership: 11.701503
INFO:__main__:   • gene_density: 1.178149
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.196761
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 55:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.4331, avg_loss=36.3967]Epoch 55: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.4331, avg_loss=36.3967]Epoch 55: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=35.4331, avg_loss=36.3967]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 55 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.396725
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.124011
INFO:__main__:   • gene_density: 1.181049
INFO:__main__:   • operon_membership: 12.091666
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 55:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.5325, avg_loss=36.9069]Epoch 55: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.5325, avg_loss=36.9069]Epoch 55: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=35.5325, avg_loss=36.9069]
INFO:__main__:=== EPOCH 55 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.906908
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.202539
INFO:__main__:   • gene_density: 1.186849
INFO:__main__:   • operon_membership: 11.517519
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.56it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]

Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]
INFO:__main__:=== EPOCH 55 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 55 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 55 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]
INFO:__main__:=== EPOCH 55 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 56/681
INFO:__main__:Epoch 56/681
INFO:__main__:Epoch 56/681
INFO:__main__:Epoch 56/681
Epoch 56:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 56:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 56:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 56:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 56:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5982, avg_loss=34.5982]Epoch 56:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3105, avg_loss=35.3105]Epoch 56:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.9610, avg_loss=37.9610]Epoch 56:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5266, avg_loss=34.5266]Epoch 56:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  18%|█▊        | 2/11 [00:02<00:10,  1.21s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:  18%|█▊        | 2/11 [00:02<00:10,  1.21s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:  18%|█▊        | 2/11 [00:02<00:10,  1.21s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:  18%|█▊        | 2/11 [00:02<00:10,  1.21s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  27%|██▋       | 3/11 [00:03<00:08,  1.04s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:  27%|██▋       | 3/11 [00:03<00:08,  1.04s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  27%|██▋       | 3/11 [00:03<00:08,  1.04s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:  27%|██▋       | 3/11 [00:03<00:08,  1.04s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:  36%|███▋      | 4/11 [00:04<00:08,  1.18s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:  36%|███▋      | 4/11 [00:04<00:08,  1.18s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:  36%|███▋      | 4/11 [00:04<00:08,  1.18s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:  36%|███▋      | 4/11 [00:04<00:08,  1.19s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  55%|█████▍    | 6/11 [00:07<00:06,  1.32s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:  55%|█████▍    | 6/11 [00:07<00:06,  1.32s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=37.9610, avg_loss=37.9610]Epoch 56:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=34.5982, avg_loss=34.5982]Epoch 56:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=35.3105, avg_loss=35.3105]Epoch 56:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=34.5266, avg_loss=34.5266]Epoch 56:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=35.2213, avg_loss=35.8266]Epoch 56:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=33.4857, avg_loss=35.4696]Epoch 56: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=35.2213, avg_loss=35.8266]Epoch 56: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=33.4857, avg_loss=35.4696]Epoch 56: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=35.2213, avg_loss=35.8266]Epoch 56: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=33.4857, avg_loss=35.4696]

INFO:__main__:=== EPOCH 56 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 56 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.469583
INFO:__main__:🔢 Total Loss: 35.826622
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.403175
INFO:__main__:   • gene_expression: 23.902564
INFO:__main__:   • gene_density: 1.180043
INFO:__main__:   • gene_density: 1.176136
INFO:__main__:   • operon_membership: 11.886366
INFO:__main__:   • operon_membership: 10.747922
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 56:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=35.6723, avg_loss=36.2232]Epoch 56: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=35.6723, avg_loss=36.2232]Epoch 56: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=35.6723, avg_loss=36.2232]
INFO:__main__:=== EPOCH 56 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.223172
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.133406
INFO:__main__:   • gene_density: 1.181345
INFO:__main__:   • operon_membership: 11.908422
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 56:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=34.1614, avg_loss=35.4049]Epoch 56: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=34.1614, avg_loss=35.4049]Epoch 56: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.1614, avg_loss=35.4049]
INFO:__main__:=== EPOCH 56 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.404945
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.092437
INFO:__main__:   • gene_density: 1.194070
INFO:__main__:   • operon_membership: 12.118438
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 57/681
INFO:__main__:Epoch 57/681
INFO:__main__:Epoch 57/681
INFO:__main__:Epoch 57/681
Epoch 57:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 57:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 57:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 57:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 57:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0611, avg_loss=36.0611]Epoch 57:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0712, avg_loss=35.0712]Epoch 57:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1282, avg_loss=34.1282]Epoch 57:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.5575, avg_loss=39.5575]Epoch 57:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  45%|████▌     | 5/11 [00:06<00:06,  1.10s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:  45%|████▌     | 5/11 [00:06<00:06,  1.10s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:  45%|████▌     | 5/11 [00:06<00:06,  1.10s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:  45%|████▌     | 5/11 [00:06<00:06,  1.11s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  55%|█████▍    | 6/11 [00:07<00:06,  1.22s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:  55%|█████▍    | 6/11 [00:07<00:06,  1.22s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:  55%|█████▍    | 6/11 [00:07<00:06,  1.22s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:  55%|█████▍    | 6/11 [00:07<00:06,  1.22s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  64%|██████▎   | 7/11 [00:09<00:05,  1.30s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:  64%|██████▎   | 7/11 [00:09<00:05,  1.30s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:  64%|██████▎   | 7/11 [00:09<00:05,  1.30s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:  64%|██████▎   | 7/11 [00:09<00:05,  1.30s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=36.0611, avg_loss=36.0611]Epoch 57:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=34.1282, avg_loss=34.1282]Epoch 57:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=35.0712, avg_loss=35.0712]Epoch 57:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=39.5575, avg_loss=39.5575]Epoch 57:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=34.5459, avg_loss=36.1049]Epoch 57:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=35.1227, avg_loss=35.5401]Epoch 57:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=30.2535, avg_loss=35.4414]Epoch 57: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=34.5459, avg_loss=36.1049]Epoch 57: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=35.1227, avg_loss=35.5401]Epoch 57: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=30.2535, avg_loss=35.4414]Epoch 57: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=34.5459, avg_loss=36.1049]
Epoch 57: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=35.1227, avg_loss=35.5401]
Epoch 57: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=30.2535, avg_loss=35.4414]
INFO:__main__:=== EPOCH 57 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 57 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.104924
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 57 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.540143
INFO:__main__:   • gene_expression: 23.836302
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.191110
INFO:__main__:🔢 Total Loss: 35.441450
INFO:__main__:   • operon_membership: 11.077511
INFO:__main__:   • gene_expression: 23.390472
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_density: 1.172822
INFO:__main__:   • gene_expression: 22.661196
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 10.976849
INFO:__main__:   • gene_density: 1.177794
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.602460
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 57:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=34.3567, avg_loss=35.8478]Epoch 57: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=34.3567, avg_loss=35.8478]Epoch 57: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.3567, avg_loss=35.8478]
INFO:__main__:=== EPOCH 57 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.847768
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.003964
INFO:__main__:   • gene_density: 1.186731
INFO:__main__:   • operon_membership: 12.657073
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 58/681
INFO:__main__:Epoch 58/681
INFO:__main__:Epoch 58/681
INFO:__main__:Epoch 58/681
Epoch 58:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 58:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 58:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 58:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 58:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1675, avg_loss=36.1675]Epoch 58:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.4771, avg_loss=37.4771]Epoch 58:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.3468, avg_loss=39.3468]Epoch 58:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.2562, avg_loss=39.2562]Epoch 58:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  36%|███▋      | 4/11 [00:05<00:09,  1.37s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:  36%|███▋      | 4/11 [00:05<00:09,  1.37s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:  36%|███▋      | 4/11 [00:05<00:09,  1.37s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:  36%|███▋      | 4/11 [00:05<00:09,  1.37s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  45%|████▌     | 5/11 [00:06<00:07,  1.26s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:  64%|██████▎   | 7/11 [00:08<00:04,  1.18s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:  64%|██████▎   | 7/11 [00:08<00:04,  1.19s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:  64%|██████▎   | 7/11 [00:08<00:04,  1.19s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:  73%|███████▎  | 8/11 [00:10<00:03,  1.27s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:  73%|███████▎  | 8/11 [00:10<00:03,  1.27s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  82%|████████▏ | 9/11 [00:11<00:02,  1.32s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:  82%|████████▏ | 9/11 [00:11<00:02,  1.32s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:  82%|████████▏ | 9/11 [00:11<00:02,  1.32s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:  82%|████████▏ | 9/11 [00:11<00:02,  1.32s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  91%|█████████ | 10/11 [00:13<00:01,  1.36s/it, loss=36.1675, avg_loss=36.1675]Epoch 58:  91%|█████████ | 10/11 [00:13<00:01,  1.36s/it, loss=39.3468, avg_loss=39.3468]Epoch 58:  91%|█████████ | 10/11 [00:13<00:01,  1.36s/it, loss=37.4771, avg_loss=37.4771]Epoch 58:  91%|█████████ | 10/11 [00:13<00:01,  1.36s/it, loss=39.2562, avg_loss=39.2562]Epoch 58:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=34.7771, avg_loss=35.5409]Epoch 58: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=34.7771, avg_loss=35.5409]Epoch 58:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=34.3100, avg_loss=36.0149]Epoch 58: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=34.3100, avg_loss=36.0149]Epoch 58: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.7771, avg_loss=35.5409]
Epoch 58: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.3100, avg_loss=36.0149]
Epoch 58:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=32.0178, avg_loss=36.4441]Epoch 58: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=32.0178, avg_loss=36.4441]Epoch 58: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=32.0178, avg_loss=36.4441]
INFO:__main__:=== EPOCH 58 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.540926
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.268515
INFO:__main__:   • gene_density: 1.185369
INFO:__main__:   • operon_membership: 12.087042
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 58 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.014857
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.915449
INFO:__main__:   • gene_density: 1.190992
INFO:__main__:   • operon_membership: 10.908416
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 58 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.444109
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.698178
INFO:__main__:   • gene_density: 1.170099
INFO:__main__:   • operon_membership: 12.575832
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 58:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=35.5056, avg_loss=35.0309]Epoch 58: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=35.5056, avg_loss=35.0309]Epoch 58: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.5056, avg_loss=35.0309]
INFO:__main__:=== EPOCH 58 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.030912
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.833341
INFO:__main__:   • gene_density: 1.188447
INFO:__main__:   • operon_membership: 11.009124
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 59/681
INFO:__main__:Epoch 59/681
INFO:__main__:Epoch 59/681
INFO:__main__:Epoch 59/681
Epoch 59:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 59:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 59:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 59:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 59:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9859, avg_loss=33.9859]Epoch 59:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3005, avg_loss=35.3005]Epoch 59:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9677, avg_loss=36.9677]Epoch 59:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9774, avg_loss=35.9774]Epoch 59:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  18%|█▊        | 2/11 [00:03<00:13,  1.56s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:  55%|█████▍    | 6/11 [00:08<00:06,  1.34s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  64%|██████▎   | 7/11 [00:09<00:04,  1.17s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  82%|████████▏ | 9/11 [00:11<00:02,  1.24s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:  82%|████████▏ | 9/11 [00:11<00:02,  1.24s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:  82%|████████▏ | 9/11 [00:11<00:02,  1.25s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:  82%|████████▏ | 9/11 [00:11<00:02,  1.25s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=35.3005, avg_loss=35.3005]Epoch 59:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=33.9859, avg_loss=33.9859]Epoch 59:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=36.9677, avg_loss=36.9677]Epoch 59:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=35.9774, avg_loss=35.9774]Epoch 59:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=35.1550, avg_loss=35.9276]Epoch 59: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=35.1550, avg_loss=35.9276]Epoch 59:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=35.9081, avg_loss=35.9648]Epoch 59: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=35.1550, avg_loss=35.9276]
Epoch 59: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=35.9081, avg_loss=35.9648]Epoch 59: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=35.9081, avg_loss=35.9648]
Epoch 59:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=33.8430, avg_loss=34.4368]Epoch 59: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=33.8430, avg_loss=34.4368]Epoch 59: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=33.8430, avg_loss=34.4368]
INFO:__main__:=== EPOCH 59 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.927580
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.800943
INFO:__main__:   • gene_density: 1.184600
INFO:__main__:   • operon_membership: 11.942037
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 59 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.964819
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.705379
INFO:__main__:   • gene_density: 1.171520
INFO:__main__:   • operon_membership: 12.087920
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 59 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.436783
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.467544
INFO:__main__:   • gene_density: 1.198331
INFO:__main__:   • operon_membership: 11.770908
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 59:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=35.6249, avg_loss=36.9024]Epoch 59: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.6249, avg_loss=36.9024]Epoch 59: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.6249, avg_loss=36.9024]
INFO:__main__:=== EPOCH 59 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.902440
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.754973
INFO:__main__:   • gene_density: 1.176906
INFO:__main__:   • operon_membership: 10.970561
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 60/681
INFO:__main__:Epoch 60/681
INFO:__main__:Epoch 60/681
INFO:__main__:Epoch 60/681
Epoch 60:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 60:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 60:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 60:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 60:   0%|          | 0/11 [00:01<?, ?it/s, loss=41.0881, avg_loss=41.0881]Epoch 60:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1079, avg_loss=34.1079]Epoch 60:   9%|▉         | 1/11 [00:01<00:15,  1.58s/it, loss=41.0881, avg_loss=41.0881]Epoch 60:   9%|▉         | 1/11 [00:01<00:15,  1.58s/it, loss=34.1079, avg_loss=34.1079]Epoch 60:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8879, avg_loss=35.8879]Epoch 60:   9%|▉         | 1/11 [00:01<00:15,  1.58s/it, loss=35.8879, avg_loss=35.8879]Epoch 60:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9581, avg_loss=35.9581]Epoch 60:   9%|▉         | 1/11 [00:01<00:15,  1.59s/it, loss=35.9581, avg_loss=35.9581]Epoch 60:  18%|█▊        | 2/11 [00:02<00:10,  1.14s/it, loss=35.8879, avg_loss=35.8879]Epoch 60:  18%|█▊        | 2/11 [00:02<00:10,  1.14s/it, loss=41.0881, avg_loss=41.0881]Epoch 60:  18%|█▊        | 2/11 [00:02<00:10,  1.14s/it, loss=35.9581, avg_loss=35.9581]Epoch 60:  18%|█▊        | 2/11 [00:02<00:10,  1.14s/it, loss=34.1079, avg_loss=34.1079]Epoch 60:  27%|██▋       | 3/11 [00:03<00:08,  1.03s/it, loss=41.0881, avg_loss=41.0881]Epoch 60:  27%|██▋       | 3/11 [00:03<00:08,  1.02s/it, loss=35.8879, avg_loss=35.8879]Epoch 60:  27%|██▋       | 3/11 [00:03<00:08,  1.03s/it, loss=34.1079, avg_loss=34.1079]Epoch 60:  27%|██▋       | 3/11 [00:03<00:08,  1.03s/it, loss=35.9581, avg_loss=35.9581]Epoch 60:  36%|███▋      | 4/11 [00:04<00:07,  1.09s/it, loss=35.8879, avg_loss=35.8879]Epoch 60:  36%|███▋      | 4/11 [00:04<00:07,  1.09s/it, loss=41.0881, avg_loss=41.0881]Epoch 60:  36%|███▋      | 4/11 [00:04<00:07,  1.09s/it, loss=34.1079, avg_loss=34.1079]Epoch 60:  36%|███▋      | 4/11 [00:04<00:07,  1.09s/it, loss=35.9581, avg_loss=35.9581]Epoch 60:  45%|████▌     | 5/11 [00:05<00:06,  1.11s/it, loss=41.0881, avg_loss=41.0881]Epoch 60:  45%|████▌     | 5/11 [00:05<00:06,  1.11s/it, loss=34.1079, avg_loss=34.1079]Epoch 60:  45%|████▌     | 5/11 [00:05<00:06,  1.11s/it, loss=35.8879, avg_loss=35.8879]Epoch 60:  45%|████▌     | 5/11 [00:05<00:06,  1.11s/it, loss=35.9581, avg_loss=35.9581]Epoch 60:  55%|█████▍    | 6/11 [00:06<00:05,  1.02s/it, loss=35.8879, avg_loss=35.8879]Epoch 60:  55%|█████▍    | 6/11 [00:06<00:05,  1.02s/it, loss=35.9581, avg_loss=35.9581]Epoch 60:  55%|█████▍    | 6/11 [00:06<00:05,  1.02s/it, loss=41.0881, avg_loss=41.0881]Epoch 60:  55%|█████▍    | 6/11 [00:06<00:05,  1.02s/it, loss=34.1079, avg_loss=34.1079]Epoch 60:  64%|██████▎   | 7/11 [00:07<00:03,  1.05it/s, loss=35.8879, avg_loss=35.8879]Epoch 60:  64%|██████▎   | 7/11 [00:07<00:03,  1.05it/s, loss=41.0881, avg_loss=41.0881]Epoch 60:  64%|██████▎   | 7/11 [00:07<00:03,  1.05it/s, loss=35.9581, avg_loss=35.9581]Epoch 60:  64%|██████▎   | 7/11 [00:07<00:03,  1.04it/s, loss=34.1079, avg_loss=34.1079]Epoch 60:  73%|███████▎  | 8/11 [00:08<00:02,  1.09it/s, loss=35.9581, avg_loss=35.9581]Epoch 60:  73%|███████▎  | 8/11 [00:08<00:02,  1.09it/s, loss=35.8879, avg_loss=35.8879]Epoch 60:  73%|███████▎  | 8/11 [00:08<00:02,  1.09it/s, loss=41.0881, avg_loss=41.0881]Epoch 60:  73%|███████▎  | 8/11 [00:08<00:02,  1.09it/s, loss=34.1079, avg_loss=34.1079]Epoch 60:  82%|████████▏ | 9/11 [00:08<00:01,  1.12it/s, loss=34.1079, avg_loss=34.1079]Epoch 60:  82%|████████▏ | 9/11 [00:08<00:01,  1.12it/s, loss=35.9581, avg_loss=35.9581]Epoch 60:  82%|████████▏ | 9/11 [00:08<00:01,  1.12it/s, loss=41.0881, avg_loss=41.0881]Epoch 60:  82%|████████▏ | 9/11 [00:08<00:01,  1.12it/s, loss=35.8879, avg_loss=35.8879]Epoch 60:  91%|█████████ | 10/11 [00:09<00:00,  1.15it/s, loss=35.8879, avg_loss=35.8879]Epoch 60:  91%|█████████ | 10/11 [00:09<00:00,  1.14it/s, loss=34.1079, avg_loss=34.1079]Epoch 60:  91%|█████████ | 10/11 [00:09<00:00,  1.14it/s, loss=35.9581, avg_loss=35.9581]Epoch 60:  91%|█████████ | 10/11 [00:09<00:00,  1.14it/s, loss=41.0881, avg_loss=41.0881]Epoch 60:  91%|█████████ | 10/11 [00:10<00:00,  1.15it/s, loss=36.4244, avg_loss=36.0934]Epoch 60:  91%|█████████ | 10/11 [00:10<00:00,  1.14it/s, loss=35.0452, avg_loss=35.0414]Epoch 60: 100%|██████████| 11/11 [00:10<00:00,  1.10it/s, loss=36.4244, avg_loss=36.0934]Epoch 60: 100%|██████████| 11/11 [00:10<00:00,  1.10it/s, loss=35.0452, avg_loss=35.0414]Epoch 60: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s, loss=36.4244, avg_loss=36.0934]
Epoch 60: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s, loss=35.0452, avg_loss=35.0414]
Epoch 60:  91%|█████████ | 10/11 [00:10<00:00,  1.14it/s, loss=37.7795, avg_loss=36.1839]Epoch 60: 100%|██████████| 11/11 [00:10<00:00,  1.10it/s, loss=37.7795, avg_loss=36.1839]INFO:__main__:=== EPOCH 60 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 60 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.041445
INFO:__main__:🔢 Total Loss: 36.093382
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.841622
INFO:__main__:   • gene_expression: 23.767357
INFO:__main__:   • gene_density: 1.182884
INFO:__main__:   • gene_density: 1.173236
INFO:__main__:   • operon_membership: 11.016938
INFO:__main__:   • operon_membership: 11.152788
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 60: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s, loss=37.7795, avg_loss=36.1839]
INFO:__main__:=== EPOCH 60 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.183901
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.441522
INFO:__main__:   • gene_density: 1.189394
INFO:__main__:   • operon_membership: 11.552984
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 60:  91%|█████████ | 10/11 [00:10<00:00,  1.14it/s, loss=33.8722, avg_loss=35.7943]Epoch 60: 100%|██████████| 11/11 [00:10<00:00,  1.10it/s, loss=33.8722, avg_loss=35.7943]Epoch 60: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s, loss=33.8722, avg_loss=35.7943]
INFO:__main__:=== EPOCH 60 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.794348
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.673718
INFO:__main__:   • gene_density: 1.187974
INFO:__main__:   • operon_membership: 12.932656
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.75it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.73it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.72it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.73it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.30it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.30it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.31it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.32it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.54it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.53it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.53it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.52it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.30it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.30it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.30it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.28it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.27it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.27it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.28it/s]
INFO:__main__:=== EPOCH 60 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 60 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:=== EPOCH 60 VALIDATION LOSSES ===
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:=== EPOCH 60 VALIDATION LOSSES ===
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_60.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_60.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_60.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_60.pt
INFO:__main__:Epoch 61/681
INFO:__main__:Epoch 61/681
INFO:__main__:Epoch 61/681
INFO:__main__:Epoch 61/681
Epoch 61:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 61:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 61:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 61:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 61:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6480, avg_loss=33.6480]Epoch 61:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1298, avg_loss=35.1298]Epoch 61:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7459, avg_loss=36.7459]Epoch 61:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0803, avg_loss=34.0803]Epoch 61:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  55%|█████▍    | 6/11 [00:08<00:06,  1.36s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  55%|█████▍    | 6/11 [00:08<00:06,  1.36s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:  55%|█████▍    | 6/11 [00:08<00:06,  1.36s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:  55%|█████▍    | 6/11 [00:08<00:06,  1.36s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:  73%|███████▎  | 8/11 [00:10<00:03,  1.20s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:  73%|███████▎  | 8/11 [00:10<00:03,  1.20s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:  73%|███████▎  | 8/11 [00:10<00:03,  1.20s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:  73%|███████▎  | 8/11 [00:10<00:03,  1.20s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  82%|████████▏ | 9/11 [00:12<00:02,  1.27s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:  82%|████████▏ | 9/11 [00:12<00:02,  1.28s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:  82%|████████▏ | 9/11 [00:12<00:02,  1.28s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:  82%|████████▏ | 9/11 [00:12<00:02,  1.28s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  91%|█████████ | 10/11 [00:13<00:01,  1.32s/it, loss=36.7459, avg_loss=36.7459]Epoch 61:  91%|█████████ | 10/11 [00:13<00:01,  1.32s/it, loss=35.1298, avg_loss=35.1298]Epoch 61:  91%|█████████ | 10/11 [00:13<00:01,  1.32s/it, loss=33.6480, avg_loss=33.6480]Epoch 61:  91%|█████████ | 10/11 [00:13<00:01,  1.32s/it, loss=34.0803, avg_loss=34.0803]Epoch 61:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=33.1387, avg_loss=35.4896]Epoch 61: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.1387, avg_loss=35.4896]Epoch 61:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=38.4622, avg_loss=36.0276]Epoch 61:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=37.5748, avg_loss=35.6530]Epoch 61: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=38.4622, avg_loss=36.0276]Epoch 61: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.5748, avg_loss=35.6530]Epoch 61: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.1387, avg_loss=35.4896]
Epoch 61: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=38.4622, avg_loss=36.0276]Epoch 61: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.5748, avg_loss=35.6530]

INFO:__main__:=== EPOCH 61 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.489581
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.275915
INFO:__main__:=== EPOCH 61 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.186139
INFO:__main__:   • operon_membership: 11.027527
INFO:__main__:=== EPOCH 61 TRAINING LOSSES ===
INFO:__main__:👥 Samples processed: 22
INFO:__main__:🔢 Total Loss: 36.027614
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.653009
INFO:__main__:   • gene_expression: 23.694106
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.188210
INFO:__main__:   • gene_expression: 22.854527
INFO:__main__:   • operon_membership: 11.145297
INFO:__main__:   • gene_density: 1.179747
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.618736
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 61:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=37.5844, avg_loss=35.9190]Epoch 61: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.5844, avg_loss=35.9190]Epoch 61: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.5844, avg_loss=35.9190]
INFO:__main__:=== EPOCH 61 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.918962
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.996600
INFO:__main__:   • gene_density: 1.175308
INFO:__main__:   • operon_membership: 12.747054
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 62/681
INFO:__main__:Epoch 62/681
INFO:__main__:Epoch 62/681
INFO:__main__:Epoch 62/681
Epoch 62:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 62:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 62:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 62:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 62:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5326, avg_loss=35.5326]Epoch 62:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5150, avg_loss=37.5150]Epoch 62:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.2026, avg_loss=39.2026]Epoch 62:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8626, avg_loss=36.8626]Epoch 62:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  64%|██████▎   | 7/11 [00:09<00:04,  1.25s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=39.2026, avg_loss=39.2026]Epoch 62:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=35.5326, avg_loss=35.5326]Epoch 62:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=37.5150, avg_loss=37.5150]Epoch 62:  91%|█████████ | 10/11 [00:13<00:01,  1.31s/it, loss=36.8626, avg_loss=36.8626]Epoch 62:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=33.0452, avg_loss=35.4314]Epoch 62:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=36.1221, avg_loss=36.0668]Epoch 62: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.0452, avg_loss=35.4314]Epoch 62: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=36.1221, avg_loss=36.0668]Epoch 62: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=33.0452, avg_loss=35.4314]
Epoch 62: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.1221, avg_loss=36.0668]
INFO:__main__:=== EPOCH 62 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.431428
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 62 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 22.688065
INFO:__main__:   • gene_density: 1.182055
INFO:__main__:   • operon_membership: 11.561307
INFO:__main__:🔢 Total Loss: 36.066843
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.716384
INFO:__main__:   • gene_density: 1.187678
INFO:__main__:   • operon_membership: 12.162781
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 62:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=31.5487, avg_loss=35.4243]Epoch 62: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=31.5487, avg_loss=35.4243]Epoch 62: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=31.5487, avg_loss=35.4243]
INFO:__main__:=== EPOCH 62 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.424323
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.443461
INFO:__main__:   • gene_density: 1.173473
INFO:__main__:   • operon_membership: 11.807390
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 62:  91%|█████████ | 10/11 [00:15<00:01,  1.31s/it, loss=37.5136, avg_loss=36.1252]Epoch 62: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.5136, avg_loss=36.1252]Epoch 62: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.5136, avg_loss=36.1252]
INFO:__main__:=== EPOCH 62 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.125239
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.807704
INFO:__main__:   • gene_density: 1.189808
INFO:__main__:   • operon_membership: 11.127727
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 63/681
INFO:__main__:Epoch 63/681
INFO:__main__:Epoch 63/681
INFO:__main__:Epoch 63/681
Epoch 63:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 63:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 63:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 63:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 63:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3556, avg_loss=35.3556]Epoch 63:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.7626, avg_loss=38.7626]Epoch 63:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0452, avg_loss=33.0452]Epoch 63:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3690, avg_loss=34.3690]Epoch 63:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  64%|██████▎   | 7/11 [00:09<00:05,  1.30s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:  64%|██████▎   | 7/11 [00:09<00:05,  1.29s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  64%|██████▎   | 7/11 [00:09<00:05,  1.30s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:  64%|██████▎   | 7/11 [00:09<00:05,  1.30s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  82%|████████▏ | 9/11 [00:12<00:02,  1.24s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:  82%|████████▏ | 9/11 [00:12<00:02,  1.24s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:  82%|████████▏ | 9/11 [00:12<00:02,  1.24s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:  82%|████████▏ | 9/11 [00:12<00:02,  1.24s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  91%|█████████ | 10/11 [00:13<00:01,  1.30s/it, loss=38.7626, avg_loss=38.7626]Epoch 63:  91%|█████████ | 10/11 [00:13<00:01,  1.30s/it, loss=35.3556, avg_loss=35.3556]Epoch 63:  91%|█████████ | 10/11 [00:13<00:01,  1.30s/it, loss=33.0452, avg_loss=33.0452]Epoch 63:  91%|█████████ | 10/11 [00:13<00:01,  1.30s/it, loss=34.3690, avg_loss=34.3690]Epoch 63:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=35.6771, avg_loss=36.3041]Epoch 63: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.6771, avg_loss=36.3041]Epoch 63:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=37.9392, avg_loss=35.9512]Epoch 63: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.9392, avg_loss=35.9512]Epoch 63: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.6771, avg_loss=36.3041]
Epoch 63: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.9392, avg_loss=35.9512]
INFO:__main__:=== EPOCH 63 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.304087
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.957036
INFO:__main__:   • gene_density: 1.176136
INFO:__main__:   • operon_membership: 11.170913
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 63 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.951199
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.303996
INFO:__main__:   • gene_density: 1.200521
INFO:__main__:   • operon_membership: 11.446681
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 63:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=33.3956, avg_loss=35.7322]Epoch 63: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=33.3956, avg_loss=35.7322]Epoch 63: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=33.3956, avg_loss=35.7322]
INFO:__main__:=== EPOCH 63 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.732167
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.370627
INFO:__main__:   • gene_density: 1.172171
INFO:__main__:   • operon_membership: 12.189369
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 63:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=35.7552, avg_loss=35.1305]Epoch 63: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.7552, avg_loss=35.1305]Epoch 63: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.7552, avg_loss=35.1305]
INFO:__main__:=== EPOCH 63 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.130497
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.166780
INFO:__main__:   • gene_density: 1.181759
INFO:__main__:   • operon_membership: 11.781959
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 64/681
INFO:__main__:Epoch 64/681
INFO:__main__:Epoch 64/681
INFO:__main__:Epoch 64/681
Epoch 64:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 64:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 64:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 64:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 64:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1327, avg_loss=37.1327]Epoch 64:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.4826, avg_loss=38.4826]Epoch 64:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.3122, avg_loss=33.3122]Epoch 64:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.3334, avg_loss=33.3334]Epoch 64:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:  45%|████▌     | 5/11 [00:08<00:11,  1.97s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  55%|█████▍    | 6/11 [00:09<00:08,  1.75s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:  55%|█████▍    | 6/11 [00:09<00:08,  1.75s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:  55%|█████▍    | 6/11 [00:09<00:08,  1.75s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:  55%|█████▍    | 6/11 [00:09<00:08,  1.60s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  64%|██████▎   | 7/11 [00:10<00:06,  1.50s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:  64%|██████▎   | 7/11 [00:10<00:06,  1.50s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:  64%|██████▎   | 7/11 [00:10<00:06,  1.50s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  73%|███████▎  | 8/11 [00:12<00:04,  1.49s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:  73%|███████▎  | 8/11 [00:12<00:04,  1.49s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:  73%|███████▎  | 8/11 [00:12<00:04,  1.49s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:  73%|███████▎  | 8/11 [00:12<00:04,  1.43s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  82%|████████▏ | 9/11 [00:13<00:02,  1.48s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:  82%|████████▏ | 9/11 [00:13<00:02,  1.48s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:  82%|████████▏ | 9/11 [00:13<00:02,  1.48s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=33.3122, avg_loss=33.3122]Epoch 64:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=38.4826, avg_loss=38.4826]Epoch 64:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=37.1327, avg_loss=37.1327]Epoch 64:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=33.3334, avg_loss=33.3334]Epoch 64:  91%|█████████ | 10/11 [00:16<00:01,  1.47s/it, loss=37.6132, avg_loss=35.6794]Epoch 64: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=37.6132, avg_loss=35.6794]Epoch 64: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=37.6132, avg_loss=35.6794]
INFO:__main__:=== EPOCH 64 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.679408
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.869642
INFO:__main__:   • gene_density: 1.196851
INFO:__main__:   • operon_membership: 12.612915
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 64:  91%|█████████ | 10/11 [00:16<00:01,  1.47s/it, loss=34.6094, avg_loss=36.5912]Epoch 64: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=34.6094, avg_loss=36.5912]Epoch 64: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=34.6094, avg_loss=36.5912]
Epoch 64:  91%|█████████ | 10/11 [00:16<00:01,  1.47s/it, loss=38.8465, avg_loss=36.2681]Epoch 64: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=38.8465, avg_loss=36.2681]Epoch 64: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=38.8465, avg_loss=36.2681]
INFO:__main__:=== EPOCH 64 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.591201
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.766696
INFO:__main__:   • gene_density: 1.172940
INFO:__main__:   • operon_membership: 11.651565
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 64 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.268147
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.733797
INFO:__main__:   • gene_density: 1.184955
INFO:__main__:   • operon_membership: 11.349395
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 64:  91%|█████████ | 10/11 [00:16<00:01,  1.44s/it, loss=36.1830, avg_loss=34.6230]Epoch 64: 100%|██████████| 11/11 [00:16<00:00,  1.51s/it, loss=36.1830, avg_loss=34.6230]Epoch 64: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=36.1830, avg_loss=34.6230]
INFO:__main__:=== EPOCH 64 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.622970
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.551462
INFO:__main__:   • gene_density: 1.174420
INFO:__main__:   • operon_membership: 10.897088
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 65/681
INFO:__main__:Epoch 65/681
INFO:__main__:Epoch 65/681
INFO:__main__:Epoch 65/681
Epoch 65:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 65:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 65:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 65:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 65:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4331, avg_loss=35.4331]Epoch 65:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0807, avg_loss=34.0807]Epoch 65:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1681, avg_loss=35.1681]Epoch 65:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0762, avg_loss=33.0762]Epoch 65:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  55%|█████▍    | 6/11 [00:08<00:06,  1.25s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:  55%|█████▍    | 6/11 [00:08<00:06,  1.25s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  55%|█████▍    | 6/11 [00:08<00:06,  1.26s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:  55%|█████▍    | 6/11 [00:08<00:06,  1.26s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:  64%|██████▎   | 7/11 [00:09<00:04,  1.16s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:  64%|██████▎   | 7/11 [00:09<00:04,  1.16s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:  64%|██████▎   | 7/11 [00:09<00:04,  1.16s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:  64%|██████▎   | 7/11 [00:09<00:04,  1.16s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  73%|███████▎  | 8/11 [00:10<00:03,  1.24s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:  73%|███████▎  | 8/11 [00:10<00:03,  1.24s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:  73%|███████▎  | 8/11 [00:10<00:03,  1.24s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  91%|█████████ | 10/11 [00:13<00:01,  1.33s/it, loss=34.0807, avg_loss=34.0807]Epoch 65:  91%|█████████ | 10/11 [00:13<00:01,  1.34s/it, loss=35.1681, avg_loss=35.1681]Epoch 65:  91%|█████████ | 10/11 [00:13<00:01,  1.34s/it, loss=35.4331, avg_loss=35.4331]Epoch 65:  91%|█████████ | 10/11 [00:13<00:01,  1.34s/it, loss=33.0762, avg_loss=33.0762]Epoch 65:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=37.8713, avg_loss=36.3761]Epoch 65: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=37.8713, avg_loss=36.3761]Epoch 65: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.8713, avg_loss=36.3761]
Epoch 65:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=35.7636, avg_loss=35.0596]Epoch 65: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.7636, avg_loss=35.0596]Epoch 65: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.7636, avg_loss=35.0596]
INFO:__main__:=== EPOCH 65 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.376149
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.393585
INFO:__main__:   • gene_density: 1.179983
INFO:__main__:   • operon_membership: 11.802581
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 65 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.059624
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.076077
INFO:__main__:   • gene_density: 1.182173
INFO:__main__:   • operon_membership: 10.801373
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 65:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=36.7705, avg_loss=36.8469]Epoch 65: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=36.7705, avg_loss=36.8469]Epoch 65: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.7705, avg_loss=36.8469]
INFO:__main__:=== EPOCH 65 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.846878
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.590568
INFO:__main__:   • gene_density: 1.200758
INFO:__main__:   • operon_membership: 12.055553
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 65:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=36.5118, avg_loss=34.7823]Epoch 65: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=36.5118, avg_loss=34.7823]Epoch 65: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.5118, avg_loss=34.7823]
INFO:__main__:=== EPOCH 65 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.782275
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.636460
INFO:__main__:   • gene_density: 1.169330
INFO:__main__:   • operon_membership: 11.976485
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.27it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]


INFO:__main__:=== EPOCH 65 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 65 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 65 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]
INFO:__main__:=== EPOCH 65 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 66/681
INFO:__main__:Epoch 66/681
INFO:__main__:Epoch 66/681
INFO:__main__:Epoch 66/681
Epoch 66:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 66:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 66:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 66:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 66:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8132, avg_loss=33.8132]Epoch 66:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.9280, avg_loss=34.9280]Epoch 66:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4642, avg_loss=36.4642]Epoch 66:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4736, avg_loss=35.4736]Epoch 66:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  27%|██▋       | 3/11 [00:05<00:16,  2.12s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:  27%|██▋       | 3/11 [00:06<00:17,  2.21s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:  36%|███▋      | 4/11 [00:06<00:12,  1.84s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:  36%|███▋      | 4/11 [00:06<00:11,  1.68s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:  36%|███▋      | 4/11 [00:06<00:11,  1.66s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:  36%|███▋      | 4/11 [00:06<00:12,  1.84s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  45%|████▌     | 5/11 [00:08<00:10,  1.70s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:  45%|████▌     | 5/11 [00:08<00:09,  1.59s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:  45%|████▌     | 5/11 [00:08<00:09,  1.58s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:  45%|████▌     | 5/11 [00:08<00:10,  1.70s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  55%|█████▍    | 6/11 [00:09<00:08,  1.61s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:  55%|█████▍    | 6/11 [00:09<00:07,  1.53s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:  55%|█████▍    | 6/11 [00:09<00:07,  1.54s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:  55%|█████▍    | 6/11 [00:09<00:08,  1.61s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  64%|██████▎   | 7/11 [00:11<00:06,  1.54s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:  64%|██████▎   | 7/11 [00:11<00:05,  1.50s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:  64%|██████▎   | 7/11 [00:11<00:05,  1.49s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:  64%|██████▎   | 7/11 [00:11<00:06,  1.55s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  73%|███████▎  | 8/11 [00:12<00:04,  1.50s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:  73%|███████▎  | 8/11 [00:12<00:04,  1.51s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  82%|████████▏ | 9/11 [00:14<00:02,  1.48s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:  82%|████████▏ | 9/11 [00:14<00:02,  1.45s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:  82%|████████▏ | 9/11 [00:14<00:02,  1.46s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:  82%|████████▏ | 9/11 [00:14<00:02,  1.48s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  91%|█████████ | 10/11 [00:15<00:01,  1.46s/it, loss=34.9280, avg_loss=34.9280]Epoch 66:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=36.4642, avg_loss=36.4642]Epoch 66:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=33.8132, avg_loss=33.8132]Epoch 66:  91%|█████████ | 10/11 [00:15<00:01,  1.46s/it, loss=35.4736, avg_loss=35.4736]Epoch 66:  91%|█████████ | 10/11 [00:17<00:01,  1.44s/it, loss=36.4582, avg_loss=35.5831]Epoch 66:  91%|█████████ | 10/11 [00:17<00:01,  1.44s/it, loss=34.3041, avg_loss=35.2644]Epoch 66:  91%|█████████ | 10/11 [00:17<00:01,  1.46s/it, loss=38.2545, avg_loss=36.7950]Epoch 66: 100%|██████████| 11/11 [00:17<00:00,  1.48s/it, loss=36.4582, avg_loss=35.5831]Epoch 66: 100%|██████████| 11/11 [00:17<00:00,  1.48s/it, loss=34.3041, avg_loss=35.2644]Epoch 66: 100%|██████████| 11/11 [00:17<00:00,  1.49s/it, loss=38.2545, avg_loss=36.7950]Epoch 66: 100%|██████████| 11/11 [00:17<00:00,  1.55s/it, loss=36.4582, avg_loss=35.5831]Epoch 66: 100%|██████████| 11/11 [00:17<00:00,  1.55s/it, loss=34.3041, avg_loss=35.2644]

Epoch 66: 100%|██████████| 11/11 [00:17<00:00,  1.55s/it, loss=38.2545, avg_loss=36.7950]
INFO:__main__:=== EPOCH 66 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 66 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 66 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.264365
INFO:__main__:🔢 Total Loss: 35.583145
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 36.794959
INFO:__main__:   • gene_expression: 22.659210
INFO:__main__:   • gene_expression: 22.851784
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.185014
INFO:__main__:   • gene_density: 1.180457
INFO:__main__:   • gene_expression: 22.934826
INFO:__main__:   • operon_membership: 11.420140
INFO:__main__:   • operon_membership: 11.550904
INFO:__main__:   • gene_density: 1.180635
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 12.679499
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 66:  91%|█████████ | 10/11 [00:17<00:01,  1.46s/it, loss=36.2236, avg_loss=35.5312]Epoch 66: 100%|██████████| 11/11 [00:17<00:00,  1.49s/it, loss=36.2236, avg_loss=35.5312]Epoch 66: 100%|██████████| 11/11 [00:17<00:00,  1.55s/it, loss=36.2236, avg_loss=35.5312]
INFO:__main__:=== EPOCH 66 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.531184
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.307260
INFO:__main__:   • gene_density: 1.183357
INFO:__main__:   • operon_membership: 11.040566
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 67/681
INFO:__main__:Epoch 67/681
INFO:__main__:Epoch 67/681
INFO:__main__:Epoch 67/681
Epoch 67:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 67:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 67:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 67:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 67:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.4764, avg_loss=38.4764]Epoch 67:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6217, avg_loss=33.6217]Epoch 67:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1573, avg_loss=35.1573]Epoch 67:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6930, avg_loss=36.6930]Epoch 67:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  36%|███▋      | 4/11 [00:05<00:08,  1.20s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:  36%|███▋      | 4/11 [00:05<00:08,  1.21s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:  36%|███▋      | 4/11 [00:06<00:11,  1.71s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:  45%|████▌     | 5/11 [00:07<00:09,  1.60s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:  45%|████▌     | 5/11 [00:07<00:10,  1.73s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:  45%|████▌     | 5/11 [00:07<00:10,  1.74s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:  45%|████▌     | 5/11 [00:07<00:10,  1.74s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  55%|█████▍    | 6/11 [00:09<00:07,  1.56s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:  55%|█████▍    | 6/11 [00:09<00:08,  1.65s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:  55%|█████▍    | 6/11 [00:09<00:08,  1.65s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:  55%|█████▍    | 6/11 [00:09<00:08,  1.65s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  64%|██████▎   | 7/11 [00:10<00:06,  1.52s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:  64%|██████▎   | 7/11 [00:10<00:06,  1.58s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:  64%|██████▎   | 7/11 [00:10<00:06,  1.58s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:  64%|██████▎   | 7/11 [00:10<00:06,  1.59s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  73%|███████▎  | 8/11 [00:12<00:04,  1.50s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:  73%|███████▎  | 8/11 [00:12<00:04,  1.54s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:  73%|███████▎  | 8/11 [00:12<00:04,  1.54s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:  73%|███████▎  | 8/11 [00:12<00:04,  1.55s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  82%|████████▏ | 9/11 [00:13<00:02,  1.48s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:  82%|████████▏ | 9/11 [00:13<00:03,  1.51s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:  82%|████████▏ | 9/11 [00:13<00:03,  1.51s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:  82%|████████▏ | 9/11 [00:13<00:03,  1.51s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=33.6217, avg_loss=33.6217]Epoch 67:  91%|█████████ | 10/11 [00:15<00:01,  1.49s/it, loss=35.1573, avg_loss=35.1573]Epoch 67:  91%|█████████ | 10/11 [00:15<00:01,  1.49s/it, loss=38.4764, avg_loss=38.4764]Epoch 67:  91%|█████████ | 10/11 [00:15<00:01,  1.49s/it, loss=36.6930, avg_loss=36.6930]Epoch 67:  91%|█████████ | 10/11 [00:16<00:01,  1.49s/it, loss=40.0122, avg_loss=36.3666]Epoch 67: 100%|██████████| 11/11 [00:16<00:00,  1.52s/it, loss=40.0122, avg_loss=36.3666]Epoch 67: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=40.0122, avg_loss=36.3666]
INFO:__main__:=== EPOCH 67 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.366594
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.471219
INFO:__main__:   • gene_density: 1.161458
INFO:__main__:   • operon_membership: 11.733917
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 67:  91%|█████████ | 10/11 [00:16<00:01,  1.47s/it, loss=36.2006, avg_loss=35.6912]Epoch 67: 100%|██████████| 11/11 [00:16<00:00,  1.51s/it, loss=36.2006, avg_loss=35.6912]Epoch 67:  91%|█████████ | 10/11 [00:16<00:01,  1.49s/it, loss=32.3046, avg_loss=34.9776]Epoch 67: 100%|██████████| 11/11 [00:16<00:00,  1.52s/it, loss=32.3046, avg_loss=34.9776]Epoch 67: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=36.2006, avg_loss=35.6912]
Epoch 67: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=32.3046, avg_loss=34.9776]
INFO:__main__:=== EPOCH 67 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.691224
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.030446
INFO:__main__:   • gene_density: 1.198745
INFO:__main__:   • operon_membership: 11.462033
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 67 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.977563
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.214848
INFO:__main__:   • gene_density: 1.182588
INFO:__main__:   • operon_membership: 11.580127
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 67:  91%|█████████ | 10/11 [00:16<00:01,  1.49s/it, loss=37.6903, avg_loss=35.8153]Epoch 67: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=37.6903, avg_loss=35.8153]Epoch 67: 100%|██████████| 11/11 [00:16<00:00,  1.53s/it, loss=37.6903, avg_loss=35.8153]
INFO:__main__:=== EPOCH 67 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.815325
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.916233
INFO:__main__:   • gene_density: 1.188388
INFO:__main__:   • operon_membership: 11.710705
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 68/681
INFO:__main__:Epoch 68/681
INFO:__main__:Epoch 68/681
INFO:__main__:Epoch 68/681
Epoch 68:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 68:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 68:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 68:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 68:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5617, avg_loss=34.5617]Epoch 68:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4889, avg_loss=36.4889]Epoch 68:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5746, avg_loss=35.5746]Epoch 68:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1149, avg_loss=38.1149]Epoch 68:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  18%|█▊        | 2/11 [00:03<00:13,  1.48s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:  18%|█▊        | 2/11 [00:03<00:13,  1.48s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:  18%|█▊        | 2/11 [00:03<00:13,  1.48s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:  18%|█▊        | 2/11 [00:03<00:13,  1.48s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  36%|███▋      | 4/11 [00:04<00:07,  1.11s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:  36%|███▋      | 4/11 [00:04<00:07,  1.11s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:  36%|███▋      | 4/11 [00:04<00:07,  1.11s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:  36%|███▋      | 4/11 [00:04<00:07,  1.12s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  45%|████▌     | 5/11 [00:06<00:07,  1.24s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:  45%|████▌     | 5/11 [00:06<00:07,  1.24s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:  45%|████▌     | 5/11 [00:06<00:07,  1.24s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:  45%|████▌     | 5/11 [00:06<00:07,  1.24s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  64%|██████▎   | 7/11 [00:09<00:05,  1.34s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:  64%|██████▎   | 7/11 [00:09<00:05,  1.34s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:  64%|██████▎   | 7/11 [00:09<00:05,  1.34s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:  64%|██████▎   | 7/11 [00:09<00:05,  1.34s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  82%|████████▏ | 9/11 [00:12<00:02,  1.38s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:  82%|████████▏ | 9/11 [00:12<00:02,  1.38s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:  82%|████████▏ | 9/11 [00:12<00:02,  1.38s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:  82%|████████▏ | 9/11 [00:12<00:02,  1.38s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=34.5617, avg_loss=34.5617]Epoch 68:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=36.4889, avg_loss=36.4889]Epoch 68:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=35.5746, avg_loss=35.5746]Epoch 68:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=38.1149, avg_loss=38.1149]Epoch 68:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=34.8505, avg_loss=36.7011]Epoch 68: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=34.8505, avg_loss=36.7011]Epoch 68: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.8505, avg_loss=36.7011]
INFO:__main__:=== EPOCH 68 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.701050
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.497520
INFO:__main__:   • gene_density: 1.182292
INFO:__main__:   • operon_membership: 11.021239
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 68:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=36.8001, avg_loss=35.5599]Epoch 68:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=34.9282, avg_loss=35.3484]Epoch 68: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=36.8001, avg_loss=35.5599]Epoch 68: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=34.9282, avg_loss=35.3484]Epoch 68: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=36.8001, avg_loss=35.5599]
Epoch 68: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.9282, avg_loss=35.3484]
INFO:__main__:=== EPOCH 68 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.559906
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 68 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 22.693127
INFO:__main__:   • gene_density: 1.186731
INFO:__main__:🔢 Total Loss: 35.348421
INFO:__main__:   • operon_membership: 11.680049
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 22.940551
INFO:__main__:   • gene_density: 1.185724
INFO:__main__:   • operon_membership: 11.222146
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 68:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.9532, avg_loss=35.6391]Epoch 68: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=35.9532, avg_loss=35.6391]Epoch 68: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.9532, avg_loss=35.6391]
INFO:__main__:=== EPOCH 68 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.639060
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.821493
INFO:__main__:   • gene_density: 1.175012
INFO:__main__:   • operon_membership: 12.642554
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 69/681
INFO:__main__:Epoch 69/681
INFO:__main__:Epoch 69/681
INFO:__main__:Epoch 69/681
Epoch 69:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 69:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 69:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 69:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 69:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8507, avg_loss=35.8507]Epoch 69:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.8675, avg_loss=38.8675]Epoch 69:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7102, avg_loss=37.7102]Epoch 69:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6827, avg_loss=37.6827]Epoch 69:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  27%|██▋       | 3/11 [00:04<00:11,  1.39s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:  27%|██▋       | 3/11 [00:04<00:11,  1.39s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  36%|███▋      | 4/11 [00:05<00:08,  1.19s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:  36%|███▋      | 4/11 [00:05<00:08,  1.19s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  36%|███▋      | 4/11 [00:05<00:08,  1.19s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:  36%|███▋      | 4/11 [00:05<00:08,  1.20s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:  45%|████▌     | 5/11 [00:06<00:06,  1.06s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:  45%|████▌     | 5/11 [00:06<00:06,  1.06s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  45%|████▌     | 5/11 [00:06<00:06,  1.06s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:  45%|████▌     | 5/11 [00:06<00:06,  1.06s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:  55%|█████▍    | 6/11 [00:07<00:05,  1.17s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  64%|██████▎   | 7/11 [00:08<00:04,  1.24s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:  64%|██████▎   | 7/11 [00:08<00:04,  1.24s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:  64%|██████▎   | 7/11 [00:08<00:04,  1.24s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:  64%|██████▎   | 7/11 [00:08<00:04,  1.24s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:  73%|███████▎  | 8/11 [00:10<00:03,  1.30s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=35.8507, avg_loss=35.8507]Epoch 69:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=37.7102, avg_loss=37.7102]Epoch 69:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=38.8675, avg_loss=38.8675]Epoch 69:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=37.6827, avg_loss=37.6827]Epoch 69:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=34.5850, avg_loss=35.0819]Epoch 69: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=34.5850, avg_loss=35.0819]Epoch 69:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=38.6366, avg_loss=36.5390]Epoch 69: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=38.6366, avg_loss=36.5390]Epoch 69: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=34.5850, avg_loss=35.0819]
Epoch 69: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=38.6366, avg_loss=36.5390]
INFO:__main__:=== EPOCH 69 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.081918
INFO:__main__:=== EPOCH 69 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.680022
INFO:__main__:🔢 Total Loss: 36.539009
INFO:__main__:   • gene_density: 1.185251
INFO:__main__:   • operon_membership: 11.216644
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_expression: 23.390549
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.170218
INFO:__main__:   • operon_membership: 11.978242
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 69:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=36.4763, avg_loss=35.5385]Epoch 69: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=36.4763, avg_loss=35.5385]Epoch 69: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=36.4763, avg_loss=35.5385]
INFO:__main__:=== EPOCH 69 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.538466
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.791782
INFO:__main__:   • gene_density: 1.199988
INFO:__main__:   • operon_membership: 11.546696
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 69:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=38.5393, avg_loss=35.9947]Epoch 69: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=38.5393, avg_loss=35.9947]Epoch 69: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=38.5393, avg_loss=35.9947]
INFO:__main__:=== EPOCH 69 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.994673
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.030544
INFO:__main__:   • gene_density: 1.178563
INFO:__main__:   • operon_membership: 11.785565
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 70/681
INFO:__main__:Epoch 70/681
INFO:__main__:Epoch 70/681
INFO:__main__:Epoch 70/681
Epoch 70:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 70:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 70:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 70:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 70:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2378, avg_loss=34.2378]Epoch 70:   9%|▉         | 1/11 [00:01<00:16,  1.61s/it, loss=34.2378, avg_loss=34.2378]Epoch 70:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8186, avg_loss=36.8186]Epoch 70:   9%|▉         | 1/11 [00:01<00:16,  1.62s/it, loss=36.8186, avg_loss=36.8186]Epoch 70:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8794, avg_loss=35.8794]Epoch 70:   9%|▉         | 1/11 [00:01<00:16,  1.62s/it, loss=35.8794, avg_loss=35.8794]Epoch 70:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5553, avg_loss=34.5553]Epoch 70:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=34.5553, avg_loss=34.5553]Epoch 70:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=34.2378, avg_loss=34.2378]Epoch 70:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=36.8186, avg_loss=36.8186]Epoch 70:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=34.5553, avg_loss=34.5553]Epoch 70:  18%|█▊        | 2/11 [00:02<00:13,  1.45s/it, loss=35.8794, avg_loss=35.8794]Epoch 70:  27%|██▋       | 3/11 [00:03<00:09,  1.17s/it, loss=34.2378, avg_loss=34.2378]Epoch 70:  27%|██▋       | 3/11 [00:03<00:09,  1.17s/it, loss=36.8186, avg_loss=36.8186]Epoch 70:  27%|██▋       | 3/11 [00:03<00:09,  1.16s/it, loss=34.5553, avg_loss=34.5553]Epoch 70:  27%|██▋       | 3/11 [00:03<00:09,  1.17s/it, loss=35.8794, avg_loss=35.8794]Epoch 70:  36%|███▋      | 4/11 [00:04<00:07,  1.09s/it, loss=34.2378, avg_loss=34.2378]Epoch 70:  36%|███▋      | 4/11 [00:04<00:07,  1.10s/it, loss=35.8794, avg_loss=35.8794]Epoch 70:  36%|███▋      | 4/11 [00:04<00:07,  1.10s/it, loss=36.8186, avg_loss=36.8186]Epoch 70:  36%|███▋      | 4/11 [00:04<00:07,  1.10s/it, loss=34.5553, avg_loss=34.5553]Epoch 70:  45%|████▌     | 5/11 [00:05<00:06,  1.03s/it, loss=34.2378, avg_loss=34.2378]Epoch 70:  45%|████▌     | 5/11 [00:05<00:06,  1.02s/it, loss=36.8186, avg_loss=36.8186]Epoch 70:  45%|████▌     | 5/11 [00:05<00:06,  1.02s/it, loss=34.5553, avg_loss=34.5553]Epoch 70:  45%|████▌     | 5/11 [00:05<00:06,  1.03s/it, loss=35.8794, avg_loss=35.8794]Epoch 70:  55%|█████▍    | 6/11 [00:06<00:04,  1.04it/s, loss=36.8186, avg_loss=36.8186]Epoch 70:  55%|█████▍    | 6/11 [00:06<00:04,  1.04it/s, loss=34.2378, avg_loss=34.2378]Epoch 70:  55%|█████▍    | 6/11 [00:06<00:04,  1.04it/s, loss=34.5553, avg_loss=34.5553]Epoch 70:  55%|█████▍    | 6/11 [00:06<00:04,  1.04it/s, loss=35.8794, avg_loss=35.8794]Epoch 70:  64%|██████▎   | 7/11 [00:07<00:03,  1.09it/s, loss=34.2378, avg_loss=34.2378]Epoch 70:  64%|██████▎   | 7/11 [00:07<00:03,  1.09it/s, loss=34.5553, avg_loss=34.5553]Epoch 70:  64%|██████▎   | 7/11 [00:07<00:03,  1.09it/s, loss=35.8794, avg_loss=35.8794]Epoch 70:  64%|██████▎   | 7/11 [00:07<00:03,  1.09it/s, loss=36.8186, avg_loss=36.8186]Epoch 70:  73%|███████▎  | 8/11 [00:08<00:02,  1.13it/s, loss=36.8186, avg_loss=36.8186]Epoch 70:  73%|███████▎  | 8/11 [00:08<00:02,  1.13it/s, loss=34.5553, avg_loss=34.5553]Epoch 70:  73%|███████▎  | 8/11 [00:08<00:02,  1.13it/s, loss=35.8794, avg_loss=35.8794]Epoch 70:  73%|███████▎  | 8/11 [00:08<00:02,  1.12it/s, loss=34.2378, avg_loss=34.2378]Epoch 70:  82%|████████▏ | 9/11 [00:08<00:01,  1.15it/s, loss=36.8186, avg_loss=36.8186]Epoch 70:  82%|████████▏ | 9/11 [00:08<00:01,  1.15it/s, loss=35.8794, avg_loss=35.8794]Epoch 70:  82%|████████▏ | 9/11 [00:08<00:01,  1.15it/s, loss=34.5553, avg_loss=34.5553]Epoch 70:  82%|████████▏ | 9/11 [00:08<00:01,  1.15it/s, loss=34.2378, avg_loss=34.2378]Epoch 70:  91%|█████████ | 10/11 [00:09<00:00,  1.17it/s, loss=34.5553, avg_loss=34.5553]Epoch 70:  91%|█████████ | 10/11 [00:09<00:00,  1.16it/s, loss=35.8794, avg_loss=35.8794]Epoch 70:  91%|█████████ | 10/11 [00:09<00:00,  1.16it/s, loss=36.8186, avg_loss=36.8186]Epoch 70:  91%|█████████ | 10/11 [00:09<00:00,  1.16it/s, loss=34.2378, avg_loss=34.2378]Epoch 70:  91%|█████████ | 10/11 [00:10<00:00,  1.16it/s, loss=35.8947, avg_loss=36.4396]Epoch 70: 100%|██████████| 11/11 [00:10<00:00,  1.11it/s, loss=35.8947, avg_loss=36.4396]Epoch 70: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s, loss=35.8947, avg_loss=36.4396]
INFO:__main__:=== EPOCH 70 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.439558
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.412153
INFO:__main__:   • gene_density: 1.179510
INFO:__main__:   • operon_membership: 11.847895
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 70:  91%|█████████ | 10/11 [00:10<00:00,  1.17it/s, loss=35.2044, avg_loss=35.4631]Epoch 70: 100%|██████████| 11/11 [00:10<00:00,  1.11it/s, loss=35.2044, avg_loss=35.4631]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 70: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s, loss=35.2044, avg_loss=35.4631]
INFO:__main__:=== EPOCH 70 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.463113
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.093539
INFO:__main__:   • gene_density: 1.170218
INFO:__main__:   • operon_membership: 12.199356
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 70:  91%|█████████ | 10/11 [00:10<00:00,  1.16it/s, loss=33.5677, avg_loss=35.7059]Epoch 70: 100%|██████████| 11/11 [00:10<00:00,  1.10it/s, loss=33.5677, avg_loss=35.7059]Epoch 70: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s, loss=33.5677, avg_loss=35.7059]
Epoch 70:  91%|█████████ | 10/11 [00:10<00:00,  1.16it/s, loss=36.8830, avg_loss=35.3304]Epoch 70: 100%|██████████| 11/11 [00:10<00:00,  1.10it/s, loss=36.8830, avg_loss=35.3304]Epoch 70: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s, loss=36.8830, avg_loss=35.3304]
INFO:__main__:=== EPOCH 70 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.705926
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.377120
INFO:__main__:   • gene_density: 1.187855
INFO:__main__:   • operon_membership: 11.140951
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 70 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.330392
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.573149
INFO:__main__:   • gene_density: 1.191821
INFO:__main__:   • operon_membership: 11.565423
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.70it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.72it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.73it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.72it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.30it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.29it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.30it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.30it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.56it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.57it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.57it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.57it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.30it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.30it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.28it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.27it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.28it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.28it/s]

INFO:__main__:=== EPOCH 70 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 70 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:=== EPOCH 70 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 70 VALIDATION LOSSES ===
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_70.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_70.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_70.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_70.pt
INFO:__main__:Epoch 71/681
INFO:__main__:Epoch 71/681
INFO:__main__:Epoch 71/681
INFO:__main__:Epoch 71/681
Epoch 71:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 71:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 71:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 71:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 71:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.0996, avg_loss=38.0996]Epoch 71:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5015, avg_loss=36.5015]Epoch 71:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.3664, avg_loss=36.3664]Epoch 71:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.1266, avg_loss=33.1266]Epoch 71:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:  55%|█████▍    | 6/11 [00:08<00:06,  1.40s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:  55%|█████▍    | 6/11 [00:08<00:06,  1.40s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  64%|██████▎   | 7/11 [00:09<00:05,  1.33s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:  64%|██████▎   | 7/11 [00:09<00:05,  1.33s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:  64%|██████▎   | 7/11 [00:09<00:05,  1.33s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:  64%|██████▎   | 7/11 [00:09<00:05,  1.33s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  73%|███████▎  | 8/11 [00:10<00:03,  1.19s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:  73%|███████▎  | 8/11 [00:10<00:03,  1.19s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  73%|███████▎  | 8/11 [00:10<00:03,  1.19s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:  73%|███████▎  | 8/11 [00:10<00:03,  1.19s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=36.5015, avg_loss=36.5015]Epoch 71:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=38.0996, avg_loss=38.0996]Epoch 71:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=36.3664, avg_loss=36.3664]Epoch 71:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=33.1266, avg_loss=33.1266]Epoch 71:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=34.8740, avg_loss=36.1090]Epoch 71:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=37.3750, avg_loss=35.7361]Epoch 71: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=34.8740, avg_loss=36.1090]Epoch 71: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=37.3750, avg_loss=35.7361]Epoch 71: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.8740, avg_loss=36.1090]
Epoch 71: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.3750, avg_loss=35.7361]
INFO:__main__:=== EPOCH 71 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 71 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.109018
INFO:__main__:🔢 Total Loss: 35.736068
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.402514
INFO:__main__:   • gene_expression: 22.960588
INFO:__main__:   • gene_density: 1.190459
INFO:__main__:   • gene_density: 1.187678
INFO:__main__:   • operon_membership: 12.516045
INFO:__main__:   • operon_membership: 11.587802
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 71:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=34.2584, avg_loss=35.6700]Epoch 71: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=34.2584, avg_loss=35.6700]Epoch 71: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.2584, avg_loss=35.6700]
INFO:__main__:=== EPOCH 71 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.669992
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.556096
INFO:__main__:   • gene_density: 1.184718
INFO:__main__:   • operon_membership: 10.929177
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 71:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=34.4010, avg_loss=35.4651]Epoch 71: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.4010, avg_loss=35.4651]Epoch 71: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.4010, avg_loss=35.4651]
INFO:__main__:=== EPOCH 71 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.465138
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.658654
INFO:__main__:   • gene_density: 1.170455
INFO:__main__:   • operon_membership: 11.636029
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 72/681
INFO:__main__:Epoch 72/681
INFO:__main__:Epoch 72/681
INFO:__main__:Epoch 72/681
Epoch 72:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 72:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 72:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 72:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 72:   0%|          | 0/11 [00:01<?, ?it/s, loss=40.5921, avg_loss=40.5921]Epoch 72:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.7046, avg_loss=34.7046]Epoch 72:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6288, avg_loss=36.6288]Epoch 72:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2700, avg_loss=35.2700]Epoch 72:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  55%|█████▍    | 6/11 [00:08<00:07,  1.48s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  82%|████████▏ | 9/11 [00:12<00:02,  1.27s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  82%|████████▏ | 9/11 [00:12<00:02,  1.27s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:  82%|████████▏ | 9/11 [00:12<00:02,  1.28s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:  82%|████████▏ | 9/11 [00:12<00:02,  1.28s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=34.7046, avg_loss=34.7046]Epoch 72:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=36.6288, avg_loss=36.6288]Epoch 72:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=35.2700, avg_loss=35.2700]Epoch 72:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=40.5921, avg_loss=40.5921]Epoch 72:  91%|█████████ | 10/11 [00:15<00:01,  1.14s/it, loss=35.0834, avg_loss=36.0533]Epoch 72:  91%|█████████ | 10/11 [00:15<00:01,  1.14s/it, loss=34.9063, avg_loss=34.8311]Epoch 72: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=35.0834, avg_loss=36.0533]Epoch 72: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=34.9063, avg_loss=34.8311]Epoch 72: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.0834, avg_loss=36.0533]Epoch 72: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.9063, avg_loss=34.8311]

INFO:__main__:=== EPOCH 72 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.831145
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 72 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 22.380768
INFO:__main__:   • gene_density: 1.179865
INFO:__main__:🔢 Total Loss: 36.053280
INFO:__main__:   • operon_membership: 11.270512
INFO:__main__:👥 Samples processed: 22
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 23.207750
INFO:__main__:   • gene_density: 1.194010
INFO:__main__:   • operon_membership: 11.651519
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 72:  91%|█████████ | 10/11 [00:15<00:01,  1.14s/it, loss=38.9319, avg_loss=36.1405]Epoch 72: 100%|██████████| 11/11 [00:15<00:00,  1.28s/it, loss=38.9319, avg_loss=36.1405]Epoch 72: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=38.9319, avg_loss=36.1405]
INFO:__main__:=== EPOCH 72 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.140514
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.401215
INFO:__main__:   • gene_density: 1.170455
INFO:__main__:   • operon_membership: 11.568844
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 72:  91%|█████████ | 10/11 [00:15<00:01,  1.13s/it, loss=35.3629, avg_loss=35.9553]Epoch 72: 100%|██████████| 11/11 [00:15<00:00,  1.28s/it, loss=35.3629, avg_loss=35.9553]Epoch 72: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.3629, avg_loss=35.9553]
INFO:__main__:=== EPOCH 72 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.955276
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.588118
INFO:__main__:   • gene_density: 1.188980
INFO:__main__:   • operon_membership: 12.178179
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 73/681
INFO:__main__:Epoch 73/681
INFO:__main__:Epoch 73/681
INFO:__main__:Epoch 73/681
Epoch 73:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 73:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 73:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 73:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 73:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2254, avg_loss=34.2254]Epoch 73:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.8618, avg_loss=37.8618]Epoch 73:   0%|          | 0/11 [00:01<?, ?it/s, loss=40.8259, avg_loss=40.8259]Epoch 73:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9741, avg_loss=33.9741]Epoch 73:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  82%|████████▏ | 9/11 [00:13<00:02,  1.39s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:  82%|████████▏ | 9/11 [00:13<00:02,  1.39s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:  82%|████████▏ | 9/11 [00:13<00:02,  1.39s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  91%|█████████ | 10/11 [00:14<00:01,  1.32s/it, loss=34.2254, avg_loss=34.2254]Epoch 73:  91%|█████████ | 10/11 [00:14<00:01,  1.32s/it, loss=40.8259, avg_loss=40.8259]Epoch 73:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=37.8618, avg_loss=37.8618]Epoch 73:  91%|█████████ | 10/11 [00:14<00:01,  1.32s/it, loss=33.9741, avg_loss=33.9741]Epoch 73:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=33.3443, avg_loss=34.9095]Epoch 73: 100%|██████████| 11/11 [00:15<00:00,  1.24s/it, loss=33.3443, avg_loss=34.9095]Epoch 73:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=37.2438, avg_loss=36.1797]Epoch 73: 100%|██████████| 11/11 [00:15<00:00,  1.24s/it, loss=37.2438, avg_loss=36.1797]Epoch 73: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=33.3443, avg_loss=34.9095]
Epoch 73: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=37.2438, avg_loss=36.1797]
INFO:__main__:=== EPOCH 73 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.909486
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.254941
INFO:__main__:=== EPOCH 73 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.184837
INFO:__main__:   • operon_membership: 11.469708
INFO:__main__:🔢 Total Loss: 36.179668
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.067886
INFO:__main__:   • gene_density: 1.168265
INFO:__main__:   • operon_membership: 11.943517
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 73:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=35.2601, avg_loss=36.5663]Epoch 73: 100%|██████████| 11/11 [00:15<00:00,  1.24s/it, loss=35.2601, avg_loss=36.5663]Epoch 73: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.2601, avg_loss=36.5663]
INFO:__main__:=== EPOCH 73 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.566274
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.589564
INFO:__main__:   • gene_density: 1.190637
INFO:__main__:   • operon_membership: 11.786074
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 73:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=31.8912, avg_loss=35.4059]Epoch 73: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=31.8912, avg_loss=35.4059]Epoch 73: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=31.8912, avg_loss=35.4059]
INFO:__main__:=== EPOCH 73 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.405926
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.739985
INFO:__main__:   • gene_density: 1.187678
INFO:__main__:   • operon_membership: 11.478263
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 74/681
INFO:__main__:Epoch 74/681
INFO:__main__:Epoch 74/681
INFO:__main__:Epoch 74/681
Epoch 74:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 74:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 74:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 74:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 74:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9024, avg_loss=36.9024]Epoch 74:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.3831, avg_loss=37.3831]Epoch 74:   0%|          | 0/11 [00:01<?, ?it/s, loss=41.7193, avg_loss=41.7193]Epoch 74:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6026, avg_loss=33.6026]Epoch 74:   9%|▉         | 1/11 [00:01<00:15,  1.57s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  18%|█▊        | 2/11 [00:02<00:13,  1.49s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:  18%|█▊        | 2/11 [00:02<00:13,  1.49s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:  18%|█▊        | 2/11 [00:02<00:13,  1.49s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=37.3831, avg_loss=37.3831]Epoch 74:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=36.9024, avg_loss=36.9024]Epoch 74:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=41.7193, avg_loss=41.7193]Epoch 74:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=33.6026, avg_loss=33.6026]Epoch 74:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.9393, avg_loss=36.6994]Epoch 74: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.9393, avg_loss=36.6994]Epoch 74:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=34.7872, avg_loss=35.2542]Epoch 74: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.7872, avg_loss=35.2542]Epoch 74: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=35.9393, avg_loss=36.6994]
Epoch 74: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=34.7872, avg_loss=35.2542]
INFO:__main__:=== EPOCH 74 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.699435
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.136632
INFO:__main__:   • gene_density: 1.175308
INFO:__main__:   • operon_membership: 11.387496
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 74 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.254195
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.591903
INFO:__main__:   • gene_density: 1.192353
INFO:__main__:   • operon_membership: 11.469940
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 74:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=37.9230, avg_loss=35.7337]Epoch 74: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.9230, avg_loss=35.7337]Epoch 74: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=37.9230, avg_loss=35.7337]
INFO:__main__:=== EPOCH 74 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.733652
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.883574
INFO:__main__:   • gene_density: 1.173769
INFO:__main__:   • operon_membership: 12.676309
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 74:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.3556, avg_loss=35.6064]Epoch 74: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.3556, avg_loss=35.6064]Epoch 74: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=35.3556, avg_loss=35.6064]
INFO:__main__:=== EPOCH 74 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.606370
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.322097
INFO:__main__:   • gene_density: 1.190578
INFO:__main__:   • operon_membership: 11.093695
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 75/681
INFO:__main__:Epoch 75/681
INFO:__main__:Epoch 75/681
INFO:__main__:Epoch 75/681
Epoch 75:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 75:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 75:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 75:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 75:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9024, avg_loss=36.9024]Epoch 75:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8315, avg_loss=36.8315]Epoch 75:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.6959, avg_loss=38.6959]Epoch 75:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7587, avg_loss=37.7587]Epoch 75:   9%|▉         | 1/11 [00:01<00:14,  1.40s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  18%|█▊        | 2/11 [00:02<00:09,  1.08s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:  18%|█▊        | 2/11 [00:02<00:09,  1.08s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:  18%|█▊        | 2/11 [00:02<00:09,  1.08s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:  18%|█▊        | 2/11 [00:02<00:09,  1.09s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  27%|██▋       | 3/11 [00:03<00:08,  1.06s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:  27%|██▋       | 3/11 [00:03<00:08,  1.07s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:  27%|██▋       | 3/11 [00:03<00:08,  1.07s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:  27%|██▋       | 3/11 [00:03<00:08,  1.07s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:  36%|███▋      | 4/11 [00:04<00:08,  1.24s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:  45%|████▌     | 5/11 [00:06<00:07,  1.32s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=38.6959, avg_loss=38.6959]Epoch 75:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=36.9024, avg_loss=36.9024]Epoch 75:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=36.8315, avg_loss=36.8315]Epoch 75:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=37.7587, avg_loss=37.7587]Epoch 75:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=38.1587, avg_loss=36.1389]Epoch 75: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=38.1587, avg_loss=36.1389]Epoch 75:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=40.2096, avg_loss=35.2342]Epoch 75: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=40.2096, avg_loss=35.2342]Epoch 75: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=38.1587, avg_loss=36.1389]
Epoch 75: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=40.2096, avg_loss=35.2342]
Epoch 75:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=32.9231, avg_loss=35.5692]Epoch 75: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=32.9231, avg_loss=35.5692]Epoch 75: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=32.9231, avg_loss=35.5692]INFO:__main__:=== EPOCH 75 TRAINING LOSSES ===

INFO:__main__:🔢 Total Loss: 36.138932
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.081573
INFO:__main__:   • gene_density: 1.183061
INFO:__main__:   • operon_membership: 11.874298
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 75 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.234176
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.610329
INFO:__main__:   • gene_density: 1.189927
INFO:__main__:   • operon_membership: 11.433919
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 75 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.569195
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.220066
INFO:__main__:   • gene_density: 1.191110
INFO:__main__:   • operon_membership: 12.158019
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 75:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=34.5949, avg_loss=36.1543]Epoch 75: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=34.5949, avg_loss=36.1543]Epoch 75: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.5949, avg_loss=36.1543]
INFO:__main__:=== EPOCH 75 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.154318
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.968188
INFO:__main__:   • gene_density: 1.167850
INFO:__main__:   • operon_membership: 11.018279
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.71it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.71it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.71it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.71it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]
INFO:__main__:=== EPOCH 75 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:=== EPOCH 75 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:=== EPOCH 75 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.61it/s]
INFO:__main__:=== EPOCH 75 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 76/681
INFO:__main__:Epoch 76/681
INFO:__main__:Epoch 76/681
INFO:__main__:Epoch 76/681
Epoch 76:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 76:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 76:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 76:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 76:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.9334, avg_loss=34.9334]Epoch 76:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9863, avg_loss=35.9863]Epoch 76:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.6315, avg_loss=35.6315]Epoch 76:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.0697, avg_loss=37.0697]Epoch 76:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:  27%|██▋       | 3/11 [00:03<00:08,  1.11s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:  27%|██▋       | 3/11 [00:03<00:08,  1.11s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:  27%|██▋       | 3/11 [00:03<00:08,  1.11s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  27%|██▋       | 3/11 [00:03<00:08,  1.12s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:  36%|███▋      | 4/11 [00:04<00:08,  1.24s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:  36%|███▋      | 4/11 [00:04<00:08,  1.24s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:  36%|███▋      | 4/11 [00:04<00:08,  1.24s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  36%|███▋      | 4/11 [00:04<00:08,  1.24s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:  82%|████████▏ | 9/11 [00:11<00:02,  1.42s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=37.0697, avg_loss=37.0697]Epoch 76:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=35.6315, avg_loss=35.6315]Epoch 76:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=35.9863, avg_loss=35.9863]Epoch 76:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=34.9334, avg_loss=34.9334]Epoch 76:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=37.8741, avg_loss=36.4673]Epoch 76: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=37.8741, avg_loss=36.4673]Epoch 76: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.8741, avg_loss=36.4673]
INFO:__main__:=== EPOCH 76 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.467264
INFO:__main__:📊 Individual Modality Losses:
Epoch 76:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=33.6559, avg_loss=35.3917]INFO:__main__:   • gene_expression: 23.041082
INFO:__main__:   • gene_density: 1.186967
INFO:__main__:   • operon_membership: 12.239214
INFO:__main__:👥 Samples processed: 22
Epoch 76: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=33.6559, avg_loss=35.3917]INFO:__main__:========================================
Epoch 76: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.6559, avg_loss=35.3917]
INFO:__main__:=== EPOCH 76 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.391743
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.000066
INFO:__main__:   • gene_density: 1.180398
INFO:__main__:   • operon_membership: 11.211280
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 76:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=40.5468, avg_loss=36.0426]Epoch 76: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=40.5468, avg_loss=36.0426]Epoch 76: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=40.5468, avg_loss=36.0426]
INFO:__main__:=== EPOCH 76 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.042640
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.586330
INFO:__main__:   • gene_density: 1.179510
INFO:__main__:   • operon_membership: 11.276800
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 76:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.0377, avg_loss=35.5012]Epoch 76: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.0377, avg_loss=35.5012]Epoch 76: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.0377, avg_loss=35.5012]
INFO:__main__:=== EPOCH 76 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.501177
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.362882
INFO:__main__:   • gene_density: 1.187796
INFO:__main__:   • operon_membership: 11.950499
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 77/681
INFO:__main__:Epoch 77/681
INFO:__main__:Epoch 77/681
INFO:__main__:Epoch 77/681
Epoch 77:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 77:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 77:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 77:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 77:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9581, avg_loss=36.9581]Epoch 77:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5735, avg_loss=34.5735]Epoch 77:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4798, avg_loss=35.4798]Epoch 77:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8770, avg_loss=35.8770]Epoch 77:   9%|▉         | 1/11 [00:01<00:15,  1.57s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:  36%|███▋      | 4/11 [00:04<00:07,  1.06s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:  36%|███▋      | 4/11 [00:04<00:07,  1.06s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:  36%|███▋      | 4/11 [00:04<00:07,  1.06s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  36%|███▋      | 4/11 [00:04<00:07,  1.06s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:  45%|████▌     | 5/11 [00:06<00:07,  1.19s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:  45%|████▌     | 5/11 [00:06<00:07,  1.19s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:  45%|████▌     | 5/11 [00:06<00:07,  1.19s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  55%|█████▍    | 6/11 [00:07<00:06,  1.28s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:  55%|█████▍    | 6/11 [00:07<00:06,  1.28s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:  55%|█████▍    | 6/11 [00:07<00:06,  1.28s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:  55%|█████▍    | 6/11 [00:07<00:06,  1.28s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=34.5735, avg_loss=34.5735]Epoch 77:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=36.9581, avg_loss=36.9581]Epoch 77:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=35.4798, avg_loss=35.4798]Epoch 77:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=35.8770, avg_loss=35.8770]Epoch 77:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.0617, avg_loss=36.0807]Epoch 77: 100%|██████████| 11/11 [00:14<00:00,  1.48s/it, loss=35.0617, avg_loss=36.0807]Epoch 77: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.0617, avg_loss=36.0807]
INFO:__main__:=== EPOCH 77 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.080698
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.247907
INFO:__main__:   • gene_density: 1.178267
INFO:__main__:   • operon_membership: 11.654525
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 77:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.7181, avg_loss=35.0369]Epoch 77: 100%|██████████| 11/11 [00:14<00:00,  1.48s/it, loss=35.7181, avg_loss=35.0369]Epoch 77:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=38.5346, avg_loss=35.9049]Epoch 77: 100%|██████████| 11/11 [00:14<00:00,  1.48s/it, loss=38.5346, avg_loss=35.9049]Epoch 77: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.7181, avg_loss=35.0369]
Epoch 77: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=38.5346, avg_loss=35.9049]
INFO:__main__:=== EPOCH 77 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.036867
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.236640
INFO:__main__:   • gene_density: 1.187322
INFO:__main__:   • operon_membership: 10.612904
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 77 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.904896
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.974483
INFO:__main__:   • gene_density: 1.188861
INFO:__main__:   • operon_membership: 12.741552
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 77:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=37.3078, avg_loss=36.0021]Epoch 77: 100%|██████████| 11/11 [00:14<00:00,  1.48s/it, loss=37.3078, avg_loss=36.0021]Epoch 77: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.3078, avg_loss=36.0021]
INFO:__main__:=== EPOCH 77 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.002149
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.168281
INFO:__main__:   • gene_density: 1.179806
INFO:__main__:   • operon_membership: 11.654062
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 78/681
INFO:__main__:Epoch 78/681
INFO:__main__:Epoch 78/681
INFO:__main__:Epoch 78/681
Epoch 78:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 78:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 78:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 78:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 78:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.0004, avg_loss=39.0004]Epoch 78:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0854, avg_loss=35.0854]Epoch 78:   0%|          | 0/11 [00:01<?, ?it/s, loss=42.4805, avg_loss=42.4805]Epoch 78:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4971, avg_loss=34.4971]Epoch 78:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  45%|████▌     | 5/11 [00:06<00:06,  1.14s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:  45%|████▌     | 5/11 [00:06<00:06,  1.14s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:  45%|████▌     | 5/11 [00:06<00:06,  1.14s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:  45%|████▌     | 5/11 [00:06<00:06,  1.14s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  55%|█████▍    | 6/11 [00:07<00:05,  1.17s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:  55%|█████▍    | 6/11 [00:07<00:05,  1.17s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:  55%|█████▍    | 6/11 [00:07<00:05,  1.18s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:  55%|█████▍    | 6/11 [00:07<00:05,  1.18s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  64%|██████▎   | 7/11 [00:09<00:05,  1.28s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:  64%|██████▎   | 7/11 [00:09<00:05,  1.28s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:  64%|██████▎   | 7/11 [00:09<00:05,  1.28s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:  64%|██████▎   | 7/11 [00:09<00:05,  1.28s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  73%|███████▎  | 8/11 [00:10<00:04,  1.34s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:  73%|███████▎  | 8/11 [00:10<00:04,  1.34s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:  73%|███████▎  | 8/11 [00:10<00:04,  1.34s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=35.0854, avg_loss=35.0854]Epoch 78:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=42.4805, avg_loss=42.4805]Epoch 78:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=39.0004, avg_loss=39.0004]Epoch 78:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=34.4971, avg_loss=34.4971]Epoch 78:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=36.0167, avg_loss=35.4720]Epoch 78:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=36.2929, avg_loss=36.2827]Epoch 78: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=36.0167, avg_loss=35.4720]Epoch 78: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=36.2929, avg_loss=36.2827]Epoch 78: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.0167, avg_loss=35.4720]
Epoch 78: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.2929, avg_loss=36.2827]
Epoch 78:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=39.1886, avg_loss=36.1619]Epoch 78: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=39.1886, avg_loss=36.1619]Epoch 78: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=39.1886, avg_loss=36.1619]
INFO:__main__:=== EPOCH 78 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 78 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.282688
INFO:__main__:🔢 Total Loss: 35.471962
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.564898
INFO:__main__:   • gene_expression: 22.714402
INFO:__main__:   • gene_density: 1.164477
INFO:__main__:   • gene_density: 1.186080
INFO:__main__:   • operon_membership: 12.553314
INFO:__main__:   • operon_membership: 11.571480
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 78 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.161851
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.546405
INFO:__main__:   • gene_density: 1.191051
INFO:__main__:   • operon_membership: 11.424394
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 78:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=31.7457, avg_loss=35.2200]Epoch 78: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=31.7457, avg_loss=35.2200]Epoch 78: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=31.7457, avg_loss=35.2200]
INFO:__main__:=== EPOCH 78 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.220038
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.945392
INFO:__main__:   • gene_density: 1.192649
INFO:__main__:   • operon_membership: 11.081996
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 79/681
INFO:__main__:Epoch 79/681
INFO:__main__:Epoch 79/681
INFO:__main__:Epoch 79/681
Epoch 79:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 79:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 79:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 79:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 79:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.7354, avg_loss=33.7354]Epoch 79:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.0385, avg_loss=38.0385]Epoch 79:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0096, avg_loss=34.0096]Epoch 79:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5748, avg_loss=37.5748]Epoch 79:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  45%|████▌     | 5/11 [00:07<00:07,  1.31s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:  45%|████▌     | 5/11 [00:07<00:07,  1.31s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:  45%|████▌     | 5/11 [00:07<00:07,  1.31s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:  45%|████▌     | 5/11 [00:07<00:07,  1.31s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  55%|█████▍    | 6/11 [00:07<00:05,  1.20s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:  55%|█████▍    | 6/11 [00:07<00:05,  1.20s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:  55%|█████▍    | 6/11 [00:07<00:05,  1.20s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:  55%|█████▍    | 6/11 [00:07<00:05,  1.19s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  64%|██████▎   | 7/11 [00:08<00:04,  1.12s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:  64%|██████▎   | 7/11 [00:08<00:04,  1.12s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:  64%|██████▎   | 7/11 [00:08<00:04,  1.12s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:  64%|██████▎   | 7/11 [00:08<00:04,  1.12s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  73%|███████▎  | 8/11 [00:10<00:03,  1.22s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:  73%|███████▎  | 8/11 [00:10<00:03,  1.22s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:  73%|███████▎  | 8/11 [00:10<00:03,  1.22s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:  73%|███████▎  | 8/11 [00:10<00:03,  1.22s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  91%|█████████ | 10/11 [00:13<00:01,  1.35s/it, loss=38.0385, avg_loss=38.0385]Epoch 79:  91%|█████████ | 10/11 [00:13<00:01,  1.35s/it, loss=34.0096, avg_loss=34.0096]Epoch 79:  91%|█████████ | 10/11 [00:13<00:01,  1.35s/it, loss=33.7354, avg_loss=33.7354]Epoch 79:  91%|█████████ | 10/11 [00:13<00:01,  1.35s/it, loss=37.5748, avg_loss=37.5748]Epoch 79:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=34.4822, avg_loss=36.0799]Epoch 79:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=37.2588, avg_loss=36.0590]Epoch 79: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=34.4822, avg_loss=36.0799]Epoch 79: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=37.2588, avg_loss=36.0590]Epoch 79: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.4822, avg_loss=36.0799]Epoch 79: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.2588, avg_loss=36.0590]

INFO:__main__:=== EPOCH 79 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 79 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.079924
INFO:__main__:🔢 Total Loss: 36.058977
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.605060
INFO:__main__:   • gene_expression: 23.210248
INFO:__main__:   • gene_density: 1.189927
INFO:__main__:   • gene_density: 1.183061
INFO:__main__:   • operon_membership: 11.284938
INFO:__main__:   • operon_membership: 11.665668
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 79:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=36.9005, avg_loss=35.9480]Epoch 79: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=36.9005, avg_loss=35.9480]Epoch 79: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=36.9005, avg_loss=35.9480]
INFO:__main__:=== EPOCH 79 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.948045
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.029706
INFO:__main__:   • gene_density: 1.166667
INFO:__main__:   • operon_membership: 11.751672
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 79:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=34.0779, avg_loss=35.1119]Epoch 79: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=34.0779, avg_loss=35.1119]Epoch 79: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.0779, avg_loss=35.1119]
INFO:__main__:=== EPOCH 79 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.111923
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.947061
INFO:__main__:   • gene_density: 1.190874
INFO:__main__:   • operon_membership: 11.973988
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 80/681
INFO:__main__:Epoch 80/681
INFO:__main__:Epoch 80/681
INFO:__main__:Epoch 80/681
Epoch 80:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 80:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 80:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 80:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 80:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.9353, avg_loss=34.9353]Epoch 80:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.8492, avg_loss=32.8492]Epoch 80:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5933, avg_loss=34.5933]Epoch 80:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.6503, avg_loss=39.6503]Epoch 80:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  55%|█████▍    | 6/11 [00:08<00:06,  1.37s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:  55%|█████▍    | 6/11 [00:08<00:06,  1.37s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:  55%|█████▍    | 6/11 [00:08<00:06,  1.37s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:  55%|█████▍    | 6/11 [00:08<00:06,  1.37s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  64%|██████▎   | 7/11 [00:09<00:05,  1.29s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:  64%|██████▎   | 7/11 [00:09<00:05,  1.29s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:  64%|██████▎   | 7/11 [00:09<00:05,  1.29s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:  64%|██████▎   | 7/11 [00:09<00:05,  1.29s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  82%|████████▏ | 9/11 [00:11<00:02,  1.19s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:  82%|████████▏ | 9/11 [00:11<00:02,  1.19s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:  82%|████████▏ | 9/11 [00:11<00:02,  1.19s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:  82%|████████▏ | 9/11 [00:11<00:02,  1.20s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  91%|█████████ | 10/11 [00:13<00:01,  1.27s/it, loss=32.8492, avg_loss=32.8492]Epoch 80:  91%|█████████ | 10/11 [00:13<00:01,  1.27s/it, loss=34.5933, avg_loss=34.5933]Epoch 80:  91%|█████████ | 10/11 [00:13<00:01,  1.27s/it, loss=34.9353, avg_loss=34.9353]Epoch 80:  91%|█████████ | 10/11 [00:13<00:01,  1.27s/it, loss=39.6503, avg_loss=39.6503]Epoch 80:  91%|█████████ | 10/11 [00:14<00:01,  1.27s/it, loss=36.0817, avg_loss=36.1492]Epoch 80: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=36.0817, avg_loss=36.1492]Epoch 80: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=36.0817, avg_loss=36.1492]
INFO:__main__:=== EPOCH 80 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.149216
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.263636
INFO:__main__:   • gene_density: 1.180279
INFO:__main__:   • operon_membership: 12.705300
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 80:  91%|█████████ | 10/11 [00:14<00:01,  1.27s/it, loss=34.4533, avg_loss=35.0679]Epoch 80: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.4533, avg_loss=35.0679]Epoch 80:  91%|█████████ | 10/11 [00:14<00:01,  1.27s/it, loss=41.5234, avg_loss=36.1799]Epoch 80: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=41.5234, avg_loss=36.1799]Epoch 80: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.4533, avg_loss=35.0679]
Epoch 80: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=41.5234, avg_loss=36.1799]
INFO:__main__:=== EPOCH 80 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.067910
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.417623
INFO:__main__:   • gene_density: 1.188625
INFO:__main__:   • operon_membership: 11.461663
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 80 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.179889
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.794187
INFO:__main__:   • gene_density: 1.174006
INFO:__main__:   • operon_membership: 11.211696
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 80:  91%|█████████ | 10/11 [00:14<00:01,  1.27s/it, loss=34.8019, avg_loss=35.5832]Epoch 80: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.8019, avg_loss=35.5832]Epoch 80: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.8019, avg_loss=35.5832]
INFO:__main__:=== EPOCH 80 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.583199
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.102405
INFO:__main__:   • gene_density: 1.190400
INFO:__main__:   • operon_membership: 11.290395
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.27it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.27it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.26it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.27it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.60it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]
INFO:__main__:=== EPOCH 80 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:=== EPOCH 80 VALIDATION LOSSES ===
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:========================================
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
INFO:__main__:=== EPOCH 80 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]
INFO:__main__:=== EPOCH 80 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_80.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_80.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_80.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_80.pt
INFO:__main__:Epoch 81/681
INFO:__main__:Epoch 81/681
INFO:__main__:Epoch 81/681
INFO:__main__:Epoch 81/681
Epoch 81:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 81:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 81:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 81:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 81:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5735, avg_loss=34.5735]Epoch 81:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7853, avg_loss=36.7853]Epoch 81:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2118, avg_loss=35.2118]Epoch 81:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8043, avg_loss=33.8043]Epoch 81:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:  27%|██▋       | 3/11 [00:03<00:09,  1.14s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:  27%|██▋       | 3/11 [00:03<00:09,  1.15s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  36%|███▋      | 4/11 [00:04<00:08,  1.26s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:  36%|███▋      | 4/11 [00:04<00:08,  1.26s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:  36%|███▋      | 4/11 [00:04<00:08,  1.26s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:  36%|███▋      | 4/11 [00:04<00:08,  1.27s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  45%|████▌     | 5/11 [00:06<00:07,  1.32s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:  45%|████▌     | 5/11 [00:06<00:07,  1.33s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:  45%|████▌     | 5/11 [00:06<00:07,  1.33s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:  45%|████▌     | 5/11 [00:06<00:07,  1.33s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  64%|██████▎   | 7/11 [00:09<00:05,  1.39s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=34.5735, avg_loss=34.5735]Epoch 81:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=36.7853, avg_loss=36.7853]Epoch 81:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=35.2118, avg_loss=35.2118]Epoch 81:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=33.8043, avg_loss=33.8043]Epoch 81:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.3257, avg_loss=35.3982]Epoch 81: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.3257, avg_loss=35.3982]Epoch 81:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=38.5346, avg_loss=36.0371]Epoch 81: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=38.5346, avg_loss=36.0371]Epoch 81: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.3257, avg_loss=35.3982]
Epoch 81: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.5346, avg_loss=36.0371]
Epoch 81:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.4490, avg_loss=35.2987]Epoch 81: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=35.4490, avg_loss=35.2987]Epoch 81: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.4490, avg_loss=35.2987]
INFO:__main__:=== EPOCH 81 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.398219
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.923863
INFO:__main__:   • gene_density: 1.181049
INFO:__main__:   • operon_membership: 11.293307
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 81 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.037081
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.351023
INFO:__main__:   • gene_density: 1.177734
INFO:__main__:   • operon_membership: 12.508323
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 81 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.298696
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.915970
INFO:__main__:   • gene_density: 1.195490
INFO:__main__:   • operon_membership: 11.187236
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 81:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.2544, avg_loss=36.1354]Epoch 81: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=35.2544, avg_loss=36.1354]Epoch 81: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.2544, avg_loss=36.1354]
INFO:__main__:=== EPOCH 81 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.135420
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.447213
INFO:__main__:   • gene_density: 1.178918
INFO:__main__:   • operon_membership: 11.509289
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 82/681
INFO:__main__:Epoch 82/681
INFO:__main__:Epoch 82/681
INFO:__main__:Epoch 82/681
Epoch 82:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 82:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 82:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 82:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 82:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2820, avg_loss=34.2820]Epoch 82:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.8248, avg_loss=34.8248]Epoch 82:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.9810, avg_loss=34.9810]Epoch 82:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5608, avg_loss=37.5608]Epoch 82:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  27%|██▋       | 3/11 [00:03<00:09,  1.22s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  27%|██▋       | 3/11 [00:03<00:09,  1.22s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:  27%|██▋       | 3/11 [00:03<00:09,  1.22s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:  27%|██▋       | 3/11 [00:03<00:09,  1.22s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:  36%|███▋      | 4/11 [00:04<00:07,  1.07s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:  36%|███▋      | 4/11 [00:04<00:07,  1.07s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:  36%|███▋      | 4/11 [00:04<00:07,  1.07s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  36%|███▋      | 4/11 [00:04<00:07,  1.07s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  64%|██████▎   | 7/11 [00:08<00:05,  1.32s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=34.9810, avg_loss=34.9810]Epoch 82:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=34.2820, avg_loss=34.2820]Epoch 82:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=34.8248, avg_loss=34.8248]Epoch 82:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=37.5608, avg_loss=37.5608]Epoch 82:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=39.9774, avg_loss=35.7789]Epoch 82:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=33.1511, avg_loss=36.2138]Epoch 82:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=38.8918, avg_loss=35.6774]Epoch 82: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=39.9774, avg_loss=35.7789]Epoch 82: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=33.1511, avg_loss=36.2138]Epoch 82: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=38.8918, avg_loss=35.6774]Epoch 82: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=33.1511, avg_loss=36.2138]Epoch 82: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=39.9774, avg_loss=35.7789]

Epoch 82: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=38.8918, avg_loss=35.6774]
INFO:__main__:=== EPOCH 82 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 82 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 82 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.213815
INFO:__main__:🔢 Total Loss: 35.778948
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.677429
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.222811
INFO:__main__:   • gene_expression: 22.943931
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.177557
INFO:__main__:   • gene_density: 1.178504
INFO:__main__:   • operon_membership: 11.813447
INFO:__main__:   • gene_expression: 22.213484
INFO:__main__:   • operon_membership: 11.656513
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_density: 1.194306
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.269639
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 82:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=32.8786, avg_loss=35.4190]Epoch 82: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=32.8786, avg_loss=35.4190]Epoch 82: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=32.8786, avg_loss=35.4190]
INFO:__main__:=== EPOCH 82 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.418975
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.440923
INFO:__main__:   • gene_density: 1.179036
INFO:__main__:   • operon_membership: 10.799015
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 83/681
INFO:__main__:Epoch 83/681
INFO:__main__:Epoch 83/681
INFO:__main__:Epoch 83/681
Epoch 83:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 83:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 83:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 83:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 83:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6452, avg_loss=33.6452]Epoch 83:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1977, avg_loss=36.1977]Epoch 83:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3494, avg_loss=35.3494]Epoch 83:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5196, avg_loss=36.5196]Epoch 83:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  36%|███▋      | 4/11 [00:05<00:09,  1.33s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:  36%|███▋      | 4/11 [00:05<00:09,  1.33s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:  36%|███▋      | 4/11 [00:05<00:09,  1.33s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:  36%|███▋      | 4/11 [00:05<00:09,  1.33s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  45%|████▌     | 5/11 [00:06<00:07,  1.20s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:  45%|████▌     | 5/11 [00:06<00:07,  1.20s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:  45%|████▌     | 5/11 [00:06<00:07,  1.20s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  45%|████▌     | 5/11 [00:06<00:07,  1.21s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:  55%|█████▍    | 6/11 [00:07<00:05,  1.10s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:  55%|█████▍    | 6/11 [00:07<00:05,  1.10s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:  55%|█████▍    | 6/11 [00:07<00:05,  1.10s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:  55%|█████▍    | 6/11 [00:07<00:05,  1.10s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  64%|██████▎   | 7/11 [00:08<00:04,  1.21s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:  64%|██████▎   | 7/11 [00:08<00:04,  1.21s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:  64%|██████▎   | 7/11 [00:08<00:04,  1.21s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:  64%|██████▎   | 7/11 [00:08<00:04,  1.21s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  82%|████████▏ | 9/11 [00:11<00:02,  1.33s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=33.6452, avg_loss=33.6452]Epoch 83:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=36.1977, avg_loss=36.1977]Epoch 83:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=35.3494, avg_loss=35.3494]Epoch 83:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=36.5196, avg_loss=36.5196]Epoch 83:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=34.7629, avg_loss=35.6820]Epoch 83:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=36.8172, avg_loss=36.3107]Epoch 83: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=34.7629, avg_loss=35.6820]Epoch 83: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=36.8172, avg_loss=36.3107]Epoch 83: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=34.7629, avg_loss=35.6820]
Epoch 83: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=36.8172, avg_loss=36.3107]
INFO:__main__:=== EPOCH 83 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 83 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.310652
INFO:__main__:🔢 Total Loss: 35.681980
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.622844
INFO:__main__:   • gene_expression: 22.345094
INFO:__main__:   • gene_density: 1.167791
INFO:__main__:   • gene_density: 1.191998
INFO:__main__:   • operon_membership: 11.520016
INFO:__main__:   • operon_membership: 12.144887
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 83:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=35.2666, avg_loss=35.4790]Epoch 83: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=35.2666, avg_loss=35.4790]Epoch 83: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.2666, avg_loss=35.4790]
INFO:__main__:=== EPOCH 83 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.479033
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.340098
INFO:__main__:   • gene_density: 1.173414
INFO:__main__:   • operon_membership: 10.965521
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 83:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=38.0197, avg_loss=35.4615]Epoch 83: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=38.0197, avg_loss=35.4615]Epoch 83: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=38.0197, avg_loss=35.4615]
INFO:__main__:=== EPOCH 83 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.461460
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.132541
INFO:__main__:   • gene_density: 1.197858
INFO:__main__:   • operon_membership: 12.131061
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 84/681
INFO:__main__:Epoch 84/681
INFO:__main__:Epoch 84/681
INFO:__main__:Epoch 84/681
Epoch 84:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 84:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 84:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 84:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 84:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8570, avg_loss=36.8570]Epoch 84:   9%|▉         | 1/11 [00:01<00:15,  1.58s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.8935, avg_loss=38.8935]Epoch 84:   9%|▉         | 1/11 [00:01<00:15,  1.59s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.8906, avg_loss=38.8906]Epoch 84:   9%|▉         | 1/11 [00:01<00:15,  1.59s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.2558, avg_loss=36.2558]Epoch 84:   9%|▉         | 1/11 [00:01<00:16,  1.61s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  45%|████▌     | 5/11 [00:07<00:08,  1.38s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:  45%|████▌     | 5/11 [00:07<00:08,  1.38s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:  45%|████▌     | 5/11 [00:07<00:08,  1.38s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:  45%|████▌     | 5/11 [00:07<00:08,  1.38s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  55%|█████▍    | 6/11 [00:08<00:06,  1.30s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:  55%|█████▍    | 6/11 [00:08<00:06,  1.30s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:  55%|█████▍    | 6/11 [00:08<00:06,  1.30s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:  55%|█████▍    | 6/11 [00:08<00:06,  1.30s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  64%|██████▎   | 7/11 [00:09<00:04,  1.24s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:  64%|██████▎   | 7/11 [00:09<00:04,  1.24s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:  64%|██████▎   | 7/11 [00:09<00:04,  1.24s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:  64%|██████▎   | 7/11 [00:09<00:04,  1.24s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  91%|█████████ | 10/11 [00:12<00:01,  1.22s/it, loss=38.8906, avg_loss=38.8906]Epoch 84:  91%|█████████ | 10/11 [00:12<00:01,  1.23s/it, loss=38.8935, avg_loss=38.8935]Epoch 84:  91%|█████████ | 10/11 [00:12<00:01,  1.23s/it, loss=36.8570, avg_loss=36.8570]Epoch 84:  91%|█████████ | 10/11 [00:12<00:01,  1.23s/it, loss=36.2558, avg_loss=36.2558]Epoch 84:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=34.6528, avg_loss=35.6616]Epoch 84: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=34.6528, avg_loss=35.6616]Epoch 84: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=34.6528, avg_loss=35.6616]
INFO:__main__:=== EPOCH 84 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.661629
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.723721
INFO:__main__:   • gene_density: 1.186790
INFO:__main__:   • operon_membership: 11.751117
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 84:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=38.5346, avg_loss=35.9350]Epoch 84: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.5346, avg_loss=35.9350]Epoch 84: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=38.5346, avg_loss=35.9350]
Epoch 84:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=34.4200, avg_loss=35.2037]Epoch 84: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=34.4200, avg_loss=35.2037]Epoch 84: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=34.4200, avg_loss=35.2037]
INFO:__main__:=== EPOCH 84 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.935050
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.098349
INFO:__main__:   • gene_density: 1.180279
INFO:__main__:   • operon_membership: 11.656420
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 84 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.203682
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.065748
INFO:__main__:   • gene_density: 1.181286
INFO:__main__:   • operon_membership: 11.956649
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 84:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=35.2183, avg_loss=36.4538]Epoch 84: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=35.2183, avg_loss=36.4538]Epoch 84: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=35.2183, avg_loss=36.4538]
INFO:__main__:=== EPOCH 84 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.453751
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.946777
INFO:__main__:   • gene_density: 1.184304
INFO:__main__:   • operon_membership: 11.322669
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 85/681
INFO:__main__:Epoch 85/681
INFO:__main__:Epoch 85/681
INFO:__main__:Epoch 85/681
Epoch 85:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 85:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 85:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 85:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 85:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.9699, avg_loss=34.9699]Epoch 85:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0022, avg_loss=33.0022]Epoch 85:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.3407, avg_loss=36.3407]Epoch 85:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8645, avg_loss=33.8645]Epoch 85:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  82%|████████▏ | 9/11 [00:12<00:02,  1.27s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=36.3407, avg_loss=36.3407]Epoch 85:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=33.0022, avg_loss=33.0022]Epoch 85:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=33.8645, avg_loss=33.8645]Epoch 85:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=34.9699, avg_loss=34.9699]Epoch 85:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=38.4826, avg_loss=35.4910]Epoch 85: 100%|██████████| 11/11 [00:14<00:00,  1.26s/it, loss=38.4826, avg_loss=35.4910]Epoch 85: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=38.4826, avg_loss=35.4910]
INFO:__main__:=== EPOCH 85 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.490954
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.260273
INFO:__main__:   • gene_density: 1.185902
INFO:__main__:   • operon_membership: 12.044780
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 85:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=37.1277, avg_loss=35.3953]Epoch 85: 100%|██████████| 11/11 [00:14<00:00,  1.26s/it, loss=37.1277, avg_loss=35.3953]Epoch 85: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.1277, avg_loss=35.3953]
Epoch 85:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=35.2196, avg_loss=35.5868]Epoch 85: 100%|██████████| 11/11 [00:14<00:00,  1.26s/it, loss=35.2196, avg_loss=35.5868]Epoch 85: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.2196, avg_loss=35.5868]
INFO:__main__:=== EPOCH 85 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.395298
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.618775
INFO:__main__:   • gene_density: 1.195194
INFO:__main__:   • operon_membership: 11.581329
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 85 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.586846
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.749995
INFO:__main__:   • gene_density: 1.164063
INFO:__main__:   • operon_membership: 11.672789
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 85:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=36.5111, avg_loss=36.5487]Epoch 85: 100%|██████████| 11/11 [00:14<00:00,  1.27s/it, loss=36.5111, avg_loss=36.5487]Epoch 85: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=36.5111, avg_loss=36.5487]
INFO:__main__:=== EPOCH 85 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.548709
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.209874
INFO:__main__:   • gene_density: 1.187618
INFO:__main__:   • operon_membership: 11.151216
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.20it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.45it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.44it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.45it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.45it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.55it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.55it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.55it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.55it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
INFO:__main__:=== EPOCH 85 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:=== EPOCH 85 VALIDATION LOSSES ===
INFO:__main__:========================================
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 85 VALIDATION LOSSES ===
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
INFO:__main__:=== EPOCH 85 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 86/681
INFO:__main__:Epoch 86/681
INFO:__main__:Epoch 86/681
INFO:__main__:Epoch 86/681
Epoch 86:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 86:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 86:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 86:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 86:   0%|          | 0/11 [00:01<?, ?it/s, loss=40.2451, avg_loss=40.2451]Epoch 86:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.4708, avg_loss=33.4708]Epoch 86:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9934, avg_loss=36.9934]Epoch 86:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.4879, avg_loss=33.4879]Epoch 86:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  64%|██████▎   | 7/11 [00:10<00:05,  1.38s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:  64%|██████▎   | 7/11 [00:10<00:05,  1.38s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:  64%|██████▎   | 7/11 [00:10<00:05,  1.38s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:  64%|██████▎   | 7/11 [00:10<00:05,  1.37s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  73%|███████▎  | 8/11 [00:11<00:03,  1.30s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:  73%|███████▎  | 8/11 [00:11<00:03,  1.30s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:  73%|███████▎  | 8/11 [00:11<00:03,  1.30s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  82%|████████▏ | 9/11 [00:12<00:02,  1.23s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  82%|████████▏ | 9/11 [00:12<00:02,  1.24s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:  82%|████████▏ | 9/11 [00:12<00:02,  1.24s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:  82%|████████▏ | 9/11 [00:12<00:02,  1.24s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:  91%|█████████ | 10/11 [00:13<00:01,  1.11s/it, loss=33.4708, avg_loss=33.4708]Epoch 86:  91%|█████████ | 10/11 [00:13<00:01,  1.11s/it, loss=40.2451, avg_loss=40.2451]Epoch 86:  91%|█████████ | 10/11 [00:13<00:01,  1.11s/it, loss=33.4879, avg_loss=33.4879]Epoch 86:  91%|█████████ | 10/11 [00:13<00:01,  1.11s/it, loss=36.9934, avg_loss=36.9934]Epoch 86:  91%|█████████ | 10/11 [00:14<00:01,  1.11s/it, loss=39.2212, avg_loss=36.1077]Epoch 86: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=39.2212, avg_loss=36.1077]Epoch 86: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=39.2212, avg_loss=36.1077]
INFO:__main__:=== EPOCH 86 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.107685
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.733862
INFO:__main__:   • gene_density: 1.195372
INFO:__main__:   • operon_membership: 11.178450
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 86:  91%|█████████ | 10/11 [00:14<00:01,  1.11s/it, loss=38.2343, avg_loss=35.7584]Epoch 86: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=38.2343, avg_loss=35.7584]Epoch 86: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=38.2343, avg_loss=35.7584]
INFO:__main__:=== EPOCH 86 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.758377
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.945834
INFO:__main__:   • gene_density: 1.178681
INFO:__main__:   • operon_membership: 12.633861
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 86:  91%|█████████ | 10/11 [00:14<00:01,  1.11s/it, loss=32.7381, avg_loss=35.9630]Epoch 86: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=32.7381, avg_loss=35.9630]Epoch 86: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=32.7381, avg_loss=35.9630]
INFO:__main__:=== EPOCH 86 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.962995
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.581096
INFO:__main__:   • gene_density: 1.182410
INFO:__main__:   • operon_membership: 11.199489
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 86:  91%|█████████ | 10/11 [00:14<00:01,  1.11s/it, loss=34.1416, avg_loss=35.2270]Epoch 86: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=34.1416, avg_loss=35.2270]Epoch 86: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=34.1416, avg_loss=35.2270]
INFO:__main__:=== EPOCH 86 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.227015
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.473653
INFO:__main__:   • gene_density: 1.176610
INFO:__main__:   • operon_membership: 11.576751
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 87/681
INFO:__main__:Epoch 87/681
INFO:__main__:Epoch 87/681
INFO:__main__:Epoch 87/681
Epoch 87:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 87:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 87:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 87:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 87:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6718, avg_loss=37.6718]Epoch 87:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5327, avg_loss=35.5327]Epoch 87:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0017, avg_loss=33.0017]Epoch 87:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:   0%|          | 0/11 [00:01<?, ?it/s, loss=40.3531, avg_loss=40.3531]Epoch 87:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  82%|████████▏ | 9/11 [00:13<00:02,  1.42s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:  82%|████████▏ | 9/11 [00:13<00:02,  1.42s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:  82%|████████▏ | 9/11 [00:13<00:02,  1.42s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=35.5327, avg_loss=35.5327]Epoch 87:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=37.6718, avg_loss=37.6718]Epoch 87:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=33.0017, avg_loss=33.0017]Epoch 87:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=40.3531, avg_loss=40.3531]Epoch 87:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=34.5809, avg_loss=36.1293]Epoch 87: 100%|██████████| 11/11 [00:15<00:00,  1.32s/it, loss=34.5809, avg_loss=36.1293]Epoch 87: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=34.5809, avg_loss=36.1293]
Epoch 87:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=34.6083, avg_loss=35.4510]Epoch 87:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=32.1367, avg_loss=35.9198]Epoch 87: 100%|██████████| 11/11 [00:15<00:00,  1.32s/it, loss=34.6083, avg_loss=35.4510]Epoch 87: 100%|██████████| 11/11 [00:15<00:00,  1.31s/it, loss=32.1367, avg_loss=35.9198]INFO:__main__:=== EPOCH 87 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.129278
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.152458
INFO:__main__:   • gene_density: 1.180990
INFO:__main__:   • operon_membership: 11.795830
Epoch 87: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=34.6083, avg_loss=35.4510]
INFO:__main__:👥 Samples processed: 22
Epoch 87: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=32.1367, avg_loss=35.9198]
INFO:__main__:========================================
INFO:__main__:=== EPOCH 87 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 87 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.919763
INFO:__main__:🔢 Total Loss: 35.450997
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.089168
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.188092
INFO:__main__:   • gene_expression: 23.128686
INFO:__main__:   • operon_membership: 11.642503
INFO:__main__:   • gene_density: 1.190933
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.131379
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 87:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=34.1980, avg_loss=35.7130]Epoch 87: 100%|██████████| 11/11 [00:15<00:00,  1.32s/it, loss=34.1980, avg_loss=35.7130]Epoch 87: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=34.1980, avg_loss=35.7130]
INFO:__main__:=== EPOCH 87 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.713023
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.433976
INFO:__main__:   • gene_density: 1.172585
INFO:__main__:   • operon_membership: 12.106462
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 88/681
INFO:__main__:Epoch 88/681
INFO:__main__:Epoch 88/681
INFO:__main__:Epoch 88/681
Epoch 88:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 88:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 88:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 88:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 88:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7040, avg_loss=36.7040]Epoch 88:   9%|▉         | 1/11 [00:01<00:11,  1.18s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.7792, avg_loss=33.7792]Epoch 88:   9%|▉         | 1/11 [00:01<00:11,  1.18s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6383, avg_loss=32.6383]Epoch 88:   9%|▉         | 1/11 [00:01<00:11,  1.18s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.3289, avg_loss=36.3289]Epoch 88:   9%|▉         | 1/11 [00:01<00:11,  1.19s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  18%|█▊        | 2/11 [00:02<00:11,  1.32s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:  18%|█▊        | 2/11 [00:02<00:11,  1.32s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:  18%|█▊        | 2/11 [00:02<00:11,  1.32s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:  18%|█▊        | 2/11 [00:02<00:11,  1.33s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  27%|██▋       | 3/11 [00:04<00:11,  1.39s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:  27%|██▋       | 3/11 [00:04<00:11,  1.39s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:  27%|██▋       | 3/11 [00:04<00:11,  1.39s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:  27%|██▋       | 3/11 [00:04<00:11,  1.39s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  36%|███▋      | 4/11 [00:05<00:09,  1.41s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:  36%|███▋      | 4/11 [00:05<00:09,  1.41s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:  36%|███▋      | 4/11 [00:05<00:09,  1.41s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:  36%|███▋      | 4/11 [00:05<00:09,  1.41s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=36.7040, avg_loss=36.7040]Epoch 88:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=32.6383, avg_loss=32.6383]Epoch 88:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=33.7792, avg_loss=33.7792]Epoch 88:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=36.3289, avg_loss=36.3289]Epoch 88:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=40.6447, avg_loss=36.5954]Epoch 88: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=40.6447, avg_loss=36.5954]Epoch 88: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=40.6447, avg_loss=36.5954]
INFO:__main__:=== EPOCH 88 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.595440
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.581059
INFO:__main__:   • gene_density: 1.192708
INFO:__main__:   • operon_membership: 10.821672
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 88:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=41.3442, avg_loss=35.7240]Epoch 88: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=41.3442, avg_loss=35.7240]Epoch 88:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=34.8901, avg_loss=35.2892]Epoch 88: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.8901, avg_loss=35.2892]Epoch 88: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=41.3442, avg_loss=35.7240]
Epoch 88: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.8901, avg_loss=35.2892]
INFO:__main__:=== EPOCH 88 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 88 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.723964
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.289209
INFO:__main__:   • gene_expression: 23.078352
INFO:__main__:   • gene_density: 1.178030
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • operon_membership: 11.467581
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_expression: 21.889499
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.191939
INFO:__main__:   • operon_membership: 12.207771
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 88:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=39.4863, avg_loss=35.3906]Epoch 88: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=39.4863, avg_loss=35.3906]Epoch 88: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=39.4863, avg_loss=35.3906]
INFO:__main__:=== EPOCH 88 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.390615
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.001185
INFO:__main__:   • gene_density: 1.170099
INFO:__main__:   • operon_membership: 12.219331
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 89/681
INFO:__main__:Epoch 89/681
INFO:__main__:Epoch 89/681
INFO:__main__:Epoch 89/681
Epoch 89:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 89:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 89:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 89:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 89:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1046, avg_loss=37.1046]Epoch 89:   9%|▉         | 1/11 [00:01<00:13,  1.37s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7553, avg_loss=35.7553]Epoch 89:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1320, avg_loss=34.1320]Epoch 89:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.1584, avg_loss=33.1584]Epoch 89:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  18%|█▊        | 2/11 [00:02<00:09,  1.09s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  18%|█▊        | 2/11 [00:02<00:09,  1.09s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:  18%|█▊        | 2/11 [00:02<00:09,  1.09s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:  27%|██▋       | 3/11 [00:03<00:08,  1.08s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:  27%|██▋       | 3/11 [00:03<00:08,  1.08s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:  27%|██▋       | 3/11 [00:03<00:08,  1.08s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:  27%|██▋       | 3/11 [00:03<00:08,  1.09s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  36%|███▋      | 4/11 [00:04<00:08,  1.22s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:  36%|███▋      | 4/11 [00:04<00:08,  1.22s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:  36%|███▋      | 4/11 [00:04<00:08,  1.22s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:  36%|███▋      | 4/11 [00:04<00:08,  1.22s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  64%|██████▎   | 7/11 [00:09<00:05,  1.39s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:  64%|██████▎   | 7/11 [00:09<00:05,  1.39s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:  64%|██████▎   | 7/11 [00:09<00:05,  1.39s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:  64%|██████▎   | 7/11 [00:09<00:05,  1.39s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=37.1046, avg_loss=37.1046]Epoch 89:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=34.1320, avg_loss=34.1320]Epoch 89:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=35.7553, avg_loss=35.7553]Epoch 89:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=33.1584, avg_loss=33.1584]Epoch 89:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=38.3965, avg_loss=36.1009]Epoch 89: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=38.3965, avg_loss=36.1009]Epoch 89: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=38.3965, avg_loss=36.1009]
Epoch 89:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=33.4253, avg_loss=35.2204]Epoch 89: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=33.4253, avg_loss=35.2204]Epoch 89: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.4253, avg_loss=35.2204]
INFO:__main__:=== EPOCH 89 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.100887
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.564284
INFO:__main__:   • gene_density: 1.187855
INFO:__main__:   • operon_membership: 11.348748
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 89 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.220414
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.314887
INFO:__main__:   • gene_density: 1.183771
INFO:__main__:   • operon_membership: 11.721756
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 89:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=37.8224, avg_loss=35.7175]Epoch 89: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=37.8224, avg_loss=35.7175]Epoch 89: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.8224, avg_loss=35.7175]
INFO:__main__:=== EPOCH 89 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.717543
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.803082
INFO:__main__:   • gene_density: 1.178741
INFO:__main__:   • operon_membership: 11.735720
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 89:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=37.3867, avg_loss=35.9054]Epoch 89: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=37.3867, avg_loss=35.9054]Epoch 89: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.3867, avg_loss=35.9054]
INFO:__main__:=== EPOCH 89 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.905379
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.021855
INFO:__main__:   • gene_density: 1.178090
INFO:__main__:   • operon_membership: 11.705434
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 90/681
INFO:__main__:Epoch 90/681
INFO:__main__:Epoch 90/681
INFO:__main__:Epoch 90/681
Epoch 90:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 90:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 90:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 90:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 90:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.8134, avg_loss=39.8134]Epoch 90:   9%|▉         | 1/11 [00:01<00:15,  1.59s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0065, avg_loss=34.0065]Epoch 90:   9%|▉         | 1/11 [00:01<00:16,  1.60s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1518, avg_loss=36.1518]Epoch 90:   9%|▉         | 1/11 [00:01<00:16,  1.61s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9024, avg_loss=36.9024]Epoch 90:   9%|▉         | 1/11 [00:01<00:16,  1.62s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  18%|█▊        | 2/11 [00:02<00:12,  1.36s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:  18%|█▊        | 2/11 [00:02<00:12,  1.36s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:  18%|█▊        | 2/11 [00:02<00:12,  1.36s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:  18%|█▊        | 2/11 [00:02<00:12,  1.37s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  27%|██▋       | 3/11 [00:03<00:09,  1.25s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  27%|██▋       | 3/11 [00:03<00:09,  1.25s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:  27%|██▋       | 3/11 [00:03<00:10,  1.25s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:  36%|███▋      | 4/11 [00:04<00:07,  1.09s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  36%|███▋      | 4/11 [00:04<00:07,  1.09s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:  36%|███▋      | 4/11 [00:04<00:07,  1.09s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:  45%|████▌     | 5/11 [00:06<00:07,  1.19s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:  45%|████▌     | 5/11 [00:06<00:07,  1.19s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:  45%|████▌     | 5/11 [00:06<00:07,  1.19s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:  45%|████▌     | 5/11 [00:06<00:07,  1.20s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  55%|█████▍    | 6/11 [00:07<00:06,  1.29s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:  55%|█████▍    | 6/11 [00:07<00:06,  1.29s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:  55%|█████▍    | 6/11 [00:07<00:06,  1.29s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:  55%|█████▍    | 6/11 [00:07<00:06,  1.29s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:  73%|███████▎  | 8/11 [00:10<00:04,  1.39s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=39.8134, avg_loss=39.8134]Epoch 90:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=36.1518, avg_loss=36.1518]Epoch 90:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=34.0065, avg_loss=34.0065]Epoch 90:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=36.9024, avg_loss=36.9024]Epoch 90:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=34.8122, avg_loss=36.3812]Epoch 90: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=34.8122, avg_loss=36.3812]Epoch 90: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.8122, avg_loss=36.3812]
INFO:__main__:=== EPOCH 90 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.381164
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.614714
INFO:__main__:   • gene_density: 1.183357
INFO:__main__:   • operon_membership: 12.583091
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 90:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=37.9399, avg_loss=35.9610]Epoch 90: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=37.9399, avg_loss=35.9610]Epoch 90: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.9399, avg_loss=35.9610]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 90 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.960989
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.577006
INFO:__main__:   • gene_density: 1.191939
INFO:__main__:   • operon_membership: 11.192045
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 90:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=36.1142, avg_loss=35.3236]Epoch 90: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=36.1142, avg_loss=35.3236]Epoch 90: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.1142, avg_loss=35.3236]
INFO:__main__:=== EPOCH 90 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.323615
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.758103
INFO:__main__:   • gene_density: 1.172467
INFO:__main__:   • operon_membership: 11.393045
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 90:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.2119, avg_loss=35.5883]Epoch 90: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=35.2119, avg_loss=35.5883]Epoch 90: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.2119, avg_loss=35.5883]
INFO:__main__:=== EPOCH 90 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.588343
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.884772
INFO:__main__:   • gene_density: 1.184896
INFO:__main__:   • operon_membership: 11.518675
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.29it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.28it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.30it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.28it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.62it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.63it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.63it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.63it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]

INFO:__main__:=== EPOCH 90 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:=== EPOCH 90 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 90 VALIDATION LOSSES ===
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
INFO:__main__:=== EPOCH 90 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_90.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_90.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_90.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_90.pt
INFO:__main__:Epoch 91/681
INFO:__main__:Epoch 91/681
INFO:__main__:Epoch 91/681
INFO:__main__:Epoch 91/681
Epoch 91:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 91:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 91:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 91:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 91:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.6834, avg_loss=34.6834]Epoch 91:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:   0%|          | 0/11 [00:01<?, ?it/s, loss=43.3235, avg_loss=43.3235]Epoch 91:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.8001, avg_loss=37.8001]Epoch 91:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4909, avg_loss=35.4909]Epoch 91:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  82%|████████▏ | 9/11 [00:12<00:02,  1.34s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:  82%|████████▏ | 9/11 [00:12<00:02,  1.34s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:  82%|████████▏ | 9/11 [00:12<00:02,  1.34s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:  82%|████████▏ | 9/11 [00:12<00:02,  1.34s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  91%|█████████ | 10/11 [00:13<00:01,  1.21s/it, loss=43.3235, avg_loss=43.3235]Epoch 91:  91%|█████████ | 10/11 [00:13<00:01,  1.21s/it, loss=37.8001, avg_loss=37.8001]Epoch 91:  91%|█████████ | 10/11 [00:13<00:01,  1.21s/it, loss=34.6834, avg_loss=34.6834]Epoch 91:  91%|█████████ | 10/11 [00:13<00:01,  1.21s/it, loss=35.4909, avg_loss=35.4909]Epoch 91:  91%|█████████ | 10/11 [00:15<00:01,  1.21s/it, loss=36.7998, avg_loss=35.6681]Epoch 91: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=36.7998, avg_loss=35.6681]Epoch 91: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.7998, avg_loss=35.6681]
INFO:__main__:=== EPOCH 91 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.668104
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.250194
INFO:__main__:   • gene_density: 1.183002
INFO:__main__:   • operon_membership: 11.234908
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 91:  91%|█████████ | 10/11 [00:15<00:01,  1.21s/it, loss=33.4559, avg_loss=35.3824]Epoch 91:  91%|█████████ | 10/11 [00:15<00:01,  1.21s/it, loss=34.7209, avg_loss=36.0629]Epoch 91: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=33.4559, avg_loss=35.3824]Epoch 91: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=34.7209, avg_loss=36.0629]Epoch 91: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=33.4559, avg_loss=35.3824]
Epoch 91: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=34.7209, avg_loss=36.0629]
INFO:__main__:=== EPOCH 91 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.382351
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 91 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 22.530225
INFO:__main__:   • gene_density: 1.161813
INFO:__main__:🔢 Total Loss: 36.062893
INFO:__main__:   • operon_membership: 11.690314
INFO:__main__:👥 Samples processed: 22
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 22.592816
INFO:__main__:   • gene_density: 1.191051
INFO:__main__:   • operon_membership: 12.279025
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 91:  91%|█████████ | 10/11 [00:15<00:01,  1.21s/it, loss=38.8945, avg_loss=36.1183]Epoch 91: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=38.8945, avg_loss=36.1183]Epoch 91: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.8945, avg_loss=36.1183]
INFO:__main__:=== EPOCH 91 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.118276
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.355605
INFO:__main__:   • gene_density: 1.195490
INFO:__main__:   • operon_membership: 11.567180
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 92/681
INFO:__main__:Epoch 92/681
INFO:__main__:Epoch 92/681
INFO:__main__:Epoch 92/681
Epoch 92:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 92:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 92:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 92:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 92:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8330, avg_loss=33.8330]Epoch 92:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1947, avg_loss=37.1947]Epoch 92:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1451, avg_loss=35.1451]Epoch 92:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9955, avg_loss=33.9955]Epoch 92:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:  18%|█▊        | 2/11 [00:03<00:14,  1.60s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:  27%|██▋       | 3/11 [00:04<00:12,  1.55s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:  27%|██▋       | 3/11 [00:04<00:12,  1.56s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  36%|███▋      | 4/11 [00:06<00:10,  1.53s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:  36%|███▋      | 4/11 [00:06<00:10,  1.53s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:  36%|███▋      | 4/11 [00:06<00:10,  1.53s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:  36%|███▋      | 4/11 [00:06<00:10,  1.53s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  45%|████▌     | 5/11 [00:07<00:09,  1.51s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:  45%|████▌     | 5/11 [00:07<00:09,  1.51s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:  45%|████▌     | 5/11 [00:07<00:09,  1.51s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:  45%|████▌     | 5/11 [00:07<00:09,  1.51s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  73%|███████▎  | 8/11 [00:12<00:04,  1.49s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:  73%|███████▎  | 8/11 [00:12<00:04,  1.49s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:  73%|███████▎  | 8/11 [00:12<00:04,  1.49s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:  73%|███████▎  | 8/11 [00:12<00:04,  1.49s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  82%|████████▏ | 9/11 [00:13<00:02,  1.41s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:  82%|████████▏ | 9/11 [00:13<00:02,  1.41s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:  82%|████████▏ | 9/11 [00:13<00:02,  1.41s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:  82%|████████▏ | 9/11 [00:13<00:02,  1.40s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=35.1451, avg_loss=35.1451]Epoch 92:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=33.8330, avg_loss=33.8330]Epoch 92:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=37.1947, avg_loss=37.1947]Epoch 92:  91%|█████████ | 10/11 [00:14<00:01,  1.32s/it, loss=33.9955, avg_loss=33.9955]Epoch 92:  91%|█████████ | 10/11 [00:15<00:01,  1.32s/it, loss=34.9686, avg_loss=35.7905]Epoch 92: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=34.9686, avg_loss=35.7905]Epoch 92: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.9686, avg_loss=35.7905]
Epoch 92:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=36.1265, avg_loss=36.2884]Epoch 92: 100%|██████████| 11/11 [00:15<00:00,  1.26s/it, loss=36.1265, avg_loss=36.2884]Epoch 92: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=36.1265, avg_loss=36.2884]
INFO:__main__:=== EPOCH 92 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.790471
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.656661
INFO:__main__:   • gene_density: 1.173000
INFO:__main__:   • operon_membership: 11.960810
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 92 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.288357
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.211591
INFO:__main__:   • gene_density: 1.168206
INFO:__main__:   • operon_membership: 11.908561
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 92:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=34.6154, avg_loss=35.4574]Epoch 92: 100%|██████████| 11/11 [00:15<00:00,  1.26s/it, loss=34.6154, avg_loss=35.4574]Epoch 92: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.6154, avg_loss=35.4574]
INFO:__main__:=== EPOCH 92 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.457448
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.124654
INFO:__main__:   • gene_density: 1.194247
INFO:__main__:   • operon_membership: 11.138546
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 92:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=32.9897, avg_loss=35.4572]Epoch 92: 100%|██████████| 11/11 [00:15<00:00,  1.26s/it, loss=32.9897, avg_loss=35.4572]Epoch 92: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=32.9897, avg_loss=35.4572]
INFO:__main__:=== EPOCH 92 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.457177
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.760793
INFO:__main__:   • gene_density: 1.196851
INFO:__main__:   • operon_membership: 11.499532
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 93/681
INFO:__main__:Epoch 93/681
INFO:__main__:Epoch 93/681
INFO:__main__:Epoch 93/681
Epoch 93:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 93:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 93:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 93:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 93:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.9213, avg_loss=31.9213]Epoch 93:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1825, avg_loss=34.1825]Epoch 93:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.3078, avg_loss=37.3078]Epoch 93:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7843, avg_loss=35.7843]Epoch 93:   9%|▉         | 1/11 [00:01<00:13,  1.40s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  82%|████████▏ | 9/11 [00:13<00:02,  1.47s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:  82%|████████▏ | 9/11 [00:13<00:02,  1.47s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:  82%|████████▏ | 9/11 [00:13<00:02,  1.48s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:  82%|████████▏ | 9/11 [00:13<00:02,  1.47s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=34.1825, avg_loss=34.1825]Epoch 93:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=31.9213, avg_loss=31.9213]Epoch 93:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=37.3078, avg_loss=37.3078]Epoch 93:  91%|█████████ | 10/11 [00:14<00:01,  1.44s/it, loss=35.7843, avg_loss=35.7843]Epoch 93:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=34.3041, avg_loss=36.9237]Epoch 93:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=31.6680, avg_loss=35.0640]Epoch 93:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=36.0288, avg_loss=35.1992]Epoch 93: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.3041, avg_loss=36.9237]Epoch 93: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=31.6680, avg_loss=35.0640]Epoch 93: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=36.0288, avg_loss=35.1992]Epoch 93: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=34.3041, avg_loss=36.9237]Epoch 93: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=31.6680, avg_loss=35.0640]

Epoch 93: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=36.0288, avg_loss=35.1992]
INFO:__main__:=== EPOCH 93 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 93 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 93 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.064005
INFO:__main__:🔢 Total Loss: 36.923694
INFO:__main__:🔢 Total Loss: 35.199227
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.136786
INFO:__main__:   • gene_expression: 24.063177
INFO:__main__:   • gene_expression: 23.091257
INFO:__main__:   • gene_density: 1.170691
INFO:__main__:   • gene_density: 1.183890
INFO:__main__:   • gene_density: 1.193774
INFO:__main__:   • operon_membership: 11.756527
INFO:__main__:   • operon_membership: 11.676627
INFO:__main__:   • operon_membership: 10.914196
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 93:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=37.6466, avg_loss=35.8790]Epoch 93: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=37.6466, avg_loss=35.8790]Epoch 93: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=37.6466, avg_loss=35.8790]
INFO:__main__:=== EPOCH 93 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.879016
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.436690
INFO:__main__:   • gene_density: 1.185310
INFO:__main__:   • operon_membership: 12.257016
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 94/681
INFO:__main__:Epoch 94/681
INFO:__main__:Epoch 94/681
INFO:__main__:Epoch 94/681
Epoch 94:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 94:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 94:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 94:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 94:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3845, avg_loss=35.3845]Epoch 94:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1658, avg_loss=36.1658]Epoch 94:   9%|▉         | 1/11 [00:01<00:11,  1.13s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0890, avg_loss=36.0890]Epoch 94:   9%|▉         | 1/11 [00:01<00:11,  1.13s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9682, avg_loss=35.9682]Epoch 94:   9%|▉         | 1/11 [00:01<00:11,  1.13s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  18%|█▊        | 2/11 [00:02<00:09,  1.07s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:  18%|█▊        | 2/11 [00:02<00:09,  1.07s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:  18%|█▊        | 2/11 [00:02<00:09,  1.07s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  18%|█▊        | 2/11 [00:02<00:09,  1.08s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:  27%|██▋       | 3/11 [00:03<00:10,  1.26s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:  27%|██▋       | 3/11 [00:03<00:10,  1.26s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:  27%|██▋       | 3/11 [00:03<00:10,  1.26s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  27%|██▋       | 3/11 [00:03<00:10,  1.26s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:  82%|████████▏ | 9/11 [00:12<00:02,  1.46s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:  82%|████████▏ | 9/11 [00:12<00:02,  1.46s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:  82%|████████▏ | 9/11 [00:12<00:02,  1.46s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  82%|████████▏ | 9/11 [00:12<00:02,  1.46s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:  91%|█████████ | 10/11 [00:13<00:01,  1.47s/it, loss=35.9682, avg_loss=35.9682]Epoch 94:  91%|█████████ | 10/11 [00:13<00:01,  1.47s/it, loss=35.3845, avg_loss=35.3845]Epoch 94:  91%|█████████ | 10/11 [00:13<00:01,  1.47s/it, loss=36.0890, avg_loss=36.0890]Epoch 94:  91%|█████████ | 10/11 [00:14<00:01,  1.47s/it, loss=36.1658, avg_loss=36.1658]Epoch 94:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=35.4185, avg_loss=35.5611]Epoch 94: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=35.4185, avg_loss=35.5611]Epoch 94: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.4185, avg_loss=35.5611]
INFO:__main__:=== EPOCH 94 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.561119
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.561951
INFO:__main__:   • gene_density: 1.198390
INFO:__main__:   • operon_membership: 11.800778
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 94:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=34.6094, avg_loss=35.6353]Epoch 94: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=34.6094, avg_loss=35.6353]Epoch 94:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=35.3111, avg_loss=36.3391]Epoch 94: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=34.6094, avg_loss=35.6353]
Epoch 94: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.3111, avg_loss=36.3391]Epoch 94: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.3111, avg_loss=36.3391]
INFO:__main__:=== EPOCH 94 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.635280
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.815143
INFO:__main__:   • gene_density: 1.177912
INFO:__main__:   • operon_membership: 11.642225
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 94 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.339091
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.558904
INFO:__main__:   • gene_density: 1.179392
INFO:__main__:   • operon_membership: 11.600795
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 94:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=38.4071, avg_loss=35.5748]Epoch 94: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=38.4071, avg_loss=35.5748]Epoch 94: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=38.4071, avg_loss=35.5748]
INFO:__main__:=== EPOCH 94 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.574847
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.824005
INFO:__main__:   • gene_density: 1.180102
INFO:__main__:   • operon_membership: 11.570740
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 95/681
INFO:__main__:Epoch 95/681
INFO:__main__:Epoch 95/681
INFO:__main__:Epoch 95/681
Epoch 95:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 95:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 95:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 95:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 95:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.8516, avg_loss=37.8516]Epoch 95:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8062, avg_loss=33.8062]Epoch 95:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.2975, avg_loss=38.2975]Epoch 95:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5889, avg_loss=37.5889]Epoch 95:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  18%|█▊        | 2/11 [00:02<00:10,  1.15s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:  18%|█▊        | 2/11 [00:02<00:10,  1.16s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:  18%|█▊        | 2/11 [00:02<00:10,  1.16s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:  18%|█▊        | 2/11 [00:02<00:10,  1.16s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  27%|██▋       | 3/11 [00:03<00:08,  1.07s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:  27%|██▋       | 3/11 [00:03<00:08,  1.07s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:  27%|██▋       | 3/11 [00:03<00:08,  1.07s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:  27%|██▋       | 3/11 [00:03<00:08,  1.08s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  45%|████▌     | 5/11 [00:06<00:07,  1.32s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:  45%|████▌     | 5/11 [00:06<00:07,  1.32s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:  45%|████▌     | 5/11 [00:06<00:07,  1.32s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:  45%|████▌     | 5/11 [00:06<00:07,  1.32s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=33.8062, avg_loss=33.8062]Epoch 95:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=38.2975, avg_loss=38.2975]Epoch 95:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=37.8516, avg_loss=37.8516]Epoch 95:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=37.5889, avg_loss=37.5889]Epoch 95:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.3674, avg_loss=35.7828]Epoch 95:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=34.6775, avg_loss=35.3971]Epoch 95:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=38.3603, avg_loss=36.1574]Epoch 95: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.3674, avg_loss=35.7828]Epoch 95: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=34.6775, avg_loss=35.3971]Epoch 95: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=38.3603, avg_loss=36.1574]Epoch 95: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.3674, avg_loss=35.7828]
Epoch 95: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.3603, avg_loss=36.1574]Epoch 95: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=34.6775, avg_loss=35.3971]

INFO:__main__:=== EPOCH 95 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 95 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 95 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.157357
INFO:__main__:🔢 Total Loss: 35.782849
INFO:__main__:🔢 Total Loss: 35.397129
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.408556
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.658834
INFO:__main__:   • gene_density: 1.172881
INFO:__main__:   • gene_expression: 22.862461
INFO:__main__:   • gene_density: 1.187618
INFO:__main__:   • operon_membership: 11.575919
INFO:__main__:   • gene_density: 1.184718
INFO:__main__:   • operon_membership: 11.936396
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.349950
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 95:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=34.2010, avg_loss=35.7916]Epoch 95: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=34.2010, avg_loss=35.7916]Epoch 95: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=34.2010, avg_loss=35.7916]
INFO:__main__:=== EPOCH 95 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.791587
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.092318
INFO:__main__:   • gene_density: 1.185310
INFO:__main__:   • operon_membership: 11.513959
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.26it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.26it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.26it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.52it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.76it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.76it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.76it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.77it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.66it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.66it/s]

Validation: 100%|██████████| 4/4 [00:02<00:00,  1.66it/s]
INFO:__main__:=== EPOCH 95 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 95 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:=== EPOCH 95 VALIDATION LOSSES ===
INFO:__main__:========================================
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.66it/s]
INFO:__main__:=== EPOCH 95 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 96/681
INFO:__main__:Epoch 96/681
INFO:__main__:Epoch 96/681
INFO:__main__:Epoch 96/681
Epoch 96:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 96:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 96:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 96:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 96:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.8529, avg_loss=31.8529]Epoch 96:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=31.8529, avg_loss=31.8529]Epoch 96:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.3528, avg_loss=33.3528]Epoch 96:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6924, avg_loss=32.6924]Epoch 96:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=33.3528, avg_loss=33.3528]Epoch 96:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=32.6924, avg_loss=32.6924]Epoch 96:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.2866, avg_loss=38.2866]Epoch 96:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=38.2866, avg_loss=38.2866]Epoch 96:  18%|█▊        | 2/11 [00:02<00:09,  1.09s/it, loss=31.8529, avg_loss=31.8529]Epoch 96:  18%|█▊        | 2/11 [00:02<00:09,  1.09s/it, loss=32.6924, avg_loss=32.6924]Epoch 96:  18%|█▊        | 2/11 [00:02<00:09,  1.09s/it, loss=33.3528, avg_loss=33.3528]Epoch 96:  18%|█▊        | 2/11 [00:02<00:09,  1.09s/it, loss=38.2866, avg_loss=38.2866]Epoch 96:  27%|██▋       | 3/11 [00:03<00:07,  1.01it/s, loss=31.8529, avg_loss=31.8529]Epoch 96:  27%|██▋       | 3/11 [00:03<00:07,  1.01it/s, loss=33.3528, avg_loss=33.3528]Epoch 96:  27%|██▋       | 3/11 [00:03<00:07,  1.01it/s, loss=32.6924, avg_loss=32.6924]Epoch 96:  27%|██▋       | 3/11 [00:03<00:07,  1.00it/s, loss=38.2866, avg_loss=38.2866]Epoch 96:  36%|███▋      | 4/11 [00:04<00:08,  1.16s/it, loss=31.8529, avg_loss=31.8529]Epoch 96:  36%|███▋      | 4/11 [00:04<00:08,  1.16s/it, loss=32.6924, avg_loss=32.6924]Epoch 96:  36%|███▋      | 4/11 [00:04<00:08,  1.16s/it, loss=33.3528, avg_loss=33.3528]Epoch 96:  36%|███▋      | 4/11 [00:04<00:08,  1.16s/it, loss=38.2866, avg_loss=38.2866]Epoch 96:  45%|████▌     | 5/11 [00:05<00:07,  1.24s/it, loss=32.6924, avg_loss=32.6924]Epoch 96:  45%|████▌     | 5/11 [00:05<00:07,  1.24s/it, loss=33.3528, avg_loss=33.3528]Epoch 96:  45%|████▌     | 5/11 [00:05<00:07,  1.24s/it, loss=31.8529, avg_loss=31.8529]Epoch 96:  45%|████▌     | 5/11 [00:05<00:07,  1.24s/it, loss=38.2866, avg_loss=38.2866]Epoch 96:  55%|█████▍    | 6/11 [00:07<00:06,  1.30s/it, loss=31.8529, avg_loss=31.8529]Epoch 96:  55%|█████▍    | 6/11 [00:07<00:06,  1.30s/it, loss=32.6924, avg_loss=32.6924]Epoch 96:  55%|█████▍    | 6/11 [00:07<00:06,  1.30s/it, loss=33.3528, avg_loss=33.3528]Epoch 96:  55%|█████▍    | 6/11 [00:07<00:06,  1.30s/it, loss=38.2866, avg_loss=38.2866]Epoch 96:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=31.8529, avg_loss=31.8529]Epoch 96:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=33.3528, avg_loss=33.3528]Epoch 96:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=32.6924, avg_loss=32.6924]Epoch 96:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=38.2866, avg_loss=38.2866]Epoch 96:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=32.6924, avg_loss=32.6924]Epoch 96:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=33.3528, avg_loss=33.3528]Epoch 96:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=31.8529, avg_loss=31.8529]Epoch 96:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=38.2866, avg_loss=38.2866]Epoch 96:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=31.8529, avg_loss=31.8529]Epoch 96:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=32.6924, avg_loss=32.6924]Epoch 96:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=33.3528, avg_loss=33.3528]Epoch 96:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=38.2866, avg_loss=38.2866]Epoch 96:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=31.8529, avg_loss=31.8529]Epoch 96:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=32.6924, avg_loss=32.6924]Epoch 96:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=33.3528, avg_loss=33.3528]Epoch 96:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=38.2866, avg_loss=38.2866]Epoch 96:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=39.3962, avg_loss=35.6920]Epoch 96:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=36.6300, avg_loss=35.4125]Epoch 96: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=39.3962, avg_loss=35.6920]Epoch 96: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=36.6300, avg_loss=35.4125]Epoch 96: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=39.3962, avg_loss=35.6920]
Epoch 96: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=36.6300, avg_loss=35.4125]
Epoch 96:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=34.9495, avg_loss=35.5546]INFO:__main__:=== EPOCH 96 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 96 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.691995
INFO:__main__:🔢 Total Loss: 35.412516
INFO:__main__:📊 Individual Modality Losses:
Epoch 96: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=34.9495, avg_loss=35.5546]INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.288844
INFO:__main__:   • gene_expression: 22.119066
INFO:__main__:   • gene_density: 1.168797
INFO:__main__:   • gene_density: 1.197206
INFO:__main__:   • operon_membership: 11.234353
INFO:__main__:   • operon_membership: 12.096244
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 96: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=34.9495, avg_loss=35.5546]
INFO:__main__:=== EPOCH 96 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.554595
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.306832
INFO:__main__:   • gene_density: 1.181759
INFO:__main__:   • operon_membership: 12.066003
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 96:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=38.5703, avg_loss=36.2310]Epoch 96: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=38.5703, avg_loss=36.2310]Epoch 96: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.5703, avg_loss=36.2310]
INFO:__main__:=== EPOCH 96 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.231040
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.775352
INFO:__main__:   • gene_density: 1.185961
INFO:__main__:   • operon_membership: 11.269726
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 97/681
INFO:__main__:Epoch 97/681
INFO:__main__:Epoch 97/681
INFO:__main__:Epoch 97/681
Epoch 97:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 97:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 97:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 97:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 97:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1861, avg_loss=38.1861]Epoch 97:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.3153, avg_loss=36.3153]Epoch 97:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8182, avg_loss=36.8182]Epoch 97:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6970, avg_loss=32.6970]Epoch 97:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  18%|█▊        | 2/11 [00:02<00:13,  1.46s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:  18%|█▊        | 2/11 [00:02<00:13,  1.46s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:  18%|█▊        | 2/11 [00:02<00:13,  1.46s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:  18%|█▊        | 2/11 [00:02<00:13,  1.46s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  36%|███▋      | 4/11 [00:05<00:08,  1.20s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:  36%|███▋      | 4/11 [00:05<00:08,  1.20s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:  36%|███▋      | 4/11 [00:05<00:08,  1.19s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  36%|███▋      | 4/11 [00:05<00:08,  1.20s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:  45%|████▌     | 5/11 [00:06<00:06,  1.08s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:  45%|████▌     | 5/11 [00:06<00:06,  1.09s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:  45%|████▌     | 5/11 [00:06<00:06,  1.09s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:  45%|████▌     | 5/11 [00:06<00:06,  1.09s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  55%|█████▍    | 6/11 [00:07<00:05,  1.20s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:  55%|█████▍    | 6/11 [00:07<00:06,  1.20s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:  55%|█████▍    | 6/11 [00:07<00:06,  1.20s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:  55%|█████▍    | 6/11 [00:07<00:06,  1.20s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  64%|██████▎   | 7/11 [00:08<00:05,  1.27s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:  64%|██████▎   | 7/11 [00:08<00:05,  1.27s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:  64%|██████▎   | 7/11 [00:08<00:05,  1.27s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:  64%|██████▎   | 7/11 [00:08<00:05,  1.27s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  73%|███████▎  | 8/11 [00:10<00:03,  1.31s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:  73%|███████▎  | 8/11 [00:10<00:03,  1.32s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:  73%|███████▎  | 8/11 [00:10<00:03,  1.32s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:  73%|███████▎  | 8/11 [00:10<00:03,  1.32s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=36.8182, avg_loss=36.8182]Epoch 97:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=36.3153, avg_loss=36.3153]Epoch 97:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=38.1861, avg_loss=38.1861]Epoch 97:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=32.6970, avg_loss=32.6970]Epoch 97:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=35.5397, avg_loss=35.7125]Epoch 97:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=36.5226, avg_loss=35.3329]Epoch 97: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=35.5397, avg_loss=35.7125]Epoch 97:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=39.9689, avg_loss=36.4600]Epoch 97: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=36.5226, avg_loss=35.3329]Epoch 97: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=39.9689, avg_loss=36.4600]Epoch 97: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=36.5226, avg_loss=35.3329]Epoch 97: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=35.5397, avg_loss=35.7125]

Epoch 97: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=39.9689, avg_loss=36.4600]
INFO:__main__:=== EPOCH 97 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 97 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.712505
INFO:__main__:🔢 Total Loss: 35.332869
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 97 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 22.824300
INFO:__main__:   • gene_expression: 22.923533
INFO:__main__:   • gene_density: 1.174124
INFO:__main__:   • gene_density: 1.186080
INFO:__main__:🔢 Total Loss: 36.459984
INFO:__main__:   • operon_membership: 11.714080
INFO:__main__:   • operon_membership: 11.223256
INFO:__main__:👥 Samples processed: 22
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 24.376793
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.195490
INFO:__main__:   • operon_membership: 10.887701
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 97:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=34.1299, avg_loss=35.6791]Epoch 97: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=34.1299, avg_loss=35.6791]Epoch 97: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=34.1299, avg_loss=35.6791]
INFO:__main__:=== EPOCH 97 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.679058
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.766864
INFO:__main__:   • gene_density: 1.174065
INFO:__main__:   • operon_membership: 12.738130
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 98/681
INFO:__main__:Epoch 98/681
INFO:__main__:Epoch 98/681
INFO:__main__:Epoch 98/681
Epoch 98:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 98:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 98:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 98:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 98:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0677, avg_loss=34.0677]Epoch 98:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.3651, avg_loss=36.3651]Epoch 98:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.0257, avg_loss=39.0257]Epoch 98:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8383, avg_loss=35.8383]Epoch 98:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:  36%|███▋      | 4/11 [00:05<00:09,  1.38s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  55%|█████▍    | 6/11 [00:07<00:06,  1.23s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  55%|█████▍    | 6/11 [00:07<00:06,  1.23s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:  55%|█████▍    | 6/11 [00:08<00:06,  1.23s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:  55%|█████▍    | 6/11 [00:08<00:06,  1.23s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:  64%|██████▎   | 7/11 [00:08<00:04,  1.10s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  64%|██████▎   | 7/11 [00:08<00:04,  1.10s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:  64%|██████▎   | 7/11 [00:08<00:04,  1.10s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:  64%|██████▎   | 7/11 [00:08<00:04,  1.10s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:  73%|███████▎  | 8/11 [00:09<00:03,  1.10s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:  73%|███████▎  | 8/11 [00:09<00:03,  1.10s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:  73%|███████▎  | 8/11 [00:09<00:03,  1.10s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:  73%|███████▎  | 8/11 [00:09<00:03,  1.10s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  82%|████████▏ | 9/11 [00:11<00:02,  1.20s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:  82%|████████▏ | 9/11 [00:11<00:02,  1.20s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  91%|█████████ | 10/11 [00:12<00:01,  1.28s/it, loss=39.0257, avg_loss=39.0257]Epoch 98:  91%|█████████ | 10/11 [00:12<00:01,  1.28s/it, loss=36.3651, avg_loss=36.3651]Epoch 98:  91%|█████████ | 10/11 [00:12<00:01,  1.28s/it, loss=34.0677, avg_loss=34.0677]Epoch 98:  91%|█████████ | 10/11 [00:12<00:01,  1.28s/it, loss=35.8383, avg_loss=35.8383]Epoch 98:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=36.8489, avg_loss=34.3686]Epoch 98:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=36.0583, avg_loss=36.4628]Epoch 98: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=36.8489, avg_loss=34.3686]Epoch 98: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=36.0583, avg_loss=36.4628]Epoch 98:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=39.0697, avg_loss=36.4493]Epoch 98: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=39.0697, avg_loss=36.4493]Epoch 98: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=36.8489, avg_loss=34.3686]
Epoch 98: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=36.0583, avg_loss=36.4628]
Epoch 98: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=39.0697, avg_loss=36.4493]
INFO:__main__:=== EPOCH 98 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.368559
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.809475
INFO:__main__:=== EPOCH 98 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.178385
INFO:__main__:=== EPOCH 98 TRAINING LOSSES ===
INFO:__main__:   • operon_membership: 11.380699
INFO:__main__:🔢 Total Loss: 36.462767
INFO:__main__:👥 Samples processed: 22
INFO:__main__:🔢 Total Loss: 36.449319
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.351324
INFO:__main__:   • gene_expression: 23.671363
INFO:__main__:   • gene_density: 1.196733
INFO:__main__:   • gene_density: 1.175959
INFO:__main__:   • operon_membership: 11.914710
INFO:__main__:   • operon_membership: 11.601997
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 98:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=39.9421, avg_loss=35.9232]Epoch 98: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=39.9421, avg_loss=35.9232]Epoch 98: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=39.9421, avg_loss=35.9232]
INFO:__main__:=== EPOCH 98 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.923218
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.956575
INFO:__main__:   • gene_density: 1.180339
INFO:__main__:   • operon_membership: 11.786305
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 99/681
INFO:__main__:Epoch 99/681
INFO:__main__:Epoch 99/681
INFO:__main__:Epoch 99/681
Epoch 99:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 99:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 99:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 99:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 99:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.6963, avg_loss=34.6963]Epoch 99:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6358, avg_loss=36.6358]Epoch 99:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1598, avg_loss=37.1598]Epoch 99:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.0246, avg_loss=39.0246]Epoch 99:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:  73%|███████▎  | 8/11 [00:11<00:03,  1.30s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:  73%|███████▎  | 8/11 [00:11<00:03,  1.30s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:  73%|███████▎  | 8/11 [00:11<00:03,  1.30s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:  73%|███████▎  | 8/11 [00:11<00:03,  1.30s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  82%|████████▏ | 9/11 [00:12<00:02,  1.16s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  82%|████████▏ | 9/11 [00:12<00:02,  1.16s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:  82%|████████▏ | 9/11 [00:12<00:02,  1.16s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:  82%|████████▏ | 9/11 [00:12<00:02,  1.16s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=36.6358, avg_loss=36.6358]Epoch 99:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=37.1598, avg_loss=37.1598]Epoch 99:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=34.6963, avg_loss=34.6963]Epoch 99:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=39.0246, avg_loss=39.0246]Epoch 99:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=37.4668, avg_loss=35.4890]Epoch 99: 100%|██████████| 11/11 [00:14<00:00,  1.27s/it, loss=37.4668, avg_loss=35.4890]Epoch 99: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=37.4668, avg_loss=35.4890]
INFO:__main__:=== EPOCH 99 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.489009
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.284352
INFO:__main__:   • gene_density: 1.184482
INFO:__main__:   • operon_membership: 11.020175
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 99:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=34.3124, avg_loss=35.2229]Epoch 99: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=34.3124, avg_loss=35.2229]Epoch 99: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=34.3124, avg_loss=35.2229]
INFO:__main__:=== EPOCH 99 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.222883
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.079695
INFO:__main__:   • gene_density: 1.190933
INFO:__main__:   • operon_membership: 11.952256
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 99:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=33.0022, avg_loss=35.7246]Epoch 99: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=33.0022, avg_loss=35.7246]Epoch 99: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=33.0022, avg_loss=35.7246]
INFO:__main__:=== EPOCH 99 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.724596
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.245647
INFO:__main__:   • gene_density: 1.174775
INFO:__main__:   • operon_membership: 11.304174
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 99:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=36.1770, avg_loss=36.4329]Epoch 99: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=36.1770, avg_loss=36.4329]Epoch 99: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=36.1770, avg_loss=36.4329]
INFO:__main__:=== EPOCH 99 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.432928
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.028375
INFO:__main__:   • gene_density: 1.183002
INFO:__main__:   • operon_membership: 12.221551
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 100/681
INFO:__main__:Epoch 100/681
INFO:__main__:Epoch 100/681
INFO:__main__:Epoch 100/681
Epoch 100:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 100:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 100:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 100:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 100:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1655, avg_loss=36.1655]Epoch 100:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.6460, avg_loss=34.6460]Epoch 100:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.9205, avg_loss=32.9205]Epoch 100:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5201, avg_loss=36.5201]Epoch 100:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  91%|█████████ | 10/11 [00:13<00:01,  1.26s/it, loss=32.9205, avg_loss=32.9205]Epoch 100:  91%|█████████ | 10/11 [00:13<00:01,  1.26s/it, loss=34.6460, avg_loss=34.6460]Epoch 100:  91%|█████████ | 10/11 [00:13<00:01,  1.25s/it, loss=36.5201, avg_loss=36.5201]Epoch 100:  91%|█████████ | 10/11 [00:13<00:01,  1.26s/it, loss=36.1655, avg_loss=36.1655]Epoch 100:  91%|█████████ | 10/11 [00:15<00:01,  1.26s/it, loss=37.3324, avg_loss=36.3597]Epoch 100:  91%|█████████ | 10/11 [00:15<00:01,  1.26s/it, loss=34.2843, avg_loss=36.2784]Epoch 100: 100%|██████████| 11/11 [00:15<00:00,  1.20s/it, loss=37.3324, avg_loss=36.3597]Epoch 100: 100%|██████████| 11/11 [00:15<00:00,  1.20s/it, loss=34.2843, avg_loss=36.2784]Epoch 100: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.3324, avg_loss=36.3597]
Epoch 100: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.2843, avg_loss=36.2784]
INFO:__main__:=== EPOCH 100 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.359664
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.647648
INFO:__main__:   • gene_density: 1.181226
INFO:__main__:   • operon_membership: 11.530790
INFO:__main__:👥 Samples processed: 22
INFO:__main__:=== EPOCH 100 TRAINING LOSSES ===
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 36.278359
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.127054
INFO:__main__:   • gene_density: 1.181108
INFO:__main__:   • operon_membership: 11.970197
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 100:  91%|█████████ | 10/11 [00:15<00:01,  1.26s/it, loss=33.7744, avg_loss=35.5708]Epoch 100: 100%|██████████| 11/11 [00:15<00:00,  1.20s/it, loss=33.7744, avg_loss=35.5708]Epoch 100: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.7744, avg_loss=35.5708]
INFO:__main__:=== EPOCH 100 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.570810
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.571929
INFO:__main__:   • gene_density: 1.190104
INFO:__main__:   • operon_membership: 11.808777
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 100:  91%|█████████ | 10/11 [00:15<00:01,  1.25s/it, loss=35.7738, avg_loss=34.8878]Epoch 100: 100%|██████████| 11/11 [00:15<00:00,  1.21s/it, loss=35.7738, avg_loss=34.8878]Epoch 100: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.7738, avg_loss=34.8878]
INFO:__main__:=== EPOCH 100 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.887787
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.533526
INFO:__main__:   • gene_density: 1.179510
INFO:__main__:   • operon_membership: 11.174751
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]

Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]INFO:__main__:=== EPOCH 100 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 100 VALIDATION LOSSES ===

INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 100 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]
INFO:__main__:=== EPOCH 100 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_100.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_100.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_100.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_100.pt
INFO:__main__:Epoch 101/681
INFO:__main__:Epoch 101/681
INFO:__main__:Epoch 101/681
INFO:__main__:Epoch 101/681
Epoch 101:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 101:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 101:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 101:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 101:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.5255, avg_loss=38.5255]Epoch 101:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.0197, avg_loss=38.0197]Epoch 101:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3159, avg_loss=34.3159]Epoch 101:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5871, avg_loss=36.5871]Epoch 101:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  27%|██▋       | 3/11 [00:04<00:10,  1.37s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:  27%|██▋       | 3/11 [00:04<00:10,  1.37s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  27%|██▋       | 3/11 [00:04<00:10,  1.37s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:  27%|██▋       | 3/11 [00:04<00:10,  1.37s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:  36%|███▋      | 4/11 [00:05<00:08,  1.27s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:  36%|███▋      | 4/11 [00:05<00:08,  1.27s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:  36%|███▋      | 4/11 [00:05<00:08,  1.27s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:  36%|███▋      | 4/11 [00:05<00:08,  1.27s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:  55%|█████▍    | 6/11 [00:07<00:05,  1.07s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:  55%|█████▍    | 6/11 [00:07<00:05,  1.06s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  55%|█████▍    | 6/11 [00:07<00:05,  1.07s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:  55%|█████▍    | 6/11 [00:07<00:05,  1.07s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:  64%|██████▎   | 7/11 [00:08<00:04,  1.14s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:  64%|██████▎   | 7/11 [00:08<00:04,  1.14s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:  64%|██████▎   | 7/11 [00:08<00:04,  1.14s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:  64%|██████▎   | 7/11 [00:08<00:04,  1.15s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:  82%|████████▏ | 9/11 [00:11<00:02,  1.32s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:  82%|████████▏ | 9/11 [00:11<00:02,  1.32s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:  82%|████████▏ | 9/11 [00:11<00:02,  1.32s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  91%|█████████ | 10/11 [00:12<00:01,  1.36s/it, loss=34.3159, avg_loss=34.3159]Epoch 101:  91%|█████████ | 10/11 [00:12<00:01,  1.37s/it, loss=38.0197, avg_loss=38.0197]Epoch 101:  91%|█████████ | 10/11 [00:12<00:01,  1.37s/it, loss=38.5255, avg_loss=38.5255]Epoch 101:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=36.5871, avg_loss=36.5871]Epoch 101:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=33.6754, avg_loss=35.9960]Epoch 101:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=35.6503, avg_loss=35.4183]Epoch 101:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=38.1575, avg_loss=36.5234]Epoch 101: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=33.6754, avg_loss=35.9960]Epoch 101: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=35.6503, avg_loss=35.4183]Epoch 101: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=38.1575, avg_loss=36.5234]Epoch 101: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=33.6754, avg_loss=35.9960]
Epoch 101: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=35.6503, avg_loss=35.4183]
Epoch 101: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.1575, avg_loss=36.5234]
INFO:__main__:=== EPOCH 101 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 101 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.996034
INFO:__main__:🔢 Total Loss: 35.418331
INFO:__main__:=== EPOCH 101 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.822619
INFO:__main__:   • gene_expression: 22.841022
INFO:__main__:🔢 Total Loss: 36.523367
INFO:__main__:   • gene_density: 1.177557
INFO:__main__:   • gene_density: 1.182647
INFO:__main__:   • operon_membership: 11.995859
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • operon_membership: 11.394663
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_expression: 24.130114
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.188447
INFO:__main__:   • operon_membership: 11.204807
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 101:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=35.9967, avg_loss=35.1912]Epoch 101: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=35.9967, avg_loss=35.1912]Epoch 101: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=35.9967, avg_loss=35.1912]
INFO:__main__:=== EPOCH 101 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.191187
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.228414
INFO:__main__:   • gene_density: 1.181877
INFO:__main__:   • operon_membership: 11.780895
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 102/681
INFO:__main__:Epoch 102/681
INFO:__main__:Epoch 102/681
INFO:__main__:Epoch 102/681
Epoch 102:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 102:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 102:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 102:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 102:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1068, avg_loss=35.1068]Epoch 102:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.9399, avg_loss=37.9399]Epoch 102:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:   0%|          | 0/11 [00:01<?, ?it/s, loss=30.8925, avg_loss=30.8925]Epoch 102:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3242, avg_loss=35.3242]Epoch 102:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  45%|████▌     | 5/11 [00:07<00:08,  1.39s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:  45%|████▌     | 5/11 [00:07<00:08,  1.39s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:  45%|████▌     | 5/11 [00:07<00:08,  1.39s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:  45%|████▌     | 5/11 [00:07<00:08,  1.39s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  55%|█████▍    | 6/11 [00:08<00:06,  1.32s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:  55%|█████▍    | 6/11 [00:08<00:06,  1.32s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:  55%|█████▍    | 6/11 [00:08<00:06,  1.32s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:  55%|█████▍    | 6/11 [00:08<00:06,  1.32s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  64%|██████▎   | 7/11 [00:09<00:04,  1.17s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  82%|████████▏ | 9/11 [00:11<00:02,  1.22s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:  82%|████████▏ | 9/11 [00:11<00:02,  1.22s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:  82%|████████▏ | 9/11 [00:11<00:02,  1.22s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:  82%|████████▏ | 9/11 [00:11<00:02,  1.22s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  91%|█████████ | 10/11 [00:13<00:01,  1.29s/it, loss=37.9399, avg_loss=37.9399]Epoch 102:  91%|█████████ | 10/11 [00:13<00:01,  1.29s/it, loss=35.1068, avg_loss=35.1068]Epoch 102:  91%|█████████ | 10/11 [00:13<00:01,  1.29s/it, loss=30.8925, avg_loss=30.8925]Epoch 102:  91%|█████████ | 10/11 [00:13<00:01,  1.29s/it, loss=35.3242, avg_loss=35.3242]Epoch 102:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=34.6577, avg_loss=35.7598]Epoch 102:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=37.9665, avg_loss=36.5871]Epoch 102: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=34.6577, avg_loss=35.7598]Epoch 102: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=37.9665, avg_loss=36.5871]Epoch 102:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=36.8567, avg_loss=35.4229]Epoch 102: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=36.8567, avg_loss=35.4229]Epoch 102: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.6577, avg_loss=35.7598]
Epoch 102: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=37.9665, avg_loss=36.5871]
Epoch 102: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=36.8567, avg_loss=35.4229]
INFO:__main__:=== EPOCH 102 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 102 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.759790
INFO:__main__:🔢 Total Loss: 36.587111
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.921115
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.175781
INFO:__main__:   • gene_expression: 23.225421
INFO:__main__:   • operon_membership: 11.662894
INFO:__main__:   • gene_density: 1.188920
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 12.172769
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:=== EPOCH 102 TRAINING LOSSES ===
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 35.422880
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.879245
INFO:__main__:   • gene_density: 1.191465
INFO:__main__:   • operon_membership: 11.352169
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 102:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=32.9507, avg_loss=35.2951]Epoch 102: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=32.9507, avg_loss=35.2951]Epoch 102: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=32.9507, avg_loss=35.2951]
INFO:__main__:=== EPOCH 102 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.295146
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.670908
INFO:__main__:   • gene_density: 1.176077
INFO:__main__:   • operon_membership: 11.448161
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 103/681
INFO:__main__:Epoch 103/681
INFO:__main__:Epoch 103/681
INFO:__main__:Epoch 103/681
Epoch 103:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 103:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 103:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 103:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 103:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3580, avg_loss=34.3580]Epoch 103:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7212, avg_loss=37.7212]Epoch 103:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.0461, avg_loss=39.0461]Epoch 103:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2961, avg_loss=34.2961]Epoch 103:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  64%|██████▎   | 7/11 [00:10<00:05,  1.36s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:  64%|██████▎   | 7/11 [00:10<00:05,  1.36s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:  64%|██████▎   | 7/11 [00:10<00:05,  1.36s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:  64%|██████▎   | 7/11 [00:10<00:05,  1.35s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  73%|███████▎  | 8/11 [00:11<00:03,  1.28s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:  73%|███████▎  | 8/11 [00:11<00:03,  1.28s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:  73%|███████▎  | 8/11 [00:11<00:03,  1.28s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:  73%|███████▎  | 8/11 [00:11<00:03,  1.27s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=37.7212, avg_loss=37.7212]Epoch 103:  91%|█████████ | 10/11 [00:13<00:01,  1.18s/it, loss=39.0461, avg_loss=39.0461]Epoch 103:  91%|█████████ | 10/11 [00:13<00:01,  1.18s/it, loss=34.3580, avg_loss=34.3580]Epoch 103:  91%|█████████ | 10/11 [00:13<00:01,  1.18s/it, loss=34.2961, avg_loss=34.2961]Epoch 103:  91%|█████████ | 10/11 [00:14<00:01,  1.17s/it, loss=40.8573, avg_loss=36.5063]Epoch 103: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=40.8573, avg_loss=36.5063]Epoch 103: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=40.8573, avg_loss=36.5063]
INFO:__main__:=== EPOCH 103 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.506299
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.365233
INFO:__main__:   • gene_density: 1.175308
INFO:__main__:   • operon_membership: 11.965758
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 103:  91%|█████████ | 10/11 [00:14<00:01,  1.18s/it, loss=35.0153, avg_loss=35.8820]Epoch 103: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.0153, avg_loss=35.8820]Epoch 103:  91%|█████████ | 10/11 [00:14<00:01,  1.18s/it, loss=36.9804, avg_loss=35.6178]Epoch 103: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.9804, avg_loss=35.6178]Epoch 103: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.0153, avg_loss=35.8820]
Epoch 103: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=36.9804, avg_loss=35.6178]
INFO:__main__:=== EPOCH 103 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.882021
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.571798
INFO:__main__:=== EPOCH 103 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.176255
INFO:__main__:   • operon_membership: 11.133969
INFO:__main__:🔢 Total Loss: 35.617793
INFO:__main__:👥 Samples processed: 22
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 23.199811
INFO:__main__:   • gene_density: 1.190519
INFO:__main__:   • operon_membership: 11.227464
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 103:  91%|█████████ | 10/11 [00:14<00:01,  1.18s/it, loss=35.6317, avg_loss=35.1202]Epoch 103: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.6317, avg_loss=35.1202]Epoch 103: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.6317, avg_loss=35.1202]
INFO:__main__:=== EPOCH 103 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.120194
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.929377
INFO:__main__:   • gene_density: 1.189039
INFO:__main__:   • operon_membership: 12.001778
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 104/681
INFO:__main__:Epoch 104/681
INFO:__main__:Epoch 104/681
INFO:__main__:Epoch 104/681
Epoch 104:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 104:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 104:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 104:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 104:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.3603, avg_loss=38.3603]Epoch 104:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3977, avg_loss=34.3977]Epoch 104:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5475, avg_loss=34.5475]Epoch 104:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.2355, avg_loss=33.2355]Epoch 104:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  82%|████████▏ | 9/11 [00:12<00:02,  1.33s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:  82%|████████▏ | 9/11 [00:12<00:02,  1.33s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:  82%|████████▏ | 9/11 [00:12<00:02,  1.33s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:  82%|████████▏ | 9/11 [00:12<00:02,  1.33s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=38.3603, avg_loss=38.3603]Epoch 104:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=33.2355, avg_loss=33.2355]Epoch 104:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=34.5475, avg_loss=34.5475]Epoch 104:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=34.3977, avg_loss=34.3977]Epoch 104:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=34.1998, avg_loss=35.8390]Epoch 104: 100%|██████████| 11/11 [00:14<00:00,  1.19s/it, loss=34.1998, avg_loss=35.8390]Epoch 104: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.1998, avg_loss=35.8390]
INFO:__main__:=== EPOCH 104 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.838952
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.196750
INFO:__main__:   • gene_density: 1.188447
INFO:__main__:   • operon_membership: 11.453756
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 104:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=34.5163, avg_loss=36.0694]Epoch 104: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=34.5163, avg_loss=36.0694]Epoch 104: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.5163, avg_loss=36.0694]
INFO:__main__:=== EPOCH 104 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.069369
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.135788
INFO:__main__:   • gene_density: 1.191110
INFO:__main__:   • operon_membership: 11.742471
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 104:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=35.1469, avg_loss=35.6871]Epoch 104: 100%|██████████| 11/11 [00:14<00:00,  1.19s/it, loss=35.1469, avg_loss=35.6871]Epoch 104: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.1469, avg_loss=35.6871]
INFO:__main__:=== EPOCH 104 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.687124
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.582413
INFO:__main__:   • gene_density: 1.168916
INFO:__main__:   • operon_membership: 11.935795
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 104:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=36.3562, avg_loss=35.5587]Epoch 104: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=36.3562, avg_loss=35.5587]Epoch 104: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=36.3562, avg_loss=35.5587]
INFO:__main__:=== EPOCH 104 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.558664
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.864116
INFO:__main__:   • gene_density: 1.185073
INFO:__main__:   • operon_membership: 11.509474
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 105/681
INFO:__main__:Epoch 105/681
INFO:__main__:Epoch 105/681
INFO:__main__:Epoch 105/681
Epoch 105:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 105:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 105:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 105:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 105:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0377, avg_loss=35.0377]Epoch 105:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7155, avg_loss=35.7155]Epoch 105:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.5295, avg_loss=31.5295]Epoch 105:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.7359, avg_loss=31.7359]Epoch 105:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  18%|█▊        | 2/11 [00:03<00:13,  1.56s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:  18%|█▊        | 2/11 [00:03<00:13,  1.56s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:  55%|█████▍    | 6/11 [00:08<00:07,  1.47s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=35.0377, avg_loss=35.0377]Epoch 105:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=35.7155, avg_loss=35.7155]Epoch 105:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=31.5295, avg_loss=31.5295]Epoch 105:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=31.7359, avg_loss=31.7359]Epoch 105:  91%|█████████ | 10/11 [00:15<00:01,  1.37s/it, loss=37.9090, avg_loss=35.3035]Epoch 105:  91%|█████████ | 10/11 [00:15<00:01,  1.37s/it, loss=39.2786, avg_loss=35.8509]Epoch 105: 100%|██████████| 11/11 [00:15<00:00,  1.34s/it, loss=37.9090, avg_loss=35.3035]Epoch 105: 100%|██████████| 11/11 [00:15<00:00,  1.34s/it, loss=39.2786, avg_loss=35.8509]Epoch 105: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=37.9090, avg_loss=35.3035]
Epoch 105: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=39.2786, avg_loss=35.8509]
INFO:__main__:=== EPOCH 105 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 105 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.850942
INFO:__main__:🔢 Total Loss: 35.303489
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.551851
INFO:__main__:   • gene_expression: 21.538574
INFO:__main__:   • gene_density: 1.182647
INFO:__main__:   • gene_density: 1.183535
INFO:__main__:   • operon_membership: 11.116444
INFO:__main__:   • operon_membership: 12.581380
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 105:  91%|█████████ | 10/11 [00:15<00:01,  1.37s/it, loss=37.4178, avg_loss=35.6336]Epoch 105: 100%|██████████| 11/11 [00:15<00:00,  1.34s/it, loss=37.4178, avg_loss=35.6336]Epoch 105:  91%|█████████ | 10/11 [00:15<00:01,  1.36s/it, loss=36.3069, avg_loss=36.3660]Epoch 105: 100%|██████████| 11/11 [00:15<00:00,  1.34s/it, loss=36.3069, avg_loss=36.3660]Epoch 105: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=37.4178, avg_loss=35.6336]
Epoch 105: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=36.3069, avg_loss=36.3660]
INFO:__main__:=== EPOCH 105 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.633588
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.025645
INFO:__main__:   • gene_density: 1.183594
INFO:__main__:   • operon_membership: 11.424348
INFO:__main__:=== EPOCH 105 TRAINING LOSSES ===
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 36.366034
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.595413
INFO:__main__:   • gene_density: 1.179628
INFO:__main__:   • operon_membership: 11.590993
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.74it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.76it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.74it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.76it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.35it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.34it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.35it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.34it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.25it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.25it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.25it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.21it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.77it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.77it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.77it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.90it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.89it/s]

Validation: 100%|██████████| 4/4 [00:02<00:00,  1.89it/s]
INFO:__main__:=== EPOCH 105 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 105 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 105 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.88it/s]
INFO:__main__:=== EPOCH 105 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 106/681
INFO:__main__:Epoch 106/681
INFO:__main__:Epoch 106/681
INFO:__main__:Epoch 106/681
Epoch 106:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 106:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 106:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 106:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 106:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9074, avg_loss=35.9074]Epoch 106:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9279, avg_loss=35.9279]Epoch 106:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3292, avg_loss=35.3292]Epoch 106:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.8423, avg_loss=38.8423]Epoch 106:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  82%|████████▏ | 9/11 [00:13<00:02,  1.38s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=35.9074, avg_loss=35.9074]Epoch 106:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=35.9279, avg_loss=35.9279]Epoch 106:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=35.3292, avg_loss=35.3292]Epoch 106:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=38.8423, avg_loss=38.8423]Epoch 106:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=37.3721, avg_loss=35.7184]Epoch 106: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=37.3721, avg_loss=35.7184]Epoch 106:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=37.4543, avg_loss=35.8339]Epoch 106: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=37.4543, avg_loss=35.8339]Epoch 106: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.3721, avg_loss=35.7184]
Epoch 106: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.4543, avg_loss=35.8339]
INFO:__main__:=== EPOCH 106 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.718366
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.417796
INFO:__main__:   • gene_density: 1.179688
INFO:__main__:   • operon_membership: 11.120883
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 106 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.833894
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.361607
INFO:__main__:   • gene_density: 1.187204
INFO:__main__:   • operon_membership: 12.285082
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 106:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=38.5066, avg_loss=36.4722]Epoch 106: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=38.5066, avg_loss=36.4722]Epoch 106: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=38.5066, avg_loss=36.4722]
Epoch 106:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=35.5293, avg_loss=35.2692]Epoch 106: 100%|██████████| 11/11 [00:15<00:00,  1.28s/it, loss=35.5293, avg_loss=35.2692]Epoch 106: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=35.5293, avg_loss=35.2692]
INFO:__main__:=== EPOCH 106 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.472180
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.907395
INFO:__main__:   • gene_density: 1.178445
INFO:__main__:   • operon_membership: 11.386340
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 106 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.269209
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.247405
INFO:__main__:   • gene_density: 1.186671
INFO:__main__:   • operon_membership: 11.835133
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 107/681
INFO:__main__:Epoch 107/681
INFO:__main__:Epoch 107/681
INFO:__main__:Epoch 107/681
Epoch 107:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 107:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 107:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 107:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 107:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3718, avg_loss=35.3718]Epoch 107:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9002, avg_loss=36.9002]Epoch 107:   9%|▉         | 1/11 [00:01<00:12,  1.20s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:   9%|▉         | 1/11 [00:01<00:12,  1.20s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.7425, avg_loss=39.7425]Epoch 107:   9%|▉         | 1/11 [00:01<00:12,  1.20s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0065, avg_loss=34.0065]Epoch 107:   9%|▉         | 1/11 [00:01<00:12,  1.21s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  18%|█▊        | 2/11 [00:02<00:11,  1.32s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:  18%|█▊        | 2/11 [00:02<00:11,  1.32s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:  18%|█▊        | 2/11 [00:02<00:11,  1.32s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:  18%|█▊        | 2/11 [00:02<00:11,  1.33s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:  27%|██▋       | 3/11 [00:04<00:10,  1.36s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:  27%|██▋       | 3/11 [00:04<00:10,  1.37s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  36%|███▋      | 4/11 [00:05<00:09,  1.38s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  55%|█████▍    | 6/11 [00:08<00:06,  1.40s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:  55%|█████▍    | 6/11 [00:08<00:06,  1.40s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:  55%|█████▍    | 6/11 [00:08<00:06,  1.40s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:  55%|█████▍    | 6/11 [00:08<00:06,  1.40s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  91%|█████████ | 10/11 [00:14<00:01,  1.46s/it, loss=35.3718, avg_loss=35.3718]Epoch 107:  91%|█████████ | 10/11 [00:14<00:01,  1.46s/it, loss=39.7425, avg_loss=39.7425]Epoch 107:  91%|█████████ | 10/11 [00:14<00:01,  1.46s/it, loss=36.9002, avg_loss=36.9002]Epoch 107:  91%|█████████ | 10/11 [00:14<00:01,  1.46s/it, loss=34.0065, avg_loss=34.0065]Epoch 107:  91%|█████████ | 10/11 [00:15<00:01,  1.46s/it, loss=35.2312, avg_loss=36.3397]Epoch 107: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=35.2312, avg_loss=36.3397]Epoch 107: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.2312, avg_loss=36.3397]
INFO:__main__:=== EPOCH 107 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.339704
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.501972
INFO:__main__:   • gene_density: 1.179924
INFO:__main__:   • operon_membership: 11.657808
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 107:  91%|█████████ | 10/11 [00:15<00:01,  1.46s/it, loss=33.7333, avg_loss=35.6446]Epoch 107: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=33.7333, avg_loss=35.6446]Epoch 107: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=33.7333, avg_loss=35.6446]
Epoch 107:  91%|█████████ | 10/11 [00:15<00:01,  1.46s/it, loss=36.2732, avg_loss=36.0786]Epoch 107: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=36.2732, avg_loss=36.0786]Epoch 107: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=36.2732, avg_loss=36.0786]
INFO:__main__:=== EPOCH 107 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.644608
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.533856
INFO:__main__:   • gene_density: 1.180043
INFO:__main__:   • operon_membership: 11.930709
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 107 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.078556
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.405081
INFO:__main__:   • gene_density: 1.182173
INFO:__main__:   • operon_membership: 11.491302
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 107:  91%|█████████ | 10/11 [00:15<00:01,  1.46s/it, loss=33.8214, avg_loss=35.1418]Epoch 107: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=33.8214, avg_loss=35.1418]Epoch 107: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=33.8214, avg_loss=35.1418]
INFO:__main__:=== EPOCH 107 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.141763
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.446199
INFO:__main__:   • gene_density: 1.190992
INFO:__main__:   • operon_membership: 11.504572
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 108/681
INFO:__main__:Epoch 108/681
INFO:__main__:Epoch 108/681
INFO:__main__:Epoch 108/681
Epoch 108:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 108:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 108:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 108:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 108:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.3422, avg_loss=33.3422]Epoch 108:   9%|▉         | 1/11 [00:01<00:13,  1.37s/it, loss=33.3422, avg_loss=33.3422]Epoch 108:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9239, avg_loss=36.9239]Epoch 108:   9%|▉         | 1/11 [00:01<00:13,  1.37s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.2436, avg_loss=39.2436]Epoch 108:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=39.2436, avg_loss=39.2436]Epoch 108:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.6161, avg_loss=38.6161]Epoch 108:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=38.6161, avg_loss=38.6161]Epoch 108:  18%|█▊        | 2/11 [00:02<00:10,  1.13s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:  18%|█▊        | 2/11 [00:02<00:10,  1.13s/it, loss=33.3422, avg_loss=33.3422]Epoch 108:  18%|█▊        | 2/11 [00:02<00:10,  1.13s/it, loss=38.6161, avg_loss=38.6161]Epoch 108:  18%|█▊        | 2/11 [00:02<00:10,  1.13s/it, loss=39.2436, avg_loss=39.2436]Epoch 108:  27%|██▋       | 3/11 [00:03<00:07,  1.00it/s, loss=33.3422, avg_loss=33.3422]Epoch 108:  27%|██▋       | 3/11 [00:03<00:07,  1.00it/s, loss=38.6161, avg_loss=38.6161]Epoch 108:  27%|██▋       | 3/11 [00:03<00:08,  1.00s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:  27%|██▋       | 3/11 [00:03<00:07,  1.00it/s, loss=39.2436, avg_loss=39.2436]Epoch 108:  36%|███▋      | 4/11 [00:04<00:07,  1.14s/it, loss=33.3422, avg_loss=33.3422]Epoch 108:  36%|███▋      | 4/11 [00:04<00:07,  1.14s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:  36%|███▋      | 4/11 [00:04<00:07,  1.14s/it, loss=39.2436, avg_loss=39.2436]Epoch 108:  36%|███▋      | 4/11 [00:04<00:08,  1.15s/it, loss=38.6161, avg_loss=38.6161]Epoch 108:  45%|████▌     | 5/11 [00:06<00:07,  1.26s/it, loss=33.3422, avg_loss=33.3422]Epoch 108:  45%|████▌     | 5/11 [00:06<00:07,  1.26s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:  45%|████▌     | 5/11 [00:06<00:07,  1.26s/it, loss=39.2436, avg_loss=39.2436]Epoch 108:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=38.6161, avg_loss=38.6161]Epoch 108:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=33.3422, avg_loss=33.3422]Epoch 108:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=39.2436, avg_loss=39.2436]Epoch 108:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=38.6161, avg_loss=38.6161]Epoch 108:  64%|██████▎   | 7/11 [00:08<00:05,  1.37s/it, loss=39.2436, avg_loss=39.2436]Epoch 108:  64%|██████▎   | 7/11 [00:08<00:05,  1.38s/it, loss=33.3422, avg_loss=33.3422]Epoch 108:  64%|██████▎   | 7/11 [00:08<00:05,  1.38s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:  64%|██████▎   | 7/11 [00:08<00:05,  1.38s/it, loss=38.6161, avg_loss=38.6161]Epoch 108:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=39.2436, avg_loss=39.2436]Epoch 108:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=33.3422, avg_loss=33.3422]Epoch 108:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=38.6161, avg_loss=38.6161]Epoch 108:  82%|████████▏ | 9/11 [00:11<00:02,  1.28s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:  82%|████████▏ | 9/11 [00:11<00:02,  1.28s/it, loss=39.2436, avg_loss=39.2436]Epoch 108:  82%|████████▏ | 9/11 [00:11<00:02,  1.28s/it, loss=38.6161, avg_loss=38.6161]Epoch 108:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=33.3422, avg_loss=33.3422]Epoch 108:  91%|█████████ | 10/11 [00:12<00:01,  1.15s/it, loss=39.2436, avg_loss=39.2436]Epoch 108:  91%|█████████ | 10/11 [00:12<00:01,  1.15s/it, loss=38.6161, avg_loss=38.6161]Epoch 108:  91%|█████████ | 10/11 [00:12<00:01,  1.15s/it, loss=36.9239, avg_loss=36.9239]Epoch 108:  91%|█████████ | 10/11 [00:12<00:01,  1.15s/it, loss=33.3422, avg_loss=33.3422]Epoch 108:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=35.3108, avg_loss=35.6061]Epoch 108: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it, loss=35.3108, avg_loss=35.6061]Epoch 108: 100%|██████████| 11/11 [00:13<00:00,  1.24s/it, loss=35.3108, avg_loss=35.6061]
INFO:__main__:=== EPOCH 108 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.606090
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.686049
INFO:__main__:   • gene_density: 1.192412
INFO:__main__:   • operon_membership: 11.727628
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 108:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=32.8083, avg_loss=36.0801]Epoch 108: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it, loss=32.8083, avg_loss=36.0801]Epoch 108: 100%|██████████| 11/11 [00:13<00:00,  1.24s/it, loss=32.8083, avg_loss=36.0801]
Epoch 108:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=35.7595, avg_loss=35.4530]Epoch 108: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it, loss=35.7595, avg_loss=35.4530]Epoch 108: 100%|██████████| 11/11 [00:13<00:00,  1.24s/it, loss=35.7595, avg_loss=35.4530]
INFO:__main__:=== EPOCH 108 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.080080
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.836305
INFO:__main__:   • gene_density: 1.175367
INFO:__main__:   • operon_membership: 12.068408
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 108 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.453034
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.857235
INFO:__main__:   • gene_density: 1.183890
INFO:__main__:   • operon_membership: 11.411910
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 108:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=34.7617, avg_loss=35.9701]Epoch 108: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it, loss=34.7617, avg_loss=35.9701]Epoch 108: 100%|██████████| 11/11 [00:13<00:00,  1.24s/it, loss=34.7617, avg_loss=35.9701]
INFO:__main__:=== EPOCH 108 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.970141
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.379679
INFO:__main__:   • gene_density: 1.181049
INFO:__main__:   • operon_membership: 11.409413
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 109/681
INFO:__main__:Epoch 109/681
INFO:__main__:Epoch 109/681
INFO:__main__:Epoch 109/681
Epoch 109:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 109:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 109:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 109:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 109:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.0491, avg_loss=38.0491]Epoch 109:   9%|▉         | 1/11 [00:01<00:12,  1.21s/it, loss=32.8086, avg_loss=32.8086]Epoch 109:   9%|▉         | 1/11 [00:01<00:12,  1.21s/it, loss=38.0491, avg_loss=38.0491]Epoch 109:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.1119, avg_loss=39.1119]Epoch 109:   9%|▉         | 1/11 [00:01<00:12,  1.22s/it, loss=39.1119, avg_loss=39.1119]Epoch 109:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2655, avg_loss=35.2655]Epoch 109:   9%|▉         | 1/11 [00:01<00:12,  1.22s/it, loss=35.2655, avg_loss=35.2655]Epoch 109:  18%|█▊        | 2/11 [00:02<00:08,  1.00it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:  18%|█▊        | 2/11 [00:02<00:09,  1.00s/it, loss=38.0491, avg_loss=38.0491]Epoch 109:  18%|█▊        | 2/11 [00:02<00:09,  1.00s/it, loss=39.1119, avg_loss=39.1119]Epoch 109:  18%|█▊        | 2/11 [00:02<00:09,  1.00s/it, loss=35.2655, avg_loss=35.2655]Epoch 109:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, loss=35.2655, avg_loss=35.2655]Epoch 109:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, loss=38.0491, avg_loss=38.0491]Epoch 109:  27%|██▋       | 3/11 [00:02<00:07,  1.08it/s, loss=39.1119, avg_loss=39.1119]Epoch 109:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, loss=38.0491, avg_loss=38.0491]Epoch 109:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, loss=35.2655, avg_loss=35.2655]Epoch 109:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, loss=39.1119, avg_loss=39.1119]Epoch 109:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, loss=38.0491, avg_loss=38.0491]Epoch 109:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, loss=35.2655, avg_loss=35.2655]Epoch 109:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, loss=39.1119, avg_loss=39.1119]Epoch 109:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=35.2655, avg_loss=35.2655]Epoch 109:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=38.0491, avg_loss=38.0491]Epoch 109:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=39.1119, avg_loss=39.1119]Epoch 109:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=38.0491, avg_loss=38.0491]Epoch 109:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=35.2655, avg_loss=35.2655]Epoch 109:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=39.1119, avg_loss=39.1119]Epoch 109:  73%|███████▎  | 8/11 [00:07<00:02,  1.19it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:  73%|███████▎  | 8/11 [00:07<00:02,  1.19it/s, loss=38.0491, avg_loss=38.0491]Epoch 109:  73%|███████▎  | 8/11 [00:07<00:02,  1.19it/s, loss=39.1119, avg_loss=39.1119]Epoch 109:  73%|███████▎  | 8/11 [00:07<00:02,  1.18it/s, loss=35.2655, avg_loss=35.2655]Epoch 109:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=38.0491, avg_loss=38.0491]Epoch 109:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=35.2655, avg_loss=35.2655]Epoch 109:  82%|████████▏ | 9/11 [00:07<00:01,  1.19it/s, loss=39.1119, avg_loss=39.1119]Epoch 109:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=38.0491, avg_loss=38.0491]Epoch 109:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=35.2655, avg_loss=35.2655]Epoch 109:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=32.8086, avg_loss=32.8086]Epoch 109:  91%|█████████ | 10/11 [00:08<00:00,  1.19it/s, loss=39.1119, avg_loss=39.1119]Epoch 109:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=35.3398, avg_loss=36.1760]Epoch 109: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=35.3398, avg_loss=36.1760]Epoch 109: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=35.3398, avg_loss=36.1760]Epoch 109:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=39.3776, avg_loss=35.1860]
Epoch 109:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=36.1859, avg_loss=36.1371]Epoch 109: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=39.3776, avg_loss=35.1860]Epoch 109: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=36.1859, avg_loss=36.1371]Epoch 109: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=39.3776, avg_loss=35.1860]
Epoch 109: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=36.1859, avg_loss=36.1371]
INFO:__main__:=== EPOCH 109 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.176001
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.181237
INFO:__main__:   • gene_density: 1.178681
INFO:__main__:   • operon_membership: 11.816083
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 109 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 109 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.186047
INFO:__main__:🔢 Total Loss: 36.137120
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.098463
INFO:__main__:   • gene_expression: 23.401365
INFO:__main__:   • gene_density: 1.187855
INFO:__main__:   • gene_density: 1.187027
INFO:__main__:   • operon_membership: 11.899729
INFO:__main__:   • operon_membership: 11.548730
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 109:  91%|█████████ | 10/11 [00:09<00:00,  1.19it/s, loss=37.4476, avg_loss=35.6852]Epoch 109: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=37.4476, avg_loss=35.6852]Epoch 109: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=37.4476, avg_loss=35.6852]
INFO:__main__:=== EPOCH 109 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.685246
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.210426
INFO:__main__:   • gene_density: 1.176196
INFO:__main__:   • operon_membership: 11.298625
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 110/681
INFO:__main__:Epoch 110/681
INFO:__main__:Epoch 110/681
INFO:__main__:Epoch 110/681
Epoch 110:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 110:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 110:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 110:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 110:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2840, avg_loss=35.2840]Epoch 110:   9%|▉         | 1/11 [00:01<00:15,  1.57s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4798, avg_loss=36.4798]Epoch 110:   9%|▉         | 1/11 [00:01<00:15,  1.57s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.6617, avg_loss=38.6617]Epoch 110:   9%|▉         | 1/11 [00:01<00:15,  1.58s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:   0%|          | 0/11 [00:01<?, ?it/s, loss=40.9540, avg_loss=40.9540]Epoch 110:   9%|▉         | 1/11 [00:01<00:15,  1.59s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  18%|█▊        | 2/11 [00:02<00:13,  1.48s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:  18%|█▊        | 2/11 [00:02<00:13,  1.48s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:  18%|█▊        | 2/11 [00:02<00:13,  1.48s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=36.4798, avg_loss=36.4798]Epoch 110:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=38.6617, avg_loss=38.6617]Epoch 110:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=35.2840, avg_loss=35.2840]Epoch 110:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=40.9540, avg_loss=40.9540]Epoch 110:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=31.6037, avg_loss=36.8298]Epoch 110: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=31.6037, avg_loss=36.8298]Epoch 110: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=31.6037, avg_loss=36.8298]
INFO:__main__:=== EPOCH 110 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.829784
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.589429
INFO:__main__:   • gene_density: 1.186790
INFO:__main__:   • operon_membership: 12.053565
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 110:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=39.5501, avg_loss=36.2890]Epoch 110: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=39.5501, avg_loss=36.2890]Epoch 110:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=33.5895, avg_loss=34.4068]Epoch 110: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.5895, avg_loss=34.4068]Epoch 110: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=39.5501, avg_loss=36.2890]
Epoch 110: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=33.5895, avg_loss=34.4068]
INFO:__main__:=== EPOCH 110 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.288995
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.278687
INFO:__main__:   • gene_density: 1.171106
INFO:__main__:   • operon_membership: 11.839202
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 110 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.406842
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.114545
INFO:__main__:   • gene_density: 1.178859
INFO:__main__:   • operon_membership: 11.113439
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 110:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.1071, avg_loss=35.4293]Epoch 110: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.1071, avg_loss=35.4293]Epoch 110: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.1071, avg_loss=35.4293]
INFO:__main__:=== EPOCH 110 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.429298
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.845909
INFO:__main__:   • gene_density: 1.192472
INFO:__main__:   • operon_membership: 11.390918
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.40it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.41it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.42it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.41it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.73it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.72it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.73it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.72it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.01it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.02it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.02it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.04it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  2.01it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  2.00it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  2.01it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.91it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  2.02it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.90it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.91it/s]
INFO:__main__:=== EPOCH 110 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:=== EPOCH 110 VALIDATION LOSSES ===
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:=== EPOCH 110 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.92it/s]
INFO:__main__:=== EPOCH 110 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_110.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_110.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_110.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_110.pt
INFO:__main__:Epoch 111/681
INFO:__main__:Epoch 111/681
INFO:__main__:Epoch 111/681
INFO:__main__:Epoch 111/681
Epoch 111:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 111:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 111:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 111:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 111:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3949, avg_loss=35.3949]Epoch 111:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1132, avg_loss=35.1132]Epoch 111:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8218, avg_loss=33.8218]Epoch 111:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6339, avg_loss=36.6339]Epoch 111:   9%|▉         | 1/11 [00:01<00:18,  1.82s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  18%|█▊        | 2/11 [00:03<00:14,  1.63s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:  18%|█▊        | 2/11 [00:03<00:14,  1.63s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:  18%|█▊        | 2/11 [00:03<00:14,  1.63s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:  18%|█▊        | 2/11 [00:03<00:14,  1.63s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  27%|██▋       | 3/11 [00:04<00:12,  1.56s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:  27%|██▋       | 3/11 [00:04<00:12,  1.56s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:  27%|██▋       | 3/11 [00:04<00:12,  1.56s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:  27%|██▋       | 3/11 [00:04<00:12,  1.56s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:  45%|████▌     | 5/11 [00:07<00:08,  1.43s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  55%|█████▍    | 6/11 [00:08<00:06,  1.35s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:  55%|█████▍    | 6/11 [00:08<00:06,  1.35s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:  55%|█████▍    | 6/11 [00:08<00:06,  1.35s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:  55%|█████▍    | 6/11 [00:08<00:06,  1.35s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  64%|██████▎   | 7/11 [00:09<00:04,  1.23s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:  64%|██████▎   | 7/11 [00:09<00:04,  1.23s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:  64%|██████▎   | 7/11 [00:09<00:04,  1.22s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  64%|██████▎   | 7/11 [00:09<00:04,  1.23s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:  73%|███████▎  | 8/11 [00:10<00:03,  1.12s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  82%|████████▏ | 9/11 [00:11<00:02,  1.22s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:  82%|████████▏ | 9/11 [00:11<00:02,  1.22s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:  82%|████████▏ | 9/11 [00:11<00:02,  1.22s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:  82%|████████▏ | 9/11 [00:12<00:02,  1.22s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  91%|█████████ | 10/11 [00:13<00:01,  1.30s/it, loss=33.8218, avg_loss=33.8218]Epoch 111:  91%|█████████ | 10/11 [00:13<00:01,  1.30s/it, loss=35.1132, avg_loss=35.1132]Epoch 111:  91%|█████████ | 10/11 [00:13<00:01,  1.30s/it, loss=35.3949, avg_loss=35.3949]Epoch 111:  91%|█████████ | 10/11 [00:13<00:01,  1.30s/it, loss=36.6339, avg_loss=36.6339]Epoch 111:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=36.5944, avg_loss=35.8228]Epoch 111: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=36.5944, avg_loss=35.8228]Epoch 111: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.5944, avg_loss=35.8228]
INFO:__main__:=== EPOCH 111 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.822759
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.713164
INFO:__main__:   • gene_density: 1.183002
INFO:__main__:   • operon_membership: 11.926593
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 111:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=37.2912, avg_loss=36.1879]Epoch 111:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=35.4202, avg_loss=36.0138]Epoch 111: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=37.2912, avg_loss=36.1879]Epoch 111: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.4202, avg_loss=36.0138]Epoch 111: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.2912, avg_loss=36.1879]
Epoch 111: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.4202, avg_loss=36.0138]
INFO:__main__:=== EPOCH 111 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.187874
INFO:__main__:=== EPOCH 111 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.002350
INFO:__main__:🔢 Total Loss: 36.013754
INFO:__main__:   • gene_density: 1.187678
INFO:__main__:   • operon_membership: 11.997848
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_expression: 23.543811
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.169330
INFO:__main__:   • operon_membership: 11.300613
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 111:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=35.7778, avg_loss=34.9974]Epoch 111: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.7778, avg_loss=34.9974]Epoch 111: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.7778, avg_loss=34.9974]
INFO:__main__:=== EPOCH 111 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.997419
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.579592
INFO:__main__:   • gene_density: 1.192768
INFO:__main__:   • operon_membership: 11.225059
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 112/681
INFO:__main__:Epoch 112/681
INFO:__main__:Epoch 112/681
INFO:__main__:Epoch 112/681
Epoch 112:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 112:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 112:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 112:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 112:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8014, avg_loss=35.8014]Epoch 112:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.6161, avg_loss=38.6161]Epoch 112:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4046, avg_loss=35.4046]Epoch 112:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.3034, avg_loss=31.3034]Epoch 112:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  64%|██████▎   | 7/11 [00:10<00:05,  1.37s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:  64%|██████▎   | 7/11 [00:10<00:05,  1.37s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:  64%|██████▎   | 7/11 [00:10<00:05,  1.37s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:  64%|██████▎   | 7/11 [00:10<00:05,  1.37s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  73%|███████▎  | 8/11 [00:11<00:03,  1.30s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:  73%|███████▎  | 8/11 [00:11<00:03,  1.30s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:  82%|████████▏ | 9/11 [00:12<00:02,  1.15s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:  82%|████████▏ | 9/11 [00:12<00:02,  1.15s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  82%|████████▏ | 9/11 [00:12<00:02,  1.15s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:  82%|████████▏ | 9/11 [00:12<00:02,  1.15s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=35.4046, avg_loss=35.4046]Epoch 112:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=35.8014, avg_loss=35.8014]Epoch 112:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=38.6161, avg_loss=38.6161]Epoch 112:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=31.3034, avg_loss=31.3034]Epoch 112:  91%|█████████ | 10/11 [00:14<00:01,  1.17s/it, loss=31.7457, avg_loss=36.1655]Epoch 112:  91%|█████████ | 10/11 [00:14<00:01,  1.17s/it, loss=33.3871, avg_loss=34.8457]Epoch 112: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=31.7457, avg_loss=36.1655]Epoch 112: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=33.3871, avg_loss=34.8457]Epoch 112: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=33.3871, avg_loss=34.8457]Epoch 112: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=31.7457, avg_loss=36.1655]

Epoch 112:  91%|█████████ | 10/11 [00:14<00:01,  1.17s/it, loss=38.3864, avg_loss=37.3474]Epoch 112: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=38.3864, avg_loss=37.3474]Epoch 112: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=38.3864, avg_loss=37.3474]
INFO:__main__:=== EPOCH 112 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 112 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.845731
INFO:__main__:🔢 Total Loss: 36.165542
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.287118
INFO:__main__:   • gene_expression: 22.589065
INFO:__main__:   • gene_density: 1.192294
INFO:__main__:   • gene_density: 1.179451
INFO:__main__:   • operon_membership: 11.366319
INFO:__main__:   • operon_membership: 12.397027
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 112 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 37.347376
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.277265
INFO:__main__:   • gene_density: 1.170336
INFO:__main__:   • operon_membership: 11.899775
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 112:  91%|█████████ | 10/11 [00:14<00:01,  1.17s/it, loss=35.8611, avg_loss=34.7057]Epoch 112: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=35.8611, avg_loss=34.7057]Epoch 112: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.8611, avg_loss=34.7057]
INFO:__main__:=== EPOCH 112 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.705736
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.478953
INFO:__main__:   • gene_density: 1.189453
INFO:__main__:   • operon_membership: 11.037330
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 113/681
INFO:__main__:Epoch 113/681
INFO:__main__:Epoch 113/681
INFO:__main__:Epoch 113/681
Epoch 113:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 113:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 113:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 113:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 113:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.5199, avg_loss=32.5199]Epoch 113:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4909, avg_loss=35.4909]Epoch 113:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2500, avg_loss=34.2500]Epoch 113:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9425, avg_loss=33.9425]Epoch 113:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  91%|█████████ | 10/11 [00:13<00:01,  1.26s/it, loss=34.2500, avg_loss=34.2500]Epoch 113:  91%|█████████ | 10/11 [00:13<00:01,  1.26s/it, loss=32.5199, avg_loss=32.5199]Epoch 113:  91%|█████████ | 10/11 [00:13<00:01,  1.26s/it, loss=35.4909, avg_loss=35.4909]Epoch 113:  91%|█████████ | 10/11 [00:13<00:01,  1.26s/it, loss=33.9425, avg_loss=33.9425]Epoch 113:  91%|█████████ | 10/11 [00:14<00:01,  1.26s/it, loss=39.0296, avg_loss=36.6747]Epoch 113: 100%|██████████| 11/11 [00:14<00:00,  1.17s/it, loss=39.0296, avg_loss=36.6747]Epoch 113: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=39.0296, avg_loss=36.6747]
INFO:__main__:=== EPOCH 113 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.674746
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.413917
INFO:__main__:   • gene_density: 1.174065
INFO:__main__:   • operon_membership: 12.086765
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 113:  91%|█████████ | 10/11 [00:14<00:01,  1.26s/it, loss=33.9112, avg_loss=35.2772]Epoch 113: 100%|██████████| 11/11 [00:14<00:00,  1.18s/it, loss=33.9112, avg_loss=35.2772]Epoch 113: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=33.9112, avg_loss=35.2772]
INFO:__main__:=== EPOCH 113 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.277157
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.146620
INFO:__main__:   • gene_density: 1.184245
INFO:__main__:   • operon_membership: 11.946291
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 113:  91%|█████████ | 10/11 [00:14<00:01,  1.26s/it, loss=34.7771, avg_loss=35.6251]Epoch 113: 100%|██████████| 11/11 [00:14<00:00,  1.18s/it, loss=34.7771, avg_loss=35.6251]Epoch 113:  91%|█████████ | 10/11 [00:14<00:01,  1.26s/it, loss=33.6149, avg_loss=35.4421]Epoch 113: 100%|██████████| 11/11 [00:14<00:00,  1.17s/it, loss=33.6149, avg_loss=35.4421]Epoch 113: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.7771, avg_loss=35.6251]
Epoch 113: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=33.6149, avg_loss=35.4421]
INFO:__main__:=== EPOCH 113 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.625095
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.462589
INFO:__main__:=== EPOCH 113 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.178859
INFO:__main__:   • operon_membership: 10.983646
INFO:__main__:🔢 Total Loss: 35.442128
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.703225
INFO:__main__:   • gene_density: 1.194010
INFO:__main__:   • operon_membership: 11.544893
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 114/681
INFO:__main__:Epoch 114/681
INFO:__main__:Epoch 114/681
INFO:__main__:Epoch 114/681
Epoch 114:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 114:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 114:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 114:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 114:   0%|          | 0/11 [00:01<?, ?it/s, loss=30.9097, avg_loss=30.9097]Epoch 114:   9%|▉         | 1/11 [00:01<00:15,  1.51s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6022, avg_loss=33.6022]Epoch 114:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.3065, avg_loss=33.3065]Epoch 114:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3728, avg_loss=35.3728]Epoch 114:   9%|▉         | 1/11 [00:01<00:15,  1.54s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  36%|███▋      | 4/11 [00:05<00:10,  1.49s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:  36%|███▋      | 4/11 [00:05<00:10,  1.49s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  55%|█████▍    | 6/11 [00:08<00:07,  1.49s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:  55%|█████▍    | 6/11 [00:08<00:07,  1.49s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:  55%|█████▍    | 6/11 [00:08<00:07,  1.49s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:  55%|█████▍    | 6/11 [00:08<00:07,  1.49s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:  64%|██████▎   | 7/11 [00:10<00:05,  1.49s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  73%|███████▎  | 8/11 [00:11<00:04,  1.49s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:  73%|███████▎  | 8/11 [00:11<00:04,  1.49s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:  73%|███████▎  | 8/11 [00:11<00:04,  1.49s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:  73%|███████▎  | 8/11 [00:11<00:04,  1.49s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  82%|████████▏ | 9/11 [00:13<00:02,  1.48s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:  82%|████████▏ | 9/11 [00:13<00:02,  1.48s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:  82%|████████▏ | 9/11 [00:13<00:02,  1.48s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:  82%|████████▏ | 9/11 [00:13<00:02,  1.48s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=33.6022, avg_loss=33.6022]Epoch 114:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=33.3065, avg_loss=33.3065]Epoch 114:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=30.9097, avg_loss=30.9097]Epoch 114:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.3728, avg_loss=35.3728]Epoch 114:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=36.5130, avg_loss=35.1532]Epoch 114:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=32.8047, avg_loss=35.6640]Epoch 114: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=36.5130, avg_loss=35.1532]Epoch 114: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=32.8047, avg_loss=35.6640]Epoch 114: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=36.5130, avg_loss=35.1532]Epoch 114: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=32.8047, avg_loss=35.6640]

INFO:__main__:=== EPOCH 114 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 114 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.663983
INFO:__main__:🔢 Total Loss: 35.153221
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.822192
INFO:__main__:   • gene_expression: 21.900213
INFO:__main__:   • gene_density: 1.183475
INFO:__main__:   • gene_density: 1.183120
INFO:__main__:   • operon_membership: 11.658316
INFO:__main__:   • operon_membership: 12.069888
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 114:  91%|█████████ | 10/11 [00:16<00:01,  1.41s/it, loss=34.6523, avg_loss=35.8973]Epoch 114: 100%|██████████| 11/11 [00:16<00:00,  1.39s/it, loss=34.6523, avg_loss=35.8973]Epoch 114: 100%|██████████| 11/11 [00:16<00:00,  1.46s/it, loss=34.6523, avg_loss=35.8973]
INFO:__main__:=== EPOCH 114 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.897295
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.545527
INFO:__main__:   • gene_density: 1.180161
INFO:__main__:   • operon_membership: 11.171607
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 114:  91%|█████████ | 10/11 [00:16<00:01,  1.41s/it, loss=38.9426, avg_loss=36.4396]Epoch 114: 100%|██████████| 11/11 [00:16<00:00,  1.38s/it, loss=38.9426, avg_loss=36.4396]Epoch 114: 100%|██████████| 11/11 [00:16<00:00,  1.46s/it, loss=38.9426, avg_loss=36.4396]
INFO:__main__:=== EPOCH 114 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.439612
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.511137
INFO:__main__:   • gene_density: 1.186790
INFO:__main__:   • operon_membership: 11.741685
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 115/681
INFO:__main__:Epoch 115/681
INFO:__main__:Epoch 115/681
INFO:__main__:Epoch 115/681
Epoch 115:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 115:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 115:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 115:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 115:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6938, avg_loss=33.6938]Epoch 115:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7510, avg_loss=35.7510]Epoch 115:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5142, avg_loss=34.5142]Epoch 115:   9%|▉         | 1/11 [00:01<00:11,  1.10s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.9774, avg_loss=39.9774]Epoch 115:   9%|▉         | 1/11 [00:01<00:11,  1.10s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:   9%|▉         | 1/11 [00:01<00:11,  1.10s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  18%|█▊        | 2/11 [00:02<00:10,  1.21s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:  18%|█▊        | 2/11 [00:02<00:10,  1.21s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:  18%|█▊        | 2/11 [00:02<00:10,  1.21s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  18%|█▊        | 2/11 [00:02<00:10,  1.22s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:  27%|██▋       | 3/11 [00:03<00:10,  1.33s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:  27%|██▋       | 3/11 [00:03<00:10,  1.33s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:  27%|██▋       | 3/11 [00:03<00:10,  1.33s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  27%|██▋       | 3/11 [00:03<00:10,  1.34s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  36%|███▋      | 4/11 [00:05<00:09,  1.40s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:  45%|████▌     | 5/11 [00:06<00:08,  1.42s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:  45%|████▌     | 5/11 [00:06<00:08,  1.42s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:  45%|████▌     | 5/11 [00:06<00:08,  1.42s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  45%|████▌     | 5/11 [00:06<00:08,  1.42s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=33.6938, avg_loss=33.6938]Epoch 115:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=35.7510, avg_loss=35.7510]Epoch 115:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=39.9774, avg_loss=39.9774]Epoch 115:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=34.5142, avg_loss=34.5142]Epoch 115:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=36.6414, avg_loss=35.4681]Epoch 115:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=31.7627, avg_loss=35.1733]Epoch 115:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=35.9047, avg_loss=36.3624]Epoch 115: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=35.9047, avg_loss=36.3624]Epoch 115: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=36.6414, avg_loss=35.4681]Epoch 115: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=31.7627, avg_loss=35.1733]Epoch 115: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.9047, avg_loss=36.3624]
Epoch 115: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=36.6414, avg_loss=35.4681]
Epoch 115: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=31.7627, avg_loss=35.1733]
INFO:__main__:=== EPOCH 115 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.362415
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.668527
INFO:__main__:   • gene_density: 1.183357
INFO:__main__:   • operon_membership: 10.510532
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 115 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.468140
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.511103
INFO:__main__:=== EPOCH 115 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.174894
INFO:__main__:   • operon_membership: 11.782144
INFO:__main__:🔢 Total Loss: 35.173341
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 20.949611
INFO:__main__:   • gene_density: 1.180516
INFO:__main__:   • operon_membership: 13.043213
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 115:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=38.7243, avg_loss=35.8096]Epoch 115: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=38.7243, avg_loss=35.8096]Epoch 115: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=38.7243, avg_loss=35.8096]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 115 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.809614
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.571140
INFO:__main__:   • gene_density: 1.195549
INFO:__main__:   • operon_membership: 11.042925
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.46it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.46it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.46it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.44it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.83it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.83it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.83it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.82it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.99it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.99it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.99it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.98it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.89it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.89it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.89it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.91it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]

Validation: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]
INFO:__main__:=== EPOCH 115 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 115 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 115 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 115 VALIDATION LOSSES ===
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:========================================
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 116/681
INFO:__main__:Epoch 116/681
INFO:__main__:Epoch 116/681
INFO:__main__:Epoch 116/681
Epoch 116:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 116:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 116:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 116:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 116:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7155, avg_loss=35.7155]Epoch 116:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7961, avg_loss=35.7961]Epoch 116:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6300, avg_loss=36.6300]Epoch 116:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2899, avg_loss=35.2899]Epoch 116:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:   9%|▉         | 1/11 [00:01<00:10,  1.09s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  18%|█▊        | 2/11 [00:02<00:11,  1.26s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:  18%|█▊        | 2/11 [00:02<00:11,  1.28s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:  27%|██▋       | 3/11 [00:03<00:10,  1.36s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:  27%|██▋       | 3/11 [00:03<00:10,  1.36s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:  27%|██▋       | 3/11 [00:03<00:10,  1.36s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  27%|██▋       | 3/11 [00:03<00:10,  1.36s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:  36%|███▋      | 4/11 [00:05<00:09,  1.40s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:  36%|███▋      | 4/11 [00:05<00:09,  1.40s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  36%|███▋      | 4/11 [00:05<00:09,  1.40s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:  36%|███▋      | 4/11 [00:05<00:09,  1.40s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:  45%|████▌     | 5/11 [00:06<00:08,  1.43s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:  64%|██████▎   | 7/11 [00:09<00:05,  1.45s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  64%|██████▎   | 7/11 [00:09<00:05,  1.45s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:  64%|██████▎   | 7/11 [00:09<00:05,  1.46s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:  64%|██████▎   | 7/11 [00:09<00:05,  1.46s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:  82%|████████▏ | 9/11 [00:12<00:02,  1.47s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:  82%|████████▏ | 9/11 [00:12<00:02,  1.47s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  82%|████████▏ | 9/11 [00:12<00:02,  1.47s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:  82%|████████▏ | 9/11 [00:12<00:02,  1.47s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:  91%|█████████ | 10/11 [00:14<00:01,  1.48s/it, loss=35.7155, avg_loss=35.7155]Epoch 116:  91%|█████████ | 10/11 [00:14<00:01,  1.48s/it, loss=35.2899, avg_loss=35.2899]Epoch 116:  91%|█████████ | 10/11 [00:14<00:01,  1.48s/it, loss=35.7961, avg_loss=35.7961]Epoch 116:  91%|█████████ | 10/11 [00:14<00:01,  1.48s/it, loss=36.6300, avg_loss=36.6300]Epoch 116:  91%|█████████ | 10/11 [00:15<00:01,  1.48s/it, loss=31.1706, avg_loss=35.8591]Epoch 116: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=31.1706, avg_loss=35.8591]Epoch 116: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=31.1706, avg_loss=35.8591]
INFO:__main__:=== EPOCH 116 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.859111
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.026184
INFO:__main__:   • gene_density: 1.189453
INFO:__main__:   • operon_membership: 11.643474
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 116:  91%|█████████ | 10/11 [00:15<00:01,  1.48s/it, loss=35.2867, avg_loss=36.8776]Epoch 116: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=35.2867, avg_loss=36.8776]Epoch 116:  91%|█████████ | 10/11 [00:15<00:01,  1.48s/it, loss=37.9476, avg_loss=34.8928]Epoch 116: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=37.9476, avg_loss=34.8928]Epoch 116: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.2867, avg_loss=36.8776]
Epoch 116: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=37.9476, avg_loss=34.8928]
INFO:__main__:=== EPOCH 116 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.877568
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.509135
INFO:__main__:   • gene_density: 1.178741
INFO:__main__:   • operon_membership: 12.189692
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 116 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.892833
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.886493
INFO:__main__:   • gene_density: 1.166075
INFO:__main__:   • operon_membership: 11.840266
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 116:  91%|█████████ | 10/11 [00:15<00:01,  1.48s/it, loss=35.2883, avg_loss=35.5400]Epoch 116: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=35.2883, avg_loss=35.5400]Epoch 116: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.2883, avg_loss=35.5400]
INFO:__main__:=== EPOCH 116 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.539975
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.350597
INFO:__main__:   • gene_density: 1.194957
INFO:__main__:   • operon_membership: 10.994420
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 117/681
INFO:__main__:Epoch 117/681
INFO:__main__:Epoch 117/681
INFO:__main__:Epoch 117/681
Epoch 117:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 117:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 117:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 117:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 117:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9689, avg_loss=35.9689]Epoch 117:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.9230, avg_loss=37.9230]Epoch 117:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4400, avg_loss=35.4400]Epoch 117:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.2405, avg_loss=36.2405]Epoch 117:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  18%|█▊        | 2/11 [00:02<00:09,  1.07s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:  18%|█▊        | 2/11 [00:02<00:09,  1.07s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:  18%|█▊        | 2/11 [00:02<00:09,  1.07s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  18%|█▊        | 2/11 [00:02<00:09,  1.07s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:  27%|██▋       | 3/11 [00:03<00:09,  1.18s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:  27%|██▋       | 3/11 [00:03<00:09,  1.18s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  27%|██▋       | 3/11 [00:03<00:09,  1.18s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:  27%|██▋       | 3/11 [00:03<00:09,  1.19s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:  36%|███▋      | 4/11 [00:04<00:08,  1.28s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:  36%|███▋      | 4/11 [00:04<00:08,  1.28s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:  36%|███▋      | 4/11 [00:04<00:08,  1.28s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  36%|███▋      | 4/11 [00:05<00:09,  1.29s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:  64%|██████▎   | 7/11 [00:09<00:05,  1.39s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:  64%|██████▎   | 7/11 [00:09<00:05,  1.39s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:  64%|██████▎   | 7/11 [00:09<00:05,  1.39s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  64%|██████▎   | 7/11 [00:09<00:05,  1.39s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=36.2405, avg_loss=36.2405]Epoch 117:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=35.9689, avg_loss=35.9689]Epoch 117:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=37.9230, avg_loss=37.9230]Epoch 117:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=35.4400, avg_loss=35.4400]Epoch 117:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=34.2929, avg_loss=35.8567]Epoch 117: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=34.2929, avg_loss=35.8567]Epoch 117: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.2929, avg_loss=35.8567]
INFO:__main__:=== EPOCH 117 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.856676
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.480392
INFO:__main__:   • gene_density: 1.169212
INFO:__main__:   • operon_membership: 11.207072
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 117:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.1078, avg_loss=35.1671]Epoch 117: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=35.1078, avg_loss=35.1671]Epoch 117: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.1078, avg_loss=35.1671]
Epoch 117:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=32.6089, avg_loss=35.6746]Epoch 117: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=32.6089, avg_loss=35.6746]Epoch 117: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=32.6089, avg_loss=35.6746]
INFO:__main__:=== EPOCH 117 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.167146
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.047141
INFO:__main__:   • gene_density: 1.183239
INFO:__main__:   • operon_membership: 11.936766
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 117 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.674569
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.597369
INFO:__main__:   • gene_density: 1.186257
INFO:__main__:   • operon_membership: 11.890943
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 117:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.9372, avg_loss=36.3234]Epoch 117: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=35.9372, avg_loss=36.3234]Epoch 117: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.9372, avg_loss=36.3234]
INFO:__main__:=== EPOCH 117 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.323417
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.714015
INFO:__main__:   • gene_density: 1.194070
INFO:__main__:   • operon_membership: 11.415332
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 118/681
INFO:__main__:Epoch 118/681
INFO:__main__:Epoch 118/681
INFO:__main__:Epoch 118/681
Epoch 118:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 118:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 118:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 118:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 118:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.4153, avg_loss=33.4153]Epoch 118:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7692, avg_loss=36.7692]Epoch 118:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3494, avg_loss=35.3494]Epoch 118:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8108, avg_loss=35.8108]Epoch 118:   9%|▉         | 1/11 [00:01<00:15,  1.57s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  18%|█▊        | 2/11 [00:02<00:11,  1.32s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:  18%|█▊        | 2/11 [00:02<00:11,  1.32s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:  18%|█▊        | 2/11 [00:02<00:11,  1.32s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:  18%|█▊        | 2/11 [00:02<00:11,  1.33s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:  27%|██▋       | 3/11 [00:03<00:09,  1.25s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  36%|███▋      | 4/11 [00:04<00:07,  1.11s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:  36%|███▋      | 4/11 [00:04<00:07,  1.10s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  36%|███▋      | 4/11 [00:04<00:07,  1.11s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:  36%|███▋      | 4/11 [00:04<00:07,  1.11s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:  45%|████▌     | 5/11 [00:05<00:06,  1.08s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:  45%|████▌     | 5/11 [00:05<00:06,  1.08s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:  45%|████▌     | 5/11 [00:05<00:06,  1.08s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:  45%|████▌     | 5/11 [00:05<00:06,  1.09s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  55%|█████▍    | 6/11 [00:07<00:05,  1.19s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:  55%|█████▍    | 6/11 [00:07<00:05,  1.19s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:  55%|█████▍    | 6/11 [00:07<00:05,  1.19s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:  55%|█████▍    | 6/11 [00:07<00:05,  1.19s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  64%|██████▎   | 7/11 [00:08<00:05,  1.26s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:  64%|██████▎   | 7/11 [00:08<00:05,  1.26s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:  64%|██████▎   | 7/11 [00:08<00:05,  1.26s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:  64%|██████▎   | 7/11 [00:08<00:05,  1.27s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  73%|███████▎  | 8/11 [00:10<00:03,  1.31s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:  73%|███████▎  | 8/11 [00:10<00:03,  1.31s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:  73%|███████▎  | 8/11 [00:10<00:03,  1.31s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:  73%|███████▎  | 8/11 [00:10<00:03,  1.31s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=33.4153, avg_loss=33.4153]Epoch 118:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=35.3494, avg_loss=35.3494]Epoch 118:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=36.7692, avg_loss=36.7692]Epoch 118:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=35.8108, avg_loss=35.8108]Epoch 118:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=34.6928, avg_loss=35.3948]Epoch 118:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=36.5755, avg_loss=36.0422]Epoch 118: 100%|██████████| 11/11 [00:14<00:00,  1.41s/it, loss=34.6928, avg_loss=35.3948]Epoch 118:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=38.4287, avg_loss=35.9455]Epoch 118: 100%|██████████| 11/11 [00:14<00:00,  1.41s/it, loss=36.5755, avg_loss=36.0422]Epoch 118: 100%|██████████| 11/11 [00:14<00:00,  1.41s/it, loss=38.4287, avg_loss=35.9455]Epoch 118: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=34.6928, avg_loss=35.3948]
Epoch 118: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=36.5755, avg_loss=36.0422]
Epoch 118: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=38.4287, avg_loss=35.9455]
INFO:__main__:=== EPOCH 118 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 118 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.394833
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 36.042185
INFO:__main__:   • gene_expression: 22.880555
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.188743
INFO:__main__:   • gene_expression: 23.080665
INFO:__main__:   • operon_membership: 11.325536
INFO:__main__:   • gene_density: 1.175308
INFO:__main__:👥 Samples processed: 22
INFO:__main__:=== EPOCH 118 TRAINING LOSSES ===
INFO:__main__:   • operon_membership: 11.786213
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:🔢 Total Loss: 35.945469
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.337312
INFO:__main__:   • gene_density: 1.179924
INFO:__main__:   • operon_membership: 11.428232
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 118:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=32.0007, avg_loss=35.5617]Epoch 118: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=32.0007, avg_loss=35.5617]Epoch 118: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=32.0007, avg_loss=35.5617]
INFO:__main__:=== EPOCH 118 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.561735
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.405577
INFO:__main__:   • gene_density: 1.184482
INFO:__main__:   • operon_membership: 11.971676
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 119/681
INFO:__main__:Epoch 119/681
INFO:__main__:Epoch 119/681
INFO:__main__:Epoch 119/681
Epoch 119:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 119:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 119:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 119:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 119:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.4047, avg_loss=37.4047]Epoch 119:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5590, avg_loss=37.5590]Epoch 119:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.2543, avg_loss=39.2543]Epoch 119:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7039, avg_loss=36.7039]Epoch 119:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:  36%|███▋      | 4/11 [00:05<00:09,  1.38s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:  45%|████▌     | 5/11 [00:06<00:07,  1.29s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  55%|█████▍    | 6/11 [00:07<00:06,  1.24s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:  55%|█████▍    | 6/11 [00:08<00:06,  1.24s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:  55%|█████▍    | 6/11 [00:08<00:06,  1.24s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:  55%|█████▍    | 6/11 [00:08<00:06,  1.24s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  64%|██████▎   | 7/11 [00:08<00:04,  1.11s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:  64%|██████▎   | 7/11 [00:08<00:04,  1.11s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:  64%|██████▎   | 7/11 [00:08<00:04,  1.11s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:  64%|██████▎   | 7/11 [00:08<00:04,  1.11s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  73%|███████▎  | 8/11 [00:09<00:03,  1.11s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:  73%|███████▎  | 8/11 [00:09<00:03,  1.11s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:  73%|███████▎  | 8/11 [00:09<00:03,  1.11s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:  73%|███████▎  | 8/11 [00:09<00:03,  1.12s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  91%|█████████ | 10/11 [00:12<00:01,  1.27s/it, loss=37.4047, avg_loss=37.4047]Epoch 119:  91%|█████████ | 10/11 [00:12<00:01,  1.27s/it, loss=37.5590, avg_loss=37.5590]Epoch 119:  91%|█████████ | 10/11 [00:12<00:01,  1.27s/it, loss=39.2543, avg_loss=39.2543]Epoch 119:  91%|█████████ | 10/11 [00:12<00:01,  1.28s/it, loss=36.7039, avg_loss=36.7039]Epoch 119:  91%|█████████ | 10/11 [00:14<00:01,  1.27s/it, loss=40.9062, avg_loss=35.9255]Epoch 119: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=40.9062, avg_loss=35.9255]Epoch 119:  91%|█████████ | 10/11 [00:14<00:01,  1.27s/it, loss=36.1228, avg_loss=36.4442]Epoch 119:  91%|█████████ | 10/11 [00:14<00:01,  1.27s/it, loss=35.2691, avg_loss=35.5838]Epoch 119: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=36.1228, avg_loss=36.4442]Epoch 119: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=40.9062, avg_loss=35.9255]Epoch 119: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.2691, avg_loss=35.5838]
Epoch 119: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=36.1228, avg_loss=36.4442]Epoch 119: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=35.2691, avg_loss=35.5838]

INFO:__main__:=== EPOCH 119 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.925453
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.648404
INFO:__main__:   • gene_density: 1.183535
INFO:__main__:   • operon_membership: 12.093515
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 119 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 119 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.583797
INFO:__main__:🔢 Total Loss: 36.444232
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.211251
INFO:__main__:   • gene_density: 1.189512
INFO:__main__:   • gene_expression: 24.333802
INFO:__main__:   • operon_membership: 12.183034
INFO:__main__:   • gene_density: 1.173947
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 10.936483
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 119:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=35.7425, avg_loss=34.7995]Epoch 119: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.7425, avg_loss=34.7995]Epoch 119: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=35.7425, avg_loss=34.7995]
INFO:__main__:=== EPOCH 119 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.799536
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.222659
INFO:__main__:   • gene_density: 1.181937
INFO:__main__:   • operon_membership: 11.394940
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 120/681
INFO:__main__:Epoch 120/681
INFO:__main__:Epoch 120/681
INFO:__main__:Epoch 120/681
Epoch 120:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 120:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 120:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 120:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 120:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.2386, avg_loss=31.2386]Epoch 120:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0654, avg_loss=36.0654]Epoch 120:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4262, avg_loss=34.4262]Epoch 120:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8736, avg_loss=35.8736]Epoch 120:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  82%|████████▏ | 9/11 [00:12<00:02,  1.22s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:  82%|████████▏ | 9/11 [00:12<00:02,  1.22s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  82%|████████▏ | 9/11 [00:12<00:02,  1.22s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:  82%|████████▏ | 9/11 [00:12<00:02,  1.22s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:  91%|█████████ | 10/11 [00:12<00:01,  1.10s/it, loss=34.4262, avg_loss=34.4262]Epoch 120:  91%|█████████ | 10/11 [00:12<00:01,  1.10s/it, loss=35.8736, avg_loss=35.8736]Epoch 120:  91%|█████████ | 10/11 [00:12<00:01,  1.10s/it, loss=36.0654, avg_loss=36.0654]Epoch 120:  91%|█████████ | 10/11 [00:12<00:01,  1.10s/it, loss=31.2386, avg_loss=31.2386]Epoch 120:  91%|█████████ | 10/11 [00:14<00:01,  1.10s/it, loss=36.7265, avg_loss=36.6179]Epoch 120: 100%|██████████| 11/11 [00:14<00:00,  1.23s/it, loss=36.7265, avg_loss=36.6179]Epoch 120: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.7265, avg_loss=36.6179]
INFO:__main__:=== EPOCH 120 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.617854
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.448474
INFO:__main__:   • gene_density: 1.193774
INFO:__main__:   • operon_membership: 11.975606
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 120:  91%|█████████ | 10/11 [00:14<00:01,  1.10s/it, loss=37.1327, avg_loss=35.9441]Epoch 120: 100%|██████████| 11/11 [00:14<00:00,  1.24s/it, loss=37.1327, avg_loss=35.9441]Epoch 120: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=37.1327, avg_loss=35.9441]
INFO:__main__:=== EPOCH 120 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.944073
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.687841
INFO:__main__:   • gene_density: 1.180102
INFO:__main__:   • operon_membership: 12.076130
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 120:  91%|█████████ | 10/11 [00:14<00:01,  1.10s/it, loss=34.0672, avg_loss=34.9300]Epoch 120: 100%|██████████| 11/11 [00:14<00:00,  1.24s/it, loss=34.0672, avg_loss=34.9300]Epoch 120: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=34.0672, avg_loss=34.9300]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 120 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.929960
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.457974
INFO:__main__:   • gene_density: 1.180575
INFO:__main__:   • operon_membership: 11.291412
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 120:  91%|█████████ | 10/11 [00:14<00:01,  1.10s/it, loss=35.9104, avg_loss=35.5725]Epoch 120: 100%|██████████| 11/11 [00:14<00:00,  1.24s/it, loss=35.9104, avg_loss=35.5725]Epoch 120: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.9104, avg_loss=35.5725]
INFO:__main__:=== EPOCH 120 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.572498
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.038113
INFO:__main__:   • gene_density: 1.177083
INFO:__main__:   • operon_membership: 11.357302
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.30it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.28it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.30it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.27it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.63it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.63it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]

INFO:__main__:=== EPOCH 120 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 120 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:=== EPOCH 120 VALIDATION LOSSES ===
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]
INFO:__main__:=== EPOCH 120 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_120.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_120.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_120.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_120.pt
INFO:__main__:Epoch 121/681
INFO:__main__:Epoch 121/681
INFO:__main__:Epoch 121/681
INFO:__main__:Epoch 121/681
Epoch 121:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 121:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 121:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 121:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 121:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1416, avg_loss=34.1416]Epoch 121:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3103, avg_loss=35.3103]Epoch 121:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0223, avg_loss=34.0223]Epoch 121:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4679, avg_loss=35.4679]Epoch 121:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  27%|██▋       | 3/11 [00:04<00:10,  1.32s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:  27%|██▋       | 3/11 [00:04<00:10,  1.32s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:  27%|██▋       | 3/11 [00:04<00:10,  1.32s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:  27%|██▋       | 3/11 [00:04<00:10,  1.32s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  36%|███▋      | 4/11 [00:05<00:08,  1.18s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:  36%|███▋      | 4/11 [00:05<00:08,  1.18s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  36%|███▋      | 4/11 [00:05<00:08,  1.19s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:  36%|███▋      | 4/11 [00:05<00:08,  1.19s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:  45%|████▌     | 5/11 [00:06<00:06,  1.08s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:  45%|████▌     | 5/11 [00:06<00:06,  1.08s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:  45%|████▌     | 5/11 [00:06<00:06,  1.08s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:  45%|████▌     | 5/11 [00:06<00:06,  1.09s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  73%|███████▎  | 8/11 [00:10<00:04,  1.34s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:  73%|███████▎  | 8/11 [00:10<00:04,  1.34s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:  73%|███████▎  | 8/11 [00:10<00:04,  1.34s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:  73%|███████▎  | 8/11 [00:10<00:04,  1.34s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  82%|████████▏ | 9/11 [00:11<00:02,  1.37s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:  82%|████████▏ | 9/11 [00:11<00:02,  1.37s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:  82%|████████▏ | 9/11 [00:11<00:02,  1.37s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:  82%|████████▏ | 9/11 [00:11<00:02,  1.37s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=34.1416, avg_loss=34.1416]Epoch 121:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=34.0223, avg_loss=34.0223]Epoch 121:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=35.3103, avg_loss=35.3103]Epoch 121:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=35.4679, avg_loss=35.4679]Epoch 121:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=34.6392, avg_loss=35.5718]Epoch 121: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=34.6392, avg_loss=35.5718]Epoch 121:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=35.5325, avg_loss=35.2151]Epoch 121: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=35.5325, avg_loss=35.2151]Epoch 121: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.6392, avg_loss=35.5718]
Epoch 121: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.5325, avg_loss=35.2151]
INFO:__main__:=== EPOCH 121 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.571753
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.784595
INFO:__main__:   • gene_density: 1.183357
INFO:__main__:=== EPOCH 121 TRAINING LOSSES ===
INFO:__main__:   • operon_membership: 11.603801
INFO:__main__:👥 Samples processed: 22
INFO:__main__:🔢 Total Loss: 35.215125
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.672926
INFO:__main__:   • gene_density: 1.173059
INFO:__main__:   • operon_membership: 11.369139
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 121:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=37.4025, avg_loss=36.1832]Epoch 121: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=37.4025, avg_loss=36.1832]Epoch 121: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=37.4025, avg_loss=36.1832]
INFO:__main__:=== EPOCH 121 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.183227
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.180716
INFO:__main__:   • gene_density: 1.183475
INFO:__main__:   • operon_membership: 10.819037
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 121:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=41.1626, avg_loss=36.4327]Epoch 121: 100%|██████████| 11/11 [00:14<00:00,  1.46s/it, loss=41.1626, avg_loss=36.4327]Epoch 121: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=41.1626, avg_loss=36.4327]
INFO:__main__:=== EPOCH 121 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.432719
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.352123
INFO:__main__:   • gene_density: 1.194780
INFO:__main__:   • operon_membership: 12.885817
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 122/681
INFO:__main__:Epoch 122/681
INFO:__main__:Epoch 122/681
INFO:__main__:Epoch 122/681
Epoch 122:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 122:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 122:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 122:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 122:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.6091, avg_loss=35.6091]Epoch 122:   9%|▉         | 1/11 [00:01<00:16,  1.62s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0348, avg_loss=33.0348]Epoch 122:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5425, avg_loss=36.5425]Epoch 122:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4171, avg_loss=34.4171]Epoch 122:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  55%|█████▍    | 6/11 [00:07<00:05,  1.19s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  55%|█████▍    | 6/11 [00:07<00:05,  1.19s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:  55%|█████▍    | 6/11 [00:07<00:05,  1.19s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:  55%|█████▍    | 6/11 [00:07<00:05,  1.19s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:  64%|██████▎   | 7/11 [00:08<00:04,  1.07s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:  73%|███████▎  | 8/11 [00:10<00:03,  1.17s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:  73%|███████▎  | 8/11 [00:10<00:03,  1.17s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:  73%|███████▎  | 8/11 [00:10<00:03,  1.17s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:  73%|███████▎  | 8/11 [00:10<00:03,  1.17s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  82%|████████▏ | 9/11 [00:11<00:02,  1.26s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:  82%|████████▏ | 9/11 [00:11<00:02,  1.27s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:  82%|████████▏ | 9/11 [00:11<00:02,  1.27s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:  82%|████████▏ | 9/11 [00:11<00:02,  1.27s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  91%|█████████ | 10/11 [00:12<00:01,  1.31s/it, loss=33.0348, avg_loss=33.0348]Epoch 122:  91%|█████████ | 10/11 [00:12<00:01,  1.31s/it, loss=35.6091, avg_loss=35.6091]Epoch 122:  91%|█████████ | 10/11 [00:12<00:01,  1.31s/it, loss=36.5425, avg_loss=36.5425]Epoch 122:  91%|█████████ | 10/11 [00:12<00:01,  1.31s/it, loss=34.4171, avg_loss=34.4171]Epoch 122:  91%|█████████ | 10/11 [00:14<00:01,  1.31s/it, loss=36.7729, avg_loss=36.0984]Epoch 122: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=36.7729, avg_loss=36.0984]Epoch 122: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.7729, avg_loss=36.0984]
INFO:__main__:=== EPOCH 122 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.098445
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.100366
INFO:__main__:   • gene_density: 1.193833
INFO:__main__:   • operon_membership: 11.804246
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 122:  91%|█████████ | 10/11 [00:14<00:01,  1.31s/it, loss=33.9112, avg_loss=34.9386]Epoch 122: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=33.9112, avg_loss=34.9386]Epoch 122:  91%|█████████ | 10/11 [00:14<00:01,  1.31s/it, loss=35.2117, avg_loss=35.8095]Epoch 122: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=35.2117, avg_loss=35.8095]Epoch 122: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=33.9112, avg_loss=34.9386]
Epoch 122: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.2117, avg_loss=35.8095]
INFO:__main__:=== EPOCH 122 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.938643
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.446368
INFO:__main__:   • gene_density: 1.171224
INFO:__main__:   • operon_membership: 11.321051
INFO:__main__:👥 Samples processed: 22
INFO:__main__:=== EPOCH 122 TRAINING LOSSES ===
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 35.809475
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.304637
INFO:__main__:   • gene_density: 1.184896
INFO:__main__:   • operon_membership: 11.319941
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 122:  91%|█████████ | 10/11 [00:14<00:01,  1.31s/it, loss=36.8769, avg_loss=36.1842]Epoch 122: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=36.8769, avg_loss=36.1842]Epoch 122: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.8769, avg_loss=36.1842]
INFO:__main__:=== EPOCH 122 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.184245
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.864113
INFO:__main__:   • gene_density: 1.184955
INFO:__main__:   • operon_membership: 12.135177
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 123/681
INFO:__main__:Epoch 123/681
INFO:__main__:Epoch 123/681
INFO:__main__:Epoch 123/681
Epoch 123:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 123:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 123:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 123:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 123:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7393, avg_loss=37.7393]Epoch 123:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1546, avg_loss=36.1546]Epoch 123:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1141, avg_loss=37.1141]Epoch 123:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0017, avg_loss=33.0017]Epoch 123:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:  55%|█████▍    | 6/11 [00:08<00:06,  1.38s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  64%|██████▎   | 7/11 [00:09<00:05,  1.30s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:  64%|██████▎   | 7/11 [00:09<00:05,  1.30s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:  64%|██████▎   | 7/11 [00:09<00:05,  1.31s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:  64%|██████▎   | 7/11 [00:09<00:05,  1.31s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:  91%|█████████ | 10/11 [00:13<00:01,  1.16s/it, loss=37.7393, avg_loss=37.7393]Epoch 123:  91%|█████████ | 10/11 [00:13<00:01,  1.16s/it, loss=36.1546, avg_loss=36.1546]Epoch 123:  91%|█████████ | 10/11 [00:13<00:01,  1.16s/it, loss=37.1141, avg_loss=37.1141]Epoch 123:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=33.0017, avg_loss=33.0017]Epoch 123:  91%|█████████ | 10/11 [00:14<00:01,  1.16s/it, loss=36.3271, avg_loss=36.7046]Epoch 123: 100%|██████████| 11/11 [00:14<00:00,  1.30s/it, loss=36.3271, avg_loss=36.7046]Epoch 123: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=36.3271, avg_loss=36.7046]
Epoch 123:  91%|█████████ | 10/11 [00:14<00:01,  1.16s/it, loss=36.5118, avg_loss=35.6546]Epoch 123: 100%|██████████| 11/11 [00:14<00:00,  1.30s/it, loss=36.5118, avg_loss=35.6546]INFO:__main__:=== EPOCH 123 TRAINING LOSSES ===
Epoch 123: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=36.5118, avg_loss=35.6546]
INFO:__main__:🔢 Total Loss: 36.704598
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.851662
INFO:__main__:   • gene_density: 1.192353
INFO:__main__:   • operon_membership: 11.660582
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 123 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.654643
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.907744
INFO:__main__:   • gene_density: 1.181522
INFO:__main__:   • operon_membership: 11.565376
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 123:  91%|█████████ | 10/11 [00:14<00:01,  1.16s/it, loss=35.3559, avg_loss=35.8890]Epoch 123: 100%|██████████| 11/11 [00:14<00:00,  1.30s/it, loss=35.3559, avg_loss=35.8890]Epoch 123: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=35.3559, avg_loss=35.8890]
INFO:__main__:=== EPOCH 123 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.888970
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.376111
INFO:__main__:   • gene_density: 1.188565
INFO:__main__:   • operon_membership: 12.324293
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 123:  91%|█████████ | 10/11 [00:14<00:01,  1.17s/it, loss=37.8894, avg_loss=35.0261]Epoch 123: 100%|██████████| 11/11 [00:14<00:00,  1.30s/it, loss=37.8894, avg_loss=35.0261]Epoch 123: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=37.8894, avg_loss=35.0261]
INFO:__main__:=== EPOCH 123 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.026118
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.687311
INFO:__main__:   • gene_density: 1.168679
INFO:__main__:   • operon_membership: 11.170128
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 124/681
INFO:__main__:Epoch 124/681
INFO:__main__:Epoch 124/681
INFO:__main__:Epoch 124/681
Epoch 124:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 124:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 124:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 124:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 124:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.4273, avg_loss=37.4273]Epoch 124:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3568, avg_loss=34.3568]Epoch 124:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.0571, avg_loss=32.0571]Epoch 124:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.2779, avg_loss=37.2779]Epoch 124:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:  55%|█████▍    | 6/11 [00:09<00:07,  1.46s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:  73%|███████▎  | 8/11 [00:11<00:04,  1.38s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  91%|█████████ | 10/11 [00:13<00:01,  1.24s/it, loss=37.4273, avg_loss=37.4273]Epoch 124:  91%|█████████ | 10/11 [00:13<00:01,  1.24s/it, loss=32.0571, avg_loss=32.0571]Epoch 124:  91%|█████████ | 10/11 [00:13<00:01,  1.24s/it, loss=37.2779, avg_loss=37.2779]Epoch 124:  91%|█████████ | 10/11 [00:13<00:01,  1.24s/it, loss=34.3568, avg_loss=34.3568]Epoch 124:  91%|█████████ | 10/11 [00:14<00:01,  1.24s/it, loss=37.2165, avg_loss=36.2295]Epoch 124:  91%|█████████ | 10/11 [00:14<00:01,  1.24s/it, loss=35.2280, avg_loss=36.3426]Epoch 124: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=37.2165, avg_loss=36.2295]Epoch 124: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=35.2280, avg_loss=36.3426]Epoch 124:  91%|█████████ | 10/11 [00:14<00:01,  1.24s/it, loss=35.1386, avg_loss=35.3704]Epoch 124: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=35.1386, avg_loss=35.3704]Epoch 124: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=37.2165, avg_loss=36.2295]Epoch 124: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.2280, avg_loss=36.3426]

Epoch 124: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.1386, avg_loss=35.3704]
Epoch 124:  91%|█████████ | 10/11 [00:14<00:01,  1.24s/it, loss=36.4582, avg_loss=34.9238]Epoch 124: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=36.4582, avg_loss=34.9238]INFO:__main__:=== EPOCH 124 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 124 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.342645
INFO:__main__:🔢 Total Loss: 36.229481
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.227802
INFO:__main__:   • gene_expression: 22.750206
INFO:__main__:   • gene_density: 1.169153
INFO:__main__:   • gene_density: 1.191465
INFO:__main__:   • operon_membership: 11.945690
INFO:__main__:   • operon_membership: 12.287811
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:=== EPOCH 124 TRAINING LOSSES ===
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 35.370379
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.950500
INFO:__main__:   • gene_density: 1.179747
INFO:__main__:   • operon_membership: 11.240133
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 124: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=36.4582, avg_loss=34.9238]
INFO:__main__:=== EPOCH 124 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.923804
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.439110
INFO:__main__:   • gene_density: 1.191525
INFO:__main__:   • operon_membership: 11.293169
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 125/681
INFO:__main__:Epoch 125/681
INFO:__main__:Epoch 125/681
INFO:__main__:Epoch 125/681
Epoch 125:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 125:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 125:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 125:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 125:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5607, avg_loss=37.5607]Epoch 125:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6843, avg_loss=37.6843]Epoch 125:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8707, avg_loss=33.8707]Epoch 125:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6016, avg_loss=37.6016]Epoch 125:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=37.6843, avg_loss=37.6843]Epoch 125:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=37.5607, avg_loss=37.5607]Epoch 125:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=33.8707, avg_loss=33.8707]Epoch 125:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=37.6016, avg_loss=37.6016]Epoch 125:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=34.0345, avg_loss=35.3055]Epoch 125: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=34.0345, avg_loss=35.3055]Epoch 125: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=34.0345, avg_loss=35.3055]
INFO:__main__:=== EPOCH 125 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.305532
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.607695
INFO:__main__:   • gene_density: 1.190814
INFO:__main__:   • operon_membership: 11.507023
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 125:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=35.6982, avg_loss=36.7642]Epoch 125: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=35.6982, avg_loss=36.7642]Epoch 125: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=35.6982, avg_loss=36.7642]
Epoch 125:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=34.0626, avg_loss=34.7800]Epoch 125: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=34.0626, avg_loss=34.7800]INFO:__main__:=== EPOCH 125 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.764238
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.652507
INFO:__main__:   • gene_density: 1.177971
INFO:__main__:   • operon_membership: 11.933760
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 125: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=34.0626, avg_loss=34.7800]
Epoch 125:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=35.2896, avg_loss=36.1607]Epoch 125: 100%|██████████| 11/11 [00:15<00:00,  1.35s/it, loss=35.2896, avg_loss=36.1607]Epoch 125: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=35.2896, avg_loss=36.1607]
INFO:__main__:=== EPOCH 125 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.779994
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.947963
INFO:__main__:   • gene_density: 1.183061
INFO:__main__:   • operon_membership: 10.648970
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 125 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.160743
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.281794
INFO:__main__:   • gene_density: 1.174065
INFO:__main__:   • operon_membership: 12.704884
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.39it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.37it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.39it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.38it/s]Validation:  50%|█████     | 2/4 [00:01<00:00,  2.01it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.99it/s]Validation:  50%|█████     | 2/4 [00:01<00:00,  2.00it/s]Validation:  50%|█████     | 2/4 [00:01<00:00,  2.01it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.35it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.34it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.35it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]Validation: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.07it/s]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.07it/s]
INFO:__main__:=== EPOCH 125 VALIDATION LOSSES ===
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:=== EPOCH 125 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 125 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 125 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 126/681
INFO:__main__:Epoch 126/681
INFO:__main__:Epoch 126/681
INFO:__main__:Epoch 126/681
Epoch 126:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 126:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 126:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 126:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 126:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0616, avg_loss=35.0616]Epoch 126:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.6658, avg_loss=35.6658]Epoch 126:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7648, avg_loss=37.7648]Epoch 126:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.4544, avg_loss=31.4544]Epoch 126:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=35.6658, avg_loss=35.6658]Epoch 126:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=35.0616, avg_loss=35.0616]Epoch 126:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=37.7648, avg_loss=37.7648]Epoch 126:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=31.4544, avg_loss=31.4544]Epoch 126:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=37.4837, avg_loss=35.2638]Epoch 126:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=33.9607, avg_loss=35.9247]Epoch 126: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.4837, avg_loss=35.2638]Epoch 126: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.9607, avg_loss=35.9247]Epoch 126: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=37.4837, avg_loss=35.2638]
Epoch 126: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=33.9607, avg_loss=35.9247]
INFO:__main__:=== EPOCH 126 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.263775
INFO:__main__:=== EPOCH 126 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.093823
INFO:__main__:🔢 Total Loss: 35.924702
INFO:__main__:   • gene_density: 1.176728
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • operon_membership: 11.993224
INFO:__main__:   • gene_expression: 23.757169
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_density: 1.171402
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 10.996131
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 126:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=36.1937, avg_loss=35.6683]Epoch 126: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=36.1937, avg_loss=35.6683]Epoch 126: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=36.1937, avg_loss=35.6683]
INFO:__main__:=== EPOCH 126 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.668261
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.919606
INFO:__main__:   • gene_density: 1.200758
INFO:__main__:   • operon_membership: 11.547898
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 126:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=35.7334, avg_loss=36.2082]Epoch 126: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.7334, avg_loss=36.2082]Epoch 126: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=35.7334, avg_loss=36.2082]
INFO:__main__:=== EPOCH 126 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.208189
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.926092
INFO:__main__:   • gene_density: 1.183357
INFO:__main__:   • operon_membership: 12.098740
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 127/681
INFO:__main__:Epoch 127/681
INFO:__main__:Epoch 127/681
INFO:__main__:Epoch 127/681
Epoch 127:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 127:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 127:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 127:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 127:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7841, avg_loss=37.7841]Epoch 127:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.4705, avg_loss=37.4705]Epoch 127:   9%|▉         | 1/11 [00:01<00:12,  1.28s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:   9%|▉         | 1/11 [00:01<00:12,  1.28s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0457, avg_loss=34.0457]Epoch 127:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6105, avg_loss=36.6105]Epoch 127:   9%|▉         | 1/11 [00:01<00:12,  1.29s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  27%|██▋       | 3/11 [00:03<00:09,  1.19s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:  27%|██▋       | 3/11 [00:03<00:09,  1.19s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:  27%|██▋       | 3/11 [00:03<00:09,  1.20s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  27%|██▋       | 3/11 [00:03<00:09,  1.20s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:  36%|███▋      | 4/11 [00:04<00:09,  1.29s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:  36%|███▋      | 4/11 [00:04<00:09,  1.29s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:  36%|███▋      | 4/11 [00:04<00:09,  1.29s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  36%|███▋      | 4/11 [00:04<00:09,  1.30s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  45%|████▌     | 5/11 [00:06<00:08,  1.37s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  55%|█████▍    | 6/11 [00:07<00:06,  1.40s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  73%|███████▎  | 8/11 [00:10<00:04,  1.41s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=37.4705, avg_loss=37.4705]Epoch 127:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=34.0457, avg_loss=34.0457]Epoch 127:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=36.6105, avg_loss=36.6105]Epoch 127:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=37.7841, avg_loss=37.7841]Epoch 127:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=39.4974, avg_loss=35.9707]Epoch 127: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=39.4974, avg_loss=35.9707]Epoch 127:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=36.3599, avg_loss=35.8443]Epoch 127: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=36.3599, avg_loss=35.8443]Epoch 127: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=39.4974, avg_loss=35.9707]
Epoch 127: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.3599, avg_loss=35.8443]
INFO:__main__:=== EPOCH 127 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.970680
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.977169
INFO:__main__:=== EPOCH 127 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.183949
INFO:__main__:   • operon_membership: 11.809563
INFO:__main__:🔢 Total Loss: 35.844279
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.454151
INFO:__main__:   • gene_density: 1.193182
INFO:__main__:   • operon_membership: 11.196946
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 127:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.0421, avg_loss=35.5021]Epoch 127: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=35.0421, avg_loss=35.5021]Epoch 127: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.0421, avg_loss=35.5021]
INFO:__main__:=== EPOCH 127 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.502087
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.084500
INFO:__main__:   • gene_density: 1.180871
INFO:__main__:   • operon_membership: 12.236717
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 127:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=32.5186, avg_loss=35.8348]Epoch 127: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=32.5186, avg_loss=35.8348]Epoch 127: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=32.5186, avg_loss=35.8348]
INFO:__main__:=== EPOCH 127 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.834764
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.250483
INFO:__main__:   • gene_density: 1.176255
INFO:__main__:   • operon_membership: 11.408026
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 128/681
INFO:__main__:Epoch 128/681
INFO:__main__:Epoch 128/681
INFO:__main__:Epoch 128/681
Epoch 128:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 128:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 128:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 128:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 128:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4301, avg_loss=34.4301]Epoch 128:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.0110, avg_loss=39.0110]Epoch 128:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0854, avg_loss=35.0854]Epoch 128:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0884, avg_loss=36.0884]Epoch 128:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  18%|█▊        | 2/11 [00:02<00:11,  1.26s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:  18%|█▊        | 2/11 [00:02<00:11,  1.27s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:  27%|██▋       | 3/11 [00:03<00:09,  1.19s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:  27%|██▋       | 3/11 [00:03<00:09,  1.20s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:  27%|██▋       | 3/11 [00:03<00:09,  1.20s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  27%|██▋       | 3/11 [00:03<00:09,  1.20s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:  36%|███▋      | 4/11 [00:04<00:07,  1.05s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:  36%|███▋      | 4/11 [00:04<00:07,  1.05s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:  36%|███▋      | 4/11 [00:04<00:07,  1.05s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:  36%|███▋      | 4/11 [00:04<00:07,  1.06s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  45%|████▌     | 5/11 [00:05<00:06,  1.11s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:  45%|████▌     | 5/11 [00:05<00:06,  1.11s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:  45%|████▌     | 5/11 [00:05<00:06,  1.11s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  45%|████▌     | 5/11 [00:05<00:06,  1.12s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:  55%|█████▍    | 6/11 [00:07<00:06,  1.24s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:  55%|█████▍    | 6/11 [00:07<00:06,  1.24s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:  55%|█████▍    | 6/11 [00:07<00:06,  1.24s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  55%|█████▍    | 6/11 [00:07<00:06,  1.24s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:  64%|██████▎   | 7/11 [00:08<00:05,  1.32s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:  64%|██████▎   | 7/11 [00:08<00:05,  1.32s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:  64%|██████▎   | 7/11 [00:08<00:05,  1.32s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  64%|██████▎   | 7/11 [00:08<00:05,  1.32s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=34.4301, avg_loss=34.4301]Epoch 128:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=39.0110, avg_loss=39.0110]Epoch 128:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=36.0884, avg_loss=36.0884]Epoch 128:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=35.0854, avg_loss=35.0854]Epoch 128:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=39.7982, avg_loss=36.4355]Epoch 128: 100%|██████████| 11/11 [00:14<00:00,  1.48s/it, loss=39.7982, avg_loss=36.4355]Epoch 128: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=39.7982, avg_loss=36.4355]
Epoch 128:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=33.4879, avg_loss=35.6495]Epoch 128: 100%|██████████| 11/11 [00:14<00:00,  1.48s/it, loss=33.4879, avg_loss=35.6495]Epoch 128: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=33.4879, avg_loss=35.6495]
Epoch 128:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=37.5670, avg_loss=35.5240]Epoch 128: 100%|██████████| 11/11 [00:14<00:00,  1.48s/it, loss=37.5670, avg_loss=35.5240]INFO:__main__:=== EPOCH 128 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.435474
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.085805
INFO:__main__:   • gene_density: 1.170751
INFO:__main__:   • operon_membership: 12.178918
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 128: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=37.5670, avg_loss=35.5240]
INFO:__main__:=== EPOCH 128 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.649489
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.630726
INFO:__main__:   • gene_density: 1.192235
INFO:__main__:   • operon_membership: 10.826527
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 128 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.523998
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.671356
INFO:__main__:   • gene_density: 1.196082
INFO:__main__:   • operon_membership: 11.656559
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 128:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=33.7181, avg_loss=35.6210]Epoch 128: 100%|██████████| 11/11 [00:14<00:00,  1.49s/it, loss=33.7181, avg_loss=35.6210]Epoch 128: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=33.7181, avg_loss=35.6210]
INFO:__main__:=== EPOCH 128 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.620983
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.430614
INFO:__main__:   • gene_density: 1.172408
INFO:__main__:   • operon_membership: 12.017961
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 129/681
INFO:__main__:Epoch 129/681
INFO:__main__:Epoch 129/681
INFO:__main__:Epoch 129/681
Epoch 129:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 129:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 129:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 129:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 129:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4960, avg_loss=36.4960]Epoch 129:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.6091, avg_loss=35.6091]Epoch 129:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.3236, avg_loss=33.3236]Epoch 129:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.5940, avg_loss=39.5940]Epoch 129:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  27%|██▋       | 3/11 [00:04<00:11,  1.38s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:  27%|██▋       | 3/11 [00:04<00:11,  1.38s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:  27%|██▋       | 3/11 [00:04<00:11,  1.38s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:  27%|██▋       | 3/11 [00:04<00:11,  1.39s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  36%|███▋      | 4/11 [00:05<00:09,  1.29s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:  36%|███▋      | 4/11 [00:05<00:09,  1.29s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:  36%|███▋      | 4/11 [00:05<00:09,  1.29s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:  36%|███▋      | 4/11 [00:05<00:09,  1.29s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  45%|████▌     | 5/11 [00:06<00:07,  1.22s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:  45%|████▌     | 5/11 [00:06<00:07,  1.22s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:  45%|████▌     | 5/11 [00:06<00:07,  1.21s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  45%|████▌     | 5/11 [00:06<00:07,  1.22s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:  55%|█████▍    | 6/11 [00:07<00:05,  1.08s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  55%|█████▍    | 6/11 [00:07<00:05,  1.09s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:  55%|█████▍    | 6/11 [00:07<00:05,  1.09s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:  55%|█████▍    | 6/11 [00:07<00:05,  1.09s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:  64%|██████▎   | 7/11 [00:08<00:04,  1.14s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:  64%|██████▎   | 7/11 [00:08<00:04,  1.14s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:  64%|██████▎   | 7/11 [00:08<00:04,  1.14s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:  64%|██████▎   | 7/11 [00:08<00:04,  1.15s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  73%|███████▎  | 8/11 [00:10<00:03,  1.23s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:  73%|███████▎  | 8/11 [00:10<00:03,  1.24s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:  73%|███████▎  | 8/11 [00:10<00:03,  1.24s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:  73%|███████▎  | 8/11 [00:10<00:03,  1.24s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:  82%|████████▏ | 9/11 [00:11<00:02,  1.30s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=35.6091, avg_loss=35.6091]Epoch 129:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=33.3236, avg_loss=33.3236]Epoch 129:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=36.4960, avg_loss=36.4960]Epoch 129:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=39.5940, avg_loss=39.5940]Epoch 129:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=35.0221, avg_loss=35.8258]Epoch 129: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=35.0221, avg_loss=35.8258]Epoch 129: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.0221, avg_loss=35.8258]
INFO:__main__:=== EPOCH 129 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.825813
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.475417
INFO:__main__:   • gene_density: 1.181286
INFO:__main__:   • operon_membership: 11.169110
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 129:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=35.6976, avg_loss=36.1607]Epoch 129: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=35.6976, avg_loss=36.1607]Epoch 129: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.6976, avg_loss=36.1607]
Epoch 129:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=33.8633, avg_loss=35.3580]Epoch 129: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=33.8633, avg_loss=35.3580]INFO:__main__:=== EPOCH 129 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.160717
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.212300
INFO:__main__:   • gene_density: 1.181996
INFO:__main__:   • operon_membership: 11.766422
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 129: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=33.8633, avg_loss=35.3580]
INFO:__main__:=== EPOCH 129 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.357982
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.356670
INFO:__main__:   • gene_density: 1.176906
INFO:__main__:   • operon_membership: 11.824406
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 129:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=32.4550, avg_loss=35.7738]Epoch 129: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=32.4550, avg_loss=35.7738]Epoch 129: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=32.4550, avg_loss=35.7738]
INFO:__main__:=== EPOCH 129 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.773786
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.691538
INFO:__main__:   • gene_density: 1.191998
INFO:__main__:   • operon_membership: 11.890250
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 130/681
INFO:__main__:Epoch 130/681
INFO:__main__:Epoch 130/681
INFO:__main__:Epoch 130/681
Epoch 130:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 130:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 130:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 130:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 130:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9532, avg_loss=35.9532]Epoch 130:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5405, avg_loss=36.5405]Epoch 130:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3773, avg_loss=34.3773]Epoch 130:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.2178, avg_loss=32.2178]Epoch 130:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:  55%|█████▍    | 6/11 [00:08<00:06,  1.32s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:  55%|█████▍    | 6/11 [00:08<00:06,  1.32s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:  55%|█████▍    | 6/11 [00:08<00:06,  1.32s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:  55%|█████▍    | 6/11 [00:08<00:06,  1.32s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  64%|██████▎   | 7/11 [00:09<00:05,  1.26s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:  64%|██████▎   | 7/11 [00:09<00:05,  1.26s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:  64%|██████▎   | 7/11 [00:09<00:05,  1.26s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:  64%|██████▎   | 7/11 [00:09<00:05,  1.26s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  73%|███████▎  | 8/11 [00:10<00:03,  1.13s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  73%|███████▎  | 8/11 [00:10<00:03,  1.13s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:  73%|███████▎  | 8/11 [00:10<00:03,  1.13s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:  73%|███████▎  | 8/11 [00:10<00:03,  1.13s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:  82%|████████▏ | 9/11 [00:11<00:02,  1.15s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  91%|█████████ | 10/11 [00:13<00:01,  1.25s/it, loss=35.9532, avg_loss=35.9532]Epoch 130:  91%|█████████ | 10/11 [00:13<00:01,  1.25s/it, loss=36.5405, avg_loss=36.5405]Epoch 130:  91%|█████████ | 10/11 [00:13<00:01,  1.25s/it, loss=34.3773, avg_loss=34.3773]Epoch 130:  91%|█████████ | 10/11 [00:13<00:01,  1.25s/it, loss=32.2178, avg_loss=32.2178]Epoch 130:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=32.9205, avg_loss=35.1539]Epoch 130: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=32.9205, avg_loss=35.1539]Epoch 130:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=37.4819, avg_loss=36.2819]Epoch 130: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=37.4819, avg_loss=36.2819]Epoch 130: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=32.9205, avg_loss=35.1539]
Epoch 130: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=37.4819, avg_loss=36.2819]
Epoch 130:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=37.7102, avg_loss=36.1486]Epoch 130: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=37.7102, avg_loss=36.1486]INFO:__main__:=== EPOCH 130 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.153917
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.849838
INFO:__main__:   • gene_density: 1.195490
INFO:__main__:   • operon_membership: 12.108589
INFO:__main__:=== EPOCH 130 TRAINING LOSSES ===
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 36.281899
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.373953
INFO:__main__:   • gene_density: 1.181937
INFO:__main__:   • operon_membership: 11.726010
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 130: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=37.7102, avg_loss=36.1486]
INFO:__main__:=== EPOCH 130 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.148566
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.813016
INFO:__main__:   • gene_density: 1.185073
INFO:__main__:   • operon_membership: 11.150476
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 130:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=35.7806, avg_loss=35.4374]Epoch 130: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=35.7806, avg_loss=35.4374]Epoch 130: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=35.7806, avg_loss=35.4374]
INFO:__main__:=== EPOCH 130 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.437425
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.802110
INFO:__main__:   • gene_density: 1.170277
INFO:__main__:   • operon_membership: 11.465038
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.18it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.53it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.53it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.53it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.53it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.44it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.44it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.44it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]
INFO:__main__:=== EPOCH 130 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]

INFO:__main__:=== EPOCH 130 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 130 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.44it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]
INFO:__main__:=== EPOCH 130 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_130.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_130.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_130.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_130.pt
INFO:__main__:Epoch 131/681
INFO:__main__:Epoch 131/681
INFO:__main__:Epoch 131/681
INFO:__main__:Epoch 131/681
Epoch 131:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 131:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 131:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 131:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 131:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.7419, avg_loss=34.7419]Epoch 131:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0268, avg_loss=35.0268]Epoch 131:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.5446, avg_loss=33.5446]Epoch 131:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6304, avg_loss=36.6304]Epoch 131:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:  36%|███▋      | 4/11 [00:05<00:09,  1.33s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:  45%|████▌     | 5/11 [00:06<00:08,  1.38s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  45%|████▌     | 5/11 [00:06<00:08,  1.38s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:  45%|████▌     | 5/11 [00:06<00:08,  1.38s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:  45%|████▌     | 5/11 [00:06<00:08,  1.38s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:  64%|██████▎   | 7/11 [00:09<00:05,  1.44s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:  82%|████████▏ | 9/11 [00:12<00:02,  1.47s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:  82%|████████▏ | 9/11 [00:12<00:02,  1.47s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:  82%|████████▏ | 9/11 [00:12<00:02,  1.47s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  82%|████████▏ | 9/11 [00:12<00:02,  1.47s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:  91%|█████████ | 10/11 [00:14<00:01,  1.47s/it, loss=35.0268, avg_loss=35.0268]Epoch 131:  91%|█████████ | 10/11 [00:14<00:01,  1.47s/it, loss=34.7419, avg_loss=34.7419]Epoch 131:  91%|█████████ | 10/11 [00:14<00:01,  1.47s/it, loss=36.6304, avg_loss=36.6304]Epoch 131:  91%|█████████ | 10/11 [00:14<00:01,  1.47s/it, loss=33.5446, avg_loss=33.5446]Epoch 131:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=32.6414, avg_loss=34.9885]Epoch 131: 100%|██████████| 11/11 [00:15<00:00,  1.51s/it, loss=32.6414, avg_loss=34.9885]Epoch 131: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=32.6414, avg_loss=34.9885]
Epoch 131:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=37.8221, avg_loss=35.6368]Epoch 131: 100%|██████████| 11/11 [00:15<00:00,  1.51s/it, loss=37.8221, avg_loss=35.6368]Epoch 131: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=37.8221, avg_loss=35.6368]
INFO:__main__:=== EPOCH 131 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.988476
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.321765
INFO:__main__:   • gene_density: 1.190992
INFO:__main__:   • operon_membership: 11.475719
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 131 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.636837
Epoch 131:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=32.9719, avg_loss=36.6445]INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.700860
INFO:__main__:   • gene_density: 1.187263
INFO:__main__:   • operon_membership: 11.748713
Epoch 131: 100%|██████████| 11/11 [00:15<00:00,  1.52s/it, loss=32.9719, avg_loss=36.6445]INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 131: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=32.9719, avg_loss=36.6445]
INFO:__main__:=== EPOCH 131 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.644539
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.798663
INFO:__main__:   • gene_density: 1.175722
INFO:__main__:   • operon_membership: 11.670153
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 131:  91%|█████████ | 10/11 [00:15<00:01,  1.47s/it, loss=34.7546, avg_loss=35.5338]Epoch 131: 100%|██████████| 11/11 [00:15<00:00,  1.51s/it, loss=34.7546, avg_loss=35.5338]Epoch 131: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=34.7546, avg_loss=35.5338]
INFO:__main__:=== EPOCH 131 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.533779
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.680349
INFO:__main__:   • gene_density: 1.182351
INFO:__main__:   • operon_membership: 11.671078
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 132/681
INFO:__main__:Epoch 132/681
INFO:__main__:Epoch 132/681
INFO:__main__:Epoch 132/681
Epoch 132:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 132:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 132:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 132:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 132:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7185, avg_loss=37.7185]Epoch 132:   9%|▉         | 1/11 [00:01<00:14,  1.49s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8913, avg_loss=36.8913]Epoch 132:   9%|▉         | 1/11 [00:01<00:14,  1.49s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5267, avg_loss=35.5267]Epoch 132:   9%|▉         | 1/11 [00:01<00:14,  1.50s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.3132, avg_loss=38.3132]Epoch 132:   9%|▉         | 1/11 [00:01<00:15,  1.50s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  18%|█▊        | 2/11 [00:02<00:10,  1.22s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:  18%|█▊        | 2/11 [00:02<00:10,  1.22s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:  18%|█▊        | 2/11 [00:02<00:10,  1.22s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  18%|█▊        | 2/11 [00:02<00:11,  1.22s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:  27%|██▋       | 3/11 [00:03<00:08,  1.05s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:  27%|██▋       | 3/11 [00:03<00:08,  1.05s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:  27%|██▋       | 3/11 [00:03<00:08,  1.05s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  27%|██▋       | 3/11 [00:03<00:08,  1.05s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:  36%|███▋      | 4/11 [00:04<00:08,  1.17s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:  36%|███▋      | 4/11 [00:04<00:08,  1.18s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:  36%|███▋      | 4/11 [00:04<00:08,  1.17s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:  36%|███▋      | 4/11 [00:04<00:08,  1.18s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  45%|████▌     | 5/11 [00:06<00:07,  1.26s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:  45%|████▌     | 5/11 [00:06<00:07,  1.26s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:  45%|████▌     | 5/11 [00:06<00:07,  1.26s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:  45%|████▌     | 5/11 [00:06<00:07,  1.26s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=37.7185, avg_loss=37.7185]Epoch 132:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=36.8913, avg_loss=36.8913]Epoch 132:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=35.5267, avg_loss=35.5267]Epoch 132:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=38.3132, avg_loss=38.3132]Epoch 132:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=37.1767, avg_loss=36.4873]Epoch 132: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=37.1767, avg_loss=36.4873]Epoch 132: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=37.1767, avg_loss=36.4873]
INFO:__main__:=== EPOCH 132 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.487288
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.860163
INFO:__main__:   • gene_density: 1.178918
INFO:__main__:   • operon_membership: 11.448207
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 132:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=32.7942, avg_loss=34.9538]Epoch 132: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=32.7942, avg_loss=34.9538]Epoch 132: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=32.7942, avg_loss=34.9538]
Epoch 132:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=34.6191, avg_loss=35.6322]Epoch 132: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=34.6191, avg_loss=35.6322]Epoch 132: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=34.6191, avg_loss=35.6322]
INFO:__main__:=== EPOCH 132 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.953766
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.195556
INFO:__main__:=== EPOCH 132 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.188210
INFO:__main__:   • operon_membership: 11.570000
INFO:__main__:🔢 Total Loss: 35.632203
INFO:__main__:👥 Samples processed: 22
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 22.456621
INFO:__main__:   • gene_density: 1.188092
INFO:__main__:   • operon_membership: 11.987490
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 132:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=34.5735, avg_loss=35.8420]Epoch 132: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=34.5735, avg_loss=35.8420]Epoch 132: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=34.5735, avg_loss=35.8420]
INFO:__main__:=== EPOCH 132 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.841998
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.892868
INFO:__main__:   • gene_density: 1.177853
INFO:__main__:   • operon_membership: 11.771278
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 133/681
INFO:__main__:Epoch 133/681
INFO:__main__:Epoch 133/681
INFO:__main__:Epoch 133/681
Epoch 133:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 133:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 133:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 133:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 133:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9240, avg_loss=33.9240]Epoch 133:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8291, avg_loss=35.8291]Epoch 133:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5843, avg_loss=34.5843]Epoch 133:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7483, avg_loss=36.7483]Epoch 133:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  18%|█▊        | 2/11 [00:03<00:13,  1.48s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:  18%|█▊        | 2/11 [00:03<00:13,  1.48s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:  18%|█▊        | 2/11 [00:03<00:13,  1.48s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:  18%|█▊        | 2/11 [00:03<00:13,  1.48s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  27%|██▋       | 3/11 [00:04<00:10,  1.32s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:  27%|██▋       | 3/11 [00:04<00:10,  1.32s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:  27%|██▋       | 3/11 [00:04<00:10,  1.32s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  36%|███▋      | 4/11 [00:05<00:08,  1.25s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:  36%|███▋      | 4/11 [00:05<00:08,  1.25s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:  36%|███▋      | 4/11 [00:05<00:08,  1.25s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:  36%|███▋      | 4/11 [00:05<00:08,  1.25s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  45%|████▌     | 5/11 [00:06<00:06,  1.13s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  45%|████▌     | 5/11 [00:06<00:06,  1.13s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:  45%|████▌     | 5/11 [00:06<00:06,  1.13s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:  45%|████▌     | 5/11 [00:06<00:06,  1.13s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:  55%|█████▍    | 6/11 [00:07<00:05,  1.06s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:  55%|█████▍    | 6/11 [00:07<00:05,  1.06s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:  55%|█████▍    | 6/11 [00:07<00:05,  1.06s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:  55%|█████▍    | 6/11 [00:07<00:05,  1.06s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  64%|██████▎   | 7/11 [00:08<00:04,  1.18s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:  64%|██████▎   | 7/11 [00:08<00:04,  1.18s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:  64%|██████▎   | 7/11 [00:08<00:04,  1.18s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:  64%|██████▎   | 7/11 [00:08<00:04,  1.18s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  73%|███████▎  | 8/11 [00:09<00:03,  1.26s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:  73%|███████▎  | 8/11 [00:09<00:03,  1.26s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:  73%|███████▎  | 8/11 [00:09<00:03,  1.26s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=33.9240, avg_loss=33.9240]Epoch 133:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=35.8291, avg_loss=35.8291]Epoch 133:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=34.5843, avg_loss=34.5843]Epoch 133:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=36.7483, avg_loss=36.7483]Epoch 133:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=35.2869, avg_loss=35.5836]Epoch 133:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=34.7189, avg_loss=36.6387]Epoch 133: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=35.2869, avg_loss=35.5836]Epoch 133: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=34.7189, avg_loss=36.6387]Epoch 133: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=35.2869, avg_loss=35.5836]
Epoch 133: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=34.7189, avg_loss=36.6387]
INFO:__main__:=== EPOCH 133 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 133 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.583610
INFO:__main__:🔢 Total Loss: 36.638701
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.849115
INFO:__main__:   • gene_expression: 24.187310
INFO:__main__:   • gene_density: 1.189927
INFO:__main__:   • gene_density: 1.189572
INFO:__main__:   • operon_membership: 11.544569
INFO:__main__:   • operon_membership: 11.261819
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 133:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=34.9055, avg_loss=35.3312]Epoch 133: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=34.9055, avg_loss=35.3312]Epoch 133: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=34.9055, avg_loss=35.3312]
INFO:__main__:=== EPOCH 133 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.331233
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.017336
INFO:__main__:   • gene_density: 1.179096
INFO:__main__:   • operon_membership: 11.134801
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 133:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=35.4685, avg_loss=35.6170]Epoch 133: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=35.4685, avg_loss=35.6170]Epoch 133: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=35.4685, avg_loss=35.6170]
INFO:__main__:=== EPOCH 133 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.616993
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.697561
INFO:__main__:   • gene_density: 1.174598
INFO:__main__:   • operon_membership: 12.744834
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 134/681
INFO:__main__:Epoch 134/681
INFO:__main__:Epoch 134/681
INFO:__main__:Epoch 134/681
Epoch 134:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 134:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 134:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 134:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 134:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0220, avg_loss=34.0220]Epoch 134:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.0880, avg_loss=37.0880]Epoch 134:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.7558, avg_loss=39.7558]Epoch 134:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.8680, avg_loss=39.8680]Epoch 134:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  45%|████▌     | 5/11 [00:07<00:08,  1.37s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:  45%|████▌     | 5/11 [00:07<00:08,  1.37s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:  45%|████▌     | 5/11 [00:07<00:08,  1.37s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:  45%|████▌     | 5/11 [00:07<00:08,  1.37s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  55%|█████▍    | 6/11 [00:08<00:06,  1.29s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:  55%|█████▍    | 6/11 [00:08<00:06,  1.29s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:  55%|█████▍    | 6/11 [00:08<00:06,  1.29s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:  55%|█████▍    | 6/11 [00:08<00:06,  1.29s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  64%|██████▎   | 7/11 [00:09<00:04,  1.22s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:  64%|██████▎   | 7/11 [00:09<00:04,  1.21s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  64%|██████▎   | 7/11 [00:09<00:04,  1.22s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:  64%|██████▎   | 7/11 [00:09<00:04,  1.22s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:  73%|███████▎  | 8/11 [00:10<00:03,  1.10s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:  73%|███████▎  | 8/11 [00:10<00:03,  1.09s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  73%|███████▎  | 8/11 [00:10<00:03,  1.10s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:  73%|███████▎  | 8/11 [00:10<00:03,  1.10s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:  82%|████████▏ | 9/11 [00:11<00:02,  1.15s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:  82%|████████▏ | 9/11 [00:11<00:02,  1.15s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:  82%|████████▏ | 9/11 [00:11<00:02,  1.15s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:  82%|████████▏ | 9/11 [00:11<00:02,  1.16s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  91%|█████████ | 10/11 [00:12<00:01,  1.24s/it, loss=34.0220, avg_loss=34.0220]Epoch 134:  91%|█████████ | 10/11 [00:12<00:01,  1.24s/it, loss=39.7558, avg_loss=39.7558]Epoch 134:  91%|█████████ | 10/11 [00:12<00:01,  1.24s/it, loss=37.0880, avg_loss=37.0880]Epoch 134:  91%|█████████ | 10/11 [00:12<00:01,  1.24s/it, loss=39.8680, avg_loss=39.8680]Epoch 134:  91%|█████████ | 10/11 [00:14<00:01,  1.24s/it, loss=37.4668, avg_loss=36.3535]Epoch 134: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=37.4668, avg_loss=36.3535]Epoch 134: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=37.4668, avg_loss=36.3535]
INFO:__main__:=== EPOCH 134 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.353452
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.880628
INFO:__main__:   • gene_density: 1.185665
INFO:__main__:   • operon_membership: 11.287158
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 134:  91%|█████████ | 10/11 [00:14<00:01,  1.24s/it, loss=35.3500, avg_loss=35.2015]Epoch 134: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.3500, avg_loss=35.2015]Epoch 134:  91%|█████████ | 10/11 [00:14<00:01,  1.24s/it, loss=39.5158, avg_loss=36.3434]Epoch 134: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=39.5158, avg_loss=36.3434]Epoch 134: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.3500, avg_loss=35.2015]
Epoch 134: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=39.5158, avg_loss=36.3434]
INFO:__main__:=== EPOCH 134 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.201462
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.030520
INFO:__main__:   • gene_density: 1.171342
INFO:__main__:   • operon_membership: 10.999599
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 134 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.343409
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.148878
INFO:__main__:   • gene_density: 1.185724
INFO:__main__:   • operon_membership: 12.008806
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 134:  91%|█████████ | 10/11 [00:14<00:01,  1.24s/it, loss=34.3157, avg_loss=35.1616]Epoch 134: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.3157, avg_loss=35.1616]Epoch 134: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=34.3157, avg_loss=35.1616]
INFO:__main__:=== EPOCH 134 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.161644
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.794427
INFO:__main__:   • gene_density: 1.186080
INFO:__main__:   • operon_membership: 12.181138
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 135/681
INFO:__main__:Epoch 135/681
INFO:__main__:Epoch 135/681
INFO:__main__:Epoch 135/681
Epoch 135:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 135:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 135:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 135:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 135:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5443, avg_loss=35.5443]Epoch 135:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.9739, avg_loss=34.9739]Epoch 135:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4679, avg_loss=35.4679]Epoch 135:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9398, avg_loss=36.9398]Epoch 135:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  64%|██████▎   | 7/11 [00:10<00:05,  1.40s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:  64%|██████▎   | 7/11 [00:10<00:05,  1.40s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:  64%|██████▎   | 7/11 [00:10<00:05,  1.40s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:  64%|██████▎   | 7/11 [00:10<00:05,  1.40s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  73%|███████▎  | 8/11 [00:11<00:03,  1.32s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:  73%|███████▎  | 8/11 [00:11<00:03,  1.32s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:  73%|███████▎  | 8/11 [00:11<00:03,  1.32s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  73%|███████▎  | 8/11 [00:11<00:03,  1.32s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=35.5443, avg_loss=35.5443]Epoch 135:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=36.9398, avg_loss=36.9398]Epoch 135:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=35.4679, avg_loss=35.4679]Epoch 135:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=34.9739, avg_loss=34.9739]Epoch 135:  91%|█████████ | 10/11 [00:14<00:01,  1.15s/it, loss=39.4555, avg_loss=35.7700]Epoch 135:  91%|█████████ | 10/11 [00:14<00:01,  1.15s/it, loss=36.1247, avg_loss=35.7599]Epoch 135: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=39.4555, avg_loss=35.7700]Epoch 135: 100%|██████████| 11/11 [00:14<00:00,  1.15s/it, loss=36.1247, avg_loss=35.7599]Epoch 135: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=39.4555, avg_loss=35.7700]
Epoch 135: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.1247, avg_loss=35.7599]
INFO:__main__:=== EPOCH 135 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 135 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.770041
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.759916
INFO:__main__:   • gene_expression: 22.807980
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.178622
INFO:__main__:   • operon_membership: 11.783438
INFO:__main__:   • gene_expression: 22.375402
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_density: 1.185251
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.199263
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 135:  91%|█████████ | 10/11 [00:14<00:01,  1.15s/it, loss=34.9335, avg_loss=35.5486]Epoch 135: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=34.9335, avg_loss=35.5486]Epoch 135: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=34.9335, avg_loss=35.5486]
INFO:__main__:=== EPOCH 135 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.548594
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.462885
INFO:__main__:   • gene_density: 1.186257
INFO:__main__:   • operon_membership: 11.899451
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 135:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=38.7968, avg_loss=35.8367]Epoch 135: 100%|██████████| 11/11 [00:14<00:00,  1.16s/it, loss=38.7968, avg_loss=35.8367]Epoch 135: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=38.7968, avg_loss=35.8367]
INFO:__main__:=== EPOCH 135 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.836707
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.758942
INFO:__main__:   • gene_density: 1.182943
INFO:__main__:   • operon_membership: 10.894822
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.20it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.43it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.43it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.44it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.44it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.55it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.55it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.55it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.54it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.45it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.45it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.45it/s]INFO:__main__:=== EPOCH 135 VALIDATION LOSSES ===

INFO:__main__:=== EPOCH 135 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 135 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.45it/s]
INFO:__main__:=== EPOCH 135 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 136/681
INFO:__main__:Epoch 136/681
INFO:__main__:Epoch 136/681
INFO:__main__:Epoch 136/681
Epoch 136:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 136:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 136:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 136:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 136:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8626, avg_loss=36.8626]Epoch 136:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.4969, avg_loss=32.4969]Epoch 136:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1724, avg_loss=37.1724]Epoch 136:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.3073, avg_loss=37.3073]Epoch 136:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:  55%|█████▍    | 6/11 [00:09<00:07,  1.49s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:  73%|███████▎  | 8/11 [00:11<00:04,  1.35s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  82%|████████▏ | 9/11 [00:12<00:02,  1.24s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:  91%|█████████ | 10/11 [00:13<00:01,  1.12s/it, loss=32.4969, avg_loss=32.4969]Epoch 136:  91%|█████████ | 10/11 [00:13<00:01,  1.12s/it, loss=36.8626, avg_loss=36.8626]Epoch 136:  91%|█████████ | 10/11 [00:13<00:01,  1.12s/it, loss=37.3073, avg_loss=37.3073]Epoch 136:  91%|█████████ | 10/11 [00:13<00:01,  1.12s/it, loss=37.1724, avg_loss=37.1724]Epoch 136:  91%|█████████ | 10/11 [00:15<00:01,  1.12s/it, loss=38.4169, avg_loss=34.8664]Epoch 136: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=38.4169, avg_loss=34.8664]Epoch 136: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=38.4169, avg_loss=34.8664]
INFO:__main__:=== EPOCH 136 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.866390
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.817585
INFO:__main__:   • gene_density: 1.183061
INFO:__main__:   • operon_membership: 11.865743
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 136:  91%|█████████ | 10/11 [00:15<00:01,  1.12s/it, loss=36.0926, avg_loss=36.2182]Epoch 136: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=36.0926, avg_loss=36.2182]Epoch 136: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.0926, avg_loss=36.2182]
INFO:__main__:=== EPOCH 136 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.218249
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.958168
INFO:__main__:   • gene_density: 1.191170
INFO:__main__:   • operon_membership: 11.068911
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 136:  91%|█████████ | 10/11 [00:15<00:01,  1.12s/it, loss=38.7976, avg_loss=35.5452]Epoch 136: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=38.7976, avg_loss=35.5452]Epoch 136: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=38.7976, avg_loss=35.5452]
INFO:__main__:=== EPOCH 136 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.545200
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.182715
INFO:__main__:   • gene_density: 1.188329
INFO:__main__:   • operon_membership: 12.174156
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 136:  91%|█████████ | 10/11 [00:15<00:01,  1.12s/it, loss=33.9264, avg_loss=36.3763]Epoch 136: 100%|██████████| 11/11 [00:15<00:00,  1.28s/it, loss=33.9264, avg_loss=36.3763]Epoch 136: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.9264, avg_loss=36.3763]
INFO:__main__:=== EPOCH 136 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.376293
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.837304
INFO:__main__:   • gene_density: 1.169804
INFO:__main__:   • operon_membership: 11.369185
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 137/681
INFO:__main__:Epoch 137/681
INFO:__main__:Epoch 137/681
INFO:__main__:Epoch 137/681
Epoch 137:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 137:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 137:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 137:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 137:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2917, avg_loss=35.2917]Epoch 137:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.3776, avg_loss=39.3776]Epoch 137:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.8219, avg_loss=39.8219]Epoch 137:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9076, avg_loss=36.9076]Epoch 137:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:  27%|██▋       | 3/11 [00:04<00:12,  1.53s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:  36%|███▋      | 4/11 [00:06<00:10,  1.50s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:  55%|█████▍    | 6/11 [00:09<00:07,  1.47s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  82%|████████▏ | 9/11 [00:13<00:02,  1.35s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:  82%|████████▏ | 9/11 [00:13<00:02,  1.35s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:  82%|████████▏ | 9/11 [00:13<00:02,  1.35s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:  82%|████████▏ | 9/11 [00:13<00:02,  1.35s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=35.2917, avg_loss=35.2917]Epoch 137:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=39.3776, avg_loss=39.3776]Epoch 137:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=39.8219, avg_loss=39.8219]Epoch 137:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=36.9076, avg_loss=36.9076]Epoch 137:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=37.8713, avg_loss=35.1961]Epoch 137: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=37.8713, avg_loss=35.1961]Epoch 137: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.8713, avg_loss=35.1961]
INFO:__main__:=== EPOCH 137 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.196125
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.471656
INFO:__main__:   • gene_density: 1.169034
INFO:__main__:   • operon_membership: 11.555435
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 137:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=37.8618, avg_loss=36.2457]Epoch 137: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=37.8618, avg_loss=36.2457]Epoch 137:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=36.0383, avg_loss=36.0057]Epoch 137: 100%|██████████| 11/11 [00:15<00:00,  1.21s/it, loss=36.0383, avg_loss=36.0057]Epoch 137:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=42.7086, avg_loss=35.8133]Epoch 137: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.8618, avg_loss=36.2457]
Epoch 137: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=42.7086, avg_loss=35.8133]Epoch 137: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.0383, avg_loss=36.0057]
Epoch 137: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=42.7086, avg_loss=35.8133]
INFO:__main__:=== EPOCH 137 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 137 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.245695
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 36.005694
INFO:__main__:   • gene_expression: 22.990867
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.176432
INFO:__main__:   • gene_expression: 23.450456
INFO:__main__:   • operon_membership: 12.078395
INFO:__main__:   • gene_density: 1.198213
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.357025
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 137 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.813325
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.111932
INFO:__main__:   • gene_density: 1.189098
INFO:__main__:   • operon_membership: 11.512294
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 138/681
INFO:__main__:Epoch 138/681
INFO:__main__:Epoch 138/681
INFO:__main__:Epoch 138/681
Epoch 138:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 138:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 138:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 138:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 138:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0249, avg_loss=34.0249]Epoch 138:   9%|▉         | 1/11 [00:01<00:15,  1.57s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7781, avg_loss=35.7781]Epoch 138:   9%|▉         | 1/11 [00:01<00:15,  1.57s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.8793, avg_loss=37.8793]Epoch 138:   9%|▉         | 1/11 [00:01<00:15,  1.57s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1227, avg_loss=35.1227]Epoch 138:   9%|▉         | 1/11 [00:01<00:15,  1.59s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=37.8793, avg_loss=37.8793]Epoch 138:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=34.0249, avg_loss=34.0249]Epoch 138:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=35.7781, avg_loss=35.7781]Epoch 138:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.1227, avg_loss=35.1227]Epoch 138:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=36.2730, avg_loss=35.7867]Epoch 138: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=36.2730, avg_loss=35.7867]Epoch 138: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=36.2730, avg_loss=35.7867]
Epoch 138:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=36.3257, avg_loss=36.1098]Epoch 138: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=36.3257, avg_loss=36.1098]Epoch 138: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=36.3257, avg_loss=36.1098]
INFO:__main__:=== EPOCH 138 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.786682
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.090640
INFO:__main__:   • gene_density: 1.195076
INFO:__main__:   • operon_membership: 11.500966
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 138 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.109820
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.482448
INFO:__main__:   • gene_density: 1.176669
INFO:__main__:   • operon_membership: 11.450704
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 138:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=36.1852, avg_loss=35.8155]Epoch 138: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=36.1852, avg_loss=35.8155]Epoch 138: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=36.1852, avg_loss=35.8155]
INFO:__main__:=== EPOCH 138 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.815466
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.662366
INFO:__main__:   • gene_density: 1.181286
INFO:__main__:   • operon_membership: 11.971815
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 138:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=33.7238, avg_loss=35.5421]Epoch 138: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.7238, avg_loss=35.5421]Epoch 138: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=33.7238, avg_loss=35.5421]
INFO:__main__:=== EPOCH 138 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.542142
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.599142
INFO:__main__:   • gene_density: 1.179628
INFO:__main__:   • operon_membership: 11.763371
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 139/681
INFO:__main__:Epoch 139/681
INFO:__main__:Epoch 139/681
INFO:__main__:Epoch 139/681
Epoch 139:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 139:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 139:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 139:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 139:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.8376, avg_loss=31.8376]Epoch 139:   9%|▉         | 1/11 [00:01<00:12,  1.22s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.2438, avg_loss=37.2438]Epoch 139:   9%|▉         | 1/11 [00:01<00:12,  1.23s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.9351, avg_loss=38.9351]Epoch 139:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5307, avg_loss=37.5307]Epoch 139:   9%|▉         | 1/11 [00:01<00:12,  1.23s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:   9%|▉         | 1/11 [00:01<00:12,  1.23s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  18%|█▊        | 2/11 [00:02<00:09,  1.05s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:  18%|█▊        | 2/11 [00:02<00:09,  1.05s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:  18%|█▊        | 2/11 [00:02<00:09,  1.05s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:  18%|█▊        | 2/11 [00:02<00:09,  1.07s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:  45%|████▌     | 5/11 [00:06<00:08,  1.37s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:  45%|████▌     | 5/11 [00:06<00:08,  1.37s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:  55%|█████▍    | 6/11 [00:07<00:06,  1.40s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:  55%|█████▍    | 6/11 [00:07<00:06,  1.40s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  73%|███████▎  | 8/11 [00:10<00:04,  1.43s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:  73%|███████▎  | 8/11 [00:10<00:04,  1.43s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:  73%|███████▎  | 8/11 [00:10<00:04,  1.43s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:  73%|███████▎  | 8/11 [00:10<00:04,  1.43s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:  82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=38.9351, avg_loss=38.9351]Epoch 139:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=31.8376, avg_loss=31.8376]Epoch 139:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=37.2438, avg_loss=37.2438]Epoch 139:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=37.5307, avg_loss=37.5307]Epoch 139:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=35.1607, avg_loss=35.6068]Epoch 139: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.1607, avg_loss=35.6068]Epoch 139: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.1607, avg_loss=35.6068]
Epoch 139:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=36.8223, avg_loss=35.6378]Epoch 139: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=36.8223, avg_loss=35.6378]Epoch 139:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=36.2897, avg_loss=35.1377]Epoch 139: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=36.8223, avg_loss=35.6378]
Epoch 139: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=36.2897, avg_loss=35.1377]INFO:__main__:=== EPOCH 139 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.606754
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.440136
INFO:__main__:   • gene_density: 1.175012
INFO:__main__:   • operon_membership: 11.991605
INFO:__main__:👥 Samples processed: 22
Epoch 139: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=36.2897, avg_loss=35.1377]INFO:__main__:========================================

INFO:__main__:=== EPOCH 139 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.637773
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:=== EPOCH 139 TRAINING LOSSES ===
INFO:__main__:   • gene_expression: 23.336163
INFO:__main__:   • gene_density: 1.185073
INFO:__main__:🔢 Total Loss: 35.137699
INFO:__main__:   • operon_membership: 11.116537
INFO:__main__:👥 Samples processed: 22
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 22.459919
INFO:__main__:   • gene_density: 1.179865
INFO:__main__:   • operon_membership: 11.497914
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 139:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=36.8029, avg_loss=36.6838]Epoch 139: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=36.8029, avg_loss=36.6838]Epoch 139: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=36.8029, avg_loss=36.6838]
INFO:__main__:=== EPOCH 139 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.683750
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.433380
INFO:__main__:   • gene_density: 1.189453
INFO:__main__:   • operon_membership: 12.060917
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 140/681
INFO:__main__:Epoch 140/681
INFO:__main__:Epoch 140/681
INFO:__main__:Epoch 140/681
Epoch 140:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 140:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 140:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 140:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 140:   0%|          | 0/11 [00:01<?, ?it/s, loss=30.5872, avg_loss=30.5872]Epoch 140:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5427, avg_loss=36.5427]Epoch 140:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3008, avg_loss=34.3008]Epoch 140:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.9898, avg_loss=32.9898]Epoch 140:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  18%|█▊        | 2/11 [00:02<00:11,  1.29s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:  18%|█▊        | 2/11 [00:02<00:11,  1.29s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:  18%|█▊        | 2/11 [00:02<00:11,  1.29s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:  18%|█▊        | 2/11 [00:02<00:11,  1.30s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  27%|██▋       | 3/11 [00:03<00:08,  1.09s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  27%|██▋       | 3/11 [00:03<00:08,  1.09s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:  27%|██▋       | 3/11 [00:03<00:08,  1.09s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:  27%|██▋       | 3/11 [00:03<00:08,  1.09s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:  36%|███▋      | 4/11 [00:04<00:07,  1.13s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:  36%|███▋      | 4/11 [00:04<00:07,  1.13s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:  36%|███▋      | 4/11 [00:04<00:07,  1.13s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:  36%|███▋      | 4/11 [00:04<00:07,  1.14s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  45%|████▌     | 5/11 [00:06<00:07,  1.24s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  64%|██████▎   | 7/11 [00:08<00:05,  1.35s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:  64%|██████▎   | 7/11 [00:08<00:05,  1.35s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:  64%|██████▎   | 7/11 [00:08<00:05,  1.35s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:  64%|██████▎   | 7/11 [00:09<00:05,  1.35s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=36.5427, avg_loss=36.5427]Epoch 140:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=34.3008, avg_loss=34.3008]Epoch 140:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=30.5872, avg_loss=30.5872]Epoch 140:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=32.9898, avg_loss=32.9898]Epoch 140:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=39.6587, avg_loss=36.3391]Epoch 140: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=39.6587, avg_loss=36.3391]Epoch 140: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=39.6587, avg_loss=36.3391]
INFO:__main__:=== EPOCH 140 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.339110
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.808755
INFO:__main__:   • gene_density: 1.182943
INFO:__main__:   • operon_membership: 12.347412
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 140:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.4383, avg_loss=35.4591]Epoch 140: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.4383, avg_loss=35.4591]Epoch 140: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.4383, avg_loss=35.4591]
Epoch 140:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=38.7934, avg_loss=35.9020]Epoch 140: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=38.7934, avg_loss=35.9020]INFO:__main__:=== EPOCH 140 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.459114
Epoch 140: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=38.7934, avg_loss=35.9020]INFO:__main__:📊 Individual Modality Losses:

INFO:__main__:   • gene_expression: 23.031048
INFO:__main__:   • gene_density: 1.180812
INFO:__main__:   • operon_membership: 11.247254
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 140 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.901971
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.865632
INFO:__main__:   • gene_density: 1.177438
INFO:__main__:   • operon_membership: 11.858900
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 140:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.4397, avg_loss=35.1133]Epoch 140: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.4397, avg_loss=35.1133]Epoch 140: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.4397, avg_loss=35.1133]
INFO:__main__:=== EPOCH 140 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.113315
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.994946
INFO:__main__:   • gene_density: 1.193123
INFO:__main__:   • operon_membership: 10.925247
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.58it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.58it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.58it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]
INFO:__main__:=== EPOCH 140 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 140 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:=== EPOCH 140 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]
INFO:__main__:=== EPOCH 140 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_140.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_140.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_140.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_140.pt
INFO:__main__:Epoch 141/681
INFO:__main__:Epoch 141/681
INFO:__main__:Epoch 141/681
INFO:__main__:Epoch 141/681
Epoch 141:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 141:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 141:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 141:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 141:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.2472, avg_loss=33.2472]Epoch 141:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8366, avg_loss=35.8366]Epoch 141:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.2576, avg_loss=37.2576]Epoch 141:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4308, avg_loss=36.4308]Epoch 141:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  64%|██████▎   | 7/11 [00:10<00:05,  1.39s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:  64%|██████▎   | 7/11 [00:10<00:05,  1.39s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:  64%|██████▎   | 7/11 [00:10<00:05,  1.39s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:  64%|██████▎   | 7/11 [00:10<00:05,  1.39s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  73%|███████▎  | 8/11 [00:11<00:03,  1.31s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:  73%|███████▎  | 8/11 [00:11<00:03,  1.31s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:  73%|███████▎  | 8/11 [00:11<00:03,  1.31s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:  73%|███████▎  | 8/11 [00:11<00:03,  1.31s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=37.2576, avg_loss=37.2576]Epoch 141:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=33.2472, avg_loss=33.2472]Epoch 141:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=35.8366, avg_loss=35.8366]Epoch 141:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=36.4308, avg_loss=36.4308]Epoch 141:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=33.1731, avg_loss=35.4634]Epoch 141: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=33.1731, avg_loss=35.4634]Epoch 141:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=36.3407, avg_loss=35.8189]Epoch 141: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=36.3407, avg_loss=35.8189]Epoch 141: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=33.1731, avg_loss=35.4634]
Epoch 141: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.3407, avg_loss=35.8189]
Epoch 141:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=36.2213, avg_loss=36.0056]INFO:__main__:=== EPOCH 141 TRAINING LOSSES ===
Epoch 141: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=36.2213, avg_loss=36.0056]INFO:__main__:🔢 Total Loss: 35.463433
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.545421
INFO:__main__:=== EPOCH 141 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.185488
INFO:__main__:   • operon_membership: 10.732524
INFO:__main__:🔢 Total Loss: 35.818918
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.388117
INFO:__main__:   • gene_density: 1.185073
INFO:__main__:   • operon_membership: 11.245728
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 141: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.2213, avg_loss=36.0056]
INFO:__main__:=== EPOCH 141 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.005634
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.730543
INFO:__main__:   • gene_density: 1.173947
INFO:__main__:   • operon_membership: 12.101145
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 141:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=34.7586, avg_loss=35.6892]Epoch 141: 100%|██████████| 11/11 [00:14<00:00,  1.20s/it, loss=34.7586, avg_loss=35.6892]Epoch 141: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=34.7586, avg_loss=35.6892]
INFO:__main__:=== EPOCH 141 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.689175
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.835894
INFO:__main__:   • gene_density: 1.187145
INFO:__main__:   • operon_membership: 12.666136
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 142/681
INFO:__main__:Epoch 142/681
INFO:__main__:Epoch 142/681
INFO:__main__:Epoch 142/681
Epoch 142:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 142:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 142:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 142:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 142:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.7245, avg_loss=34.7245]Epoch 142:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.3751, avg_loss=38.3751]Epoch 142:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5734, avg_loss=34.5734]Epoch 142:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.3527, avg_loss=33.3527]Epoch 142:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=38.3751, avg_loss=38.3751]Epoch 142:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=34.5734, avg_loss=34.5734]Epoch 142:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=34.7245, avg_loss=34.7245]Epoch 142:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=33.3527, avg_loss=33.3527]Epoch 142:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=35.8317, avg_loss=36.8369]Epoch 142: 100%|██████████| 11/11 [00:15<00:00,  1.35s/it, loss=35.8317, avg_loss=36.8369]Epoch 142: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.8317, avg_loss=36.8369]
INFO:__main__:=== EPOCH 142 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.836854
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.229908
INFO:__main__:   • gene_density: 1.179036
INFO:__main__:   • operon_membership: 11.427908
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 142:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=34.6979, avg_loss=34.8118]Epoch 142: 100%|██████████| 11/11 [00:15<00:00,  1.35s/it, loss=34.6979, avg_loss=34.8118]Epoch 142: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=34.6979, avg_loss=34.8118]
Epoch 142:  91%|█████████ | 10/11 [00:15<00:01,  1.35s/it, loss=33.1674, avg_loss=36.5745]Epoch 142: 100%|██████████| 11/11 [00:15<00:00,  1.35s/it, loss=33.1674, avg_loss=36.5745]Epoch 142: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=33.1674, avg_loss=36.5745]
INFO:__main__:=== EPOCH 142 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.811846
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.967382
INFO:__main__:   • gene_density: 1.167791
INFO:__main__:   • operon_membership: 11.676673
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 142 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.574512
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.289869
INFO:__main__:   • gene_density: 1.184659
INFO:__main__:   • operon_membership: 11.099983
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 142:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=32.9466, avg_loss=34.9601]Epoch 142: 100%|██████████| 11/11 [00:15<00:00,  1.35s/it, loss=32.9466, avg_loss=34.9601]Epoch 142: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=32.9466, avg_loss=34.9601]
INFO:__main__:=== EPOCH 142 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.960055
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.326671
INFO:__main__:   • gene_density: 1.195668
INFO:__main__:   • operon_membership: 12.437717
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 143/681
INFO:__main__:Epoch 143/681
INFO:__main__:Epoch 143/681
INFO:__main__:Epoch 143/681
Epoch 143:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 143:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 143:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 143:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 143:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5587, avg_loss=35.5587]Epoch 143:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.9610, avg_loss=37.9610]Epoch 143:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6938, avg_loss=33.6938]Epoch 143:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0430, avg_loss=36.0430]Epoch 143:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  18%|█▊        | 2/11 [00:02<00:10,  1.14s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  18%|█▊        | 2/11 [00:02<00:10,  1.14s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:  18%|█▊        | 2/11 [00:02<00:10,  1.14s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:  18%|█▊        | 2/11 [00:02<00:10,  1.15s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:  27%|██▋       | 3/11 [00:03<00:10,  1.27s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:  27%|██▋       | 3/11 [00:03<00:10,  1.27s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  27%|██▋       | 3/11 [00:03<00:10,  1.27s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:  27%|██▋       | 3/11 [00:03<00:10,  1.28s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:  36%|███▋      | 4/11 [00:05<00:09,  1.33s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  36%|███▋      | 4/11 [00:05<00:09,  1.33s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:  45%|████▌     | 5/11 [00:06<00:08,  1.37s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  45%|████▌     | 5/11 [00:06<00:08,  1.37s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:  45%|████▌     | 5/11 [00:06<00:08,  1.37s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:  45%|████▌     | 5/11 [00:06<00:08,  1.38s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:  55%|█████▍    | 6/11 [00:08<00:06,  1.39s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=37.9610, avg_loss=37.9610]Epoch 143:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=36.0430, avg_loss=36.0430]Epoch 143:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=33.6938, avg_loss=33.6938]Epoch 143:  91%|█████████ | 10/11 [00:13<00:01,  1.42s/it, loss=35.5587, avg_loss=35.5587]Epoch 143:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=34.2685, avg_loss=34.7151]Epoch 143: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=34.2685, avg_loss=34.7151]Epoch 143: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.2685, avg_loss=34.7151]
INFO:__main__:=== EPOCH 143 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.715128
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.061858
INFO:__main__:   • gene_density: 1.166726
INFO:__main__:   • operon_membership: 12.486545
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 143:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=42.7427, avg_loss=36.5127]Epoch 143: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=42.7427, avg_loss=36.5127]Epoch 143: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=42.7427, avg_loss=36.5127]
Epoch 143:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=37.1011, avg_loss=36.3763]Epoch 143: 100%|██████████| 11/11 [00:15<00:00,  1.47s/it, loss=37.1011, avg_loss=36.3763]Epoch 143: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=37.1011, avg_loss=36.3763]
INFO:__main__:=== EPOCH 143 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.512707
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.237727
INFO:__main__:   • gene_density: 1.175367
INFO:__main__:   • operon_membership: 11.099614
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 143 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.376337
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.538563
INFO:__main__:   • gene_density: 1.192768
INFO:__main__:   • operon_membership: 12.645005
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 143:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=32.7287, avg_loss=35.5576]Epoch 143: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=32.7287, avg_loss=35.5576]Epoch 143: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=32.7287, avg_loss=35.5576]
INFO:__main__:=== EPOCH 143 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.557554
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.083447
INFO:__main__:   • gene_density: 1.194306
INFO:__main__:   • operon_membership: 10.279800
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 144/681
INFO:__main__:Epoch 144/681
INFO:__main__:Epoch 144/681
INFO:__main__:Epoch 144/681
Epoch 144:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 144:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 144:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 144:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 144:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9342, avg_loss=33.9342]Epoch 144:   9%|▉         | 1/11 [00:01<00:14,  1.40s/it, loss=33.9342, avg_loss=33.9342]Epoch 144:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.7997, avg_loss=34.7997]Epoch 144:   9%|▉         | 1/11 [00:01<00:14,  1.41s/it, loss=34.7997, avg_loss=34.7997]Epoch 144:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.3727, avg_loss=38.3727]Epoch 144:   9%|▉         | 1/11 [00:01<00:14,  1.41s/it, loss=38.3727, avg_loss=38.3727]Epoch 144:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4565, avg_loss=35.4565]Epoch 144:   9%|▉         | 1/11 [00:01<00:14,  1.41s/it, loss=35.4565, avg_loss=35.4565]Epoch 144:  18%|█▊        | 2/11 [00:02<00:11,  1.24s/it, loss=34.7997, avg_loss=34.7997]Epoch 144:  18%|█▊        | 2/11 [00:02<00:11,  1.24s/it, loss=35.4565, avg_loss=35.4565]Epoch 144:  18%|█▊        | 2/11 [00:02<00:11,  1.24s/it, loss=33.9342, avg_loss=33.9342]Epoch 144:  18%|█▊        | 2/11 [00:02<00:11,  1.24s/it, loss=38.3727, avg_loss=38.3727]Epoch 144:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=38.3727, avg_loss=38.3727]Epoch 144:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=35.4565, avg_loss=35.4565]Epoch 144:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=33.9342, avg_loss=33.9342]Epoch 144:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=34.7997, avg_loss=34.7997]Epoch 144:  36%|███▋      | 4/11 [00:04<00:06,  1.01it/s, loss=35.4565, avg_loss=35.4565]Epoch 144:  36%|███▋      | 4/11 [00:04<00:06,  1.01it/s, loss=34.7997, avg_loss=34.7997]Epoch 144:  36%|███▋      | 4/11 [00:04<00:06,  1.01it/s, loss=38.3727, avg_loss=38.3727]Epoch 144:  36%|███▋      | 4/11 [00:04<00:06,  1.01it/s, loss=33.9342, avg_loss=33.9342]Epoch 144:  45%|████▌     | 5/11 [00:05<00:06,  1.14s/it, loss=35.4565, avg_loss=35.4565]Epoch 144:  45%|████▌     | 5/11 [00:05<00:06,  1.14s/it, loss=34.7997, avg_loss=34.7997]Epoch 144:  45%|████▌     | 5/11 [00:05<00:06,  1.14s/it, loss=33.9342, avg_loss=33.9342]Epoch 144:  45%|████▌     | 5/11 [00:05<00:06,  1.15s/it, loss=38.3727, avg_loss=38.3727]Epoch 144:  55%|█████▍    | 6/11 [00:07<00:06,  1.24s/it, loss=34.7997, avg_loss=34.7997]Epoch 144:  55%|█████▍    | 6/11 [00:07<00:06,  1.24s/it, loss=35.4565, avg_loss=35.4565]Epoch 144:  55%|█████▍    | 6/11 [00:07<00:06,  1.24s/it, loss=33.9342, avg_loss=33.9342]Epoch 144:  55%|█████▍    | 6/11 [00:07<00:06,  1.24s/it, loss=38.3727, avg_loss=38.3727]Epoch 144:  64%|██████▎   | 7/11 [00:08<00:05,  1.30s/it, loss=35.4565, avg_loss=35.4565]Epoch 144:  64%|██████▎   | 7/11 [00:08<00:05,  1.30s/it, loss=34.7997, avg_loss=34.7997]Epoch 144:  64%|██████▎   | 7/11 [00:08<00:05,  1.30s/it, loss=33.9342, avg_loss=33.9342]Epoch 144:  64%|██████▎   | 7/11 [00:08<00:05,  1.30s/it, loss=38.3727, avg_loss=38.3727]Epoch 144:  73%|███████▎  | 8/11 [00:09<00:03,  1.33s/it, loss=34.7997, avg_loss=34.7997]Epoch 144:  73%|███████▎  | 8/11 [00:09<00:04,  1.33s/it, loss=35.4565, avg_loss=35.4565]Epoch 144:  73%|███████▎  | 8/11 [00:09<00:03,  1.33s/it, loss=33.9342, avg_loss=33.9342]Epoch 144:  73%|███████▎  | 8/11 [00:09<00:04,  1.34s/it, loss=38.3727, avg_loss=38.3727]Epoch 144:  82%|████████▏ | 9/11 [00:11<00:02,  1.36s/it, loss=33.9342, avg_loss=33.9342]Epoch 144:  82%|████████▏ | 9/11 [00:11<00:02,  1.36s/it, loss=35.4565, avg_loss=35.4565]Epoch 144:  82%|████████▏ | 9/11 [00:11<00:02,  1.36s/it, loss=34.7997, avg_loss=34.7997]Epoch 144:  82%|████████▏ | 9/11 [00:11<00:02,  1.36s/it, loss=38.3727, avg_loss=38.3727]Epoch 144:  91%|█████████ | 10/11 [00:12<00:01,  1.37s/it, loss=34.7997, avg_loss=34.7997]Epoch 144:  91%|█████████ | 10/11 [00:12<00:01,  1.38s/it, loss=35.4565, avg_loss=35.4565]Epoch 144:  91%|█████████ | 10/11 [00:12<00:01,  1.38s/it, loss=33.9342, avg_loss=33.9342]Epoch 144:  91%|█████████ | 10/11 [00:12<00:01,  1.38s/it, loss=38.3727, avg_loss=38.3727]Epoch 144:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=34.6627, avg_loss=35.6592]Epoch 144: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=34.6627, avg_loss=35.6592]Epoch 144:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=33.1423, avg_loss=35.5923]Epoch 144: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=33.1423, avg_loss=35.5923]Epoch 144: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=34.6627, avg_loss=35.6592]
Epoch 144: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=33.1423, avg_loss=35.5923]
Epoch 144:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=38.1509, avg_loss=35.6135]Epoch 144: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=38.1509, avg_loss=35.6135]Epoch 144: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=38.1509, avg_loss=35.6135]
INFO:__main__:=== EPOCH 144 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.659247
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.392522
INFO:__main__:   • gene_density: 1.177557
INFO:__main__:   • operon_membership: 12.089169
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 144 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.592312
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.264584
INFO:__main__:   • gene_density: 1.192235
INFO:__main__:   • operon_membership: 11.135495
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 144 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.613537
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.688796
INFO:__main__:   • gene_density: 1.182824
INFO:__main__:   • operon_membership: 11.741916
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 144:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=36.8677, avg_loss=36.2638]Epoch 144: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=36.8677, avg_loss=36.2638]Epoch 144: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=36.8677, avg_loss=36.2638]
INFO:__main__:=== EPOCH 144 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.263824
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.676267
INFO:__main__:   • gene_density: 1.177912
INFO:__main__:   • operon_membership: 11.409644
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 145/681
INFO:__main__:Epoch 145/681
INFO:__main__:Epoch 145/681
INFO:__main__:Epoch 145/681
Epoch 145:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 145:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 145:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 145:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 145:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.2846, avg_loss=37.2846]Epoch 145:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.7545, avg_loss=33.7545]Epoch 145:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.7076, avg_loss=38.7076]Epoch 145:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:   0%|          | 0/11 [00:01<?, ?it/s, loss=42.1046, avg_loss=42.1046]Epoch 145:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:  55%|█████▍    | 6/11 [00:07<00:05,  1.11s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:  64%|██████▎   | 7/11 [00:08<00:04,  1.09s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  73%|███████▎  | 8/11 [00:10<00:03,  1.21s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:  73%|███████▎  | 8/11 [00:10<00:03,  1.21s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:  73%|███████▎  | 8/11 [00:10<00:03,  1.21s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:  73%|███████▎  | 8/11 [00:10<00:03,  1.21s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:  82%|████████▏ | 9/11 [00:11<00:02,  1.29s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:  82%|████████▏ | 9/11 [00:11<00:02,  1.30s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=37.2846, avg_loss=37.2846]Epoch 145:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=38.7076, avg_loss=38.7076]Epoch 145:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=33.7545, avg_loss=33.7545]Epoch 145:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=42.1046, avg_loss=42.1046]Epoch 145:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=38.7071, avg_loss=35.2682]Epoch 145: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=38.7071, avg_loss=35.2682]Epoch 145: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.7071, avg_loss=35.2682]
INFO:__main__:=== EPOCH 145 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.268212
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.773082
INFO:__main__:   • gene_density: 1.175189
INFO:__main__:   • operon_membership: 11.319941
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 145:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=34.7660, avg_loss=36.4546]Epoch 145: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=34.7660, avg_loss=36.4546]Epoch 145:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=35.2280, avg_loss=35.2982]Epoch 145: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=35.2280, avg_loss=35.2982]Epoch 145: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=34.7660, avg_loss=36.4546]
Epoch 145: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=35.2280, avg_loss=35.2982]
INFO:__main__:=== EPOCH 145 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.454605
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.154333
INFO:__main__:   • gene_density: 1.191406
INFO:__main__:   • operon_membership: 12.108867
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 145 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.298228
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.896169
INFO:__main__:   • gene_density: 1.173532
INFO:__main__:   • operon_membership: 11.228527
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 145:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=33.4696, avg_loss=36.1299]Epoch 145: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=33.4696, avg_loss=36.1299]Epoch 145: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=33.4696, avg_loss=36.1299]
INFO:__main__:=== EPOCH 145 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.129900
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.010485
INFO:__main__:   • gene_density: 1.194070
INFO:__main__:   • operon_membership: 11.925345
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.56it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.56it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.56it/s]Validation:  75%|███████▌  | 3/4 [00:02<00:00,  1.55it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.45it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
INFO:__main__:=== EPOCH 145 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:=== EPOCH 145 VALIDATION LOSSES ===
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 145 VALIDATION LOSSES ===
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
INFO:__main__:=== EPOCH 145 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 146/681
INFO:__main__:Epoch 146/681
INFO:__main__:Epoch 146/681
INFO:__main__:Epoch 146/681
Epoch 146:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 146:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 146:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 146:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 146:   0%|          | 0/11 [00:01<?, ?it/s, loss=30.0377, avg_loss=30.0377]Epoch 146:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8898, avg_loss=33.8898]Epoch 146:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7288, avg_loss=36.7288]Epoch 146:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.5895, avg_loss=33.5895]Epoch 146:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  45%|████▌     | 5/11 [00:06<00:07,  1.22s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:  45%|████▌     | 5/11 [00:06<00:07,  1.22s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:  45%|████▌     | 5/11 [00:06<00:07,  1.22s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  45%|████▌     | 5/11 [00:06<00:07,  1.22s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:  55%|█████▍    | 6/11 [00:07<00:05,  1.12s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  64%|██████▎   | 7/11 [00:09<00:04,  1.23s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:  64%|██████▎   | 7/11 [00:09<00:04,  1.23s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:  64%|██████▎   | 7/11 [00:09<00:04,  1.23s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:  64%|██████▎   | 7/11 [00:09<00:04,  1.23s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  82%|████████▏ | 9/11 [00:11<00:02,  1.33s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:  82%|████████▏ | 9/11 [00:11<00:02,  1.33s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:  82%|████████▏ | 9/11 [00:11<00:02,  1.33s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:  82%|████████▏ | 9/11 [00:11<00:02,  1.33s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  91%|█████████ | 10/11 [00:13<00:01,  1.36s/it, loss=30.0377, avg_loss=30.0377]Epoch 146:  91%|█████████ | 10/11 [00:13<00:01,  1.36s/it, loss=33.8898, avg_loss=33.8898]Epoch 146:  91%|█████████ | 10/11 [00:13<00:01,  1.36s/it, loss=36.7288, avg_loss=36.7288]Epoch 146:  91%|█████████ | 10/11 [00:13<00:01,  1.36s/it, loss=33.5895, avg_loss=33.5895]Epoch 146:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=33.4050, avg_loss=35.8376]Epoch 146: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=33.4050, avg_loss=35.8376]Epoch 146: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=33.4050, avg_loss=35.8376]
INFO:__main__:=== EPOCH 146 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.837569
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.769010
INFO:__main__:   • gene_density: 1.182055
INFO:__main__:   • operon_membership: 11.886505
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 146:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=40.2221, avg_loss=35.4866]Epoch 146: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=40.2221, avg_loss=35.4866]Epoch 146: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=40.2221, avg_loss=35.4866]
Epoch 146:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=38.5001, avg_loss=35.5611]Epoch 146: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=38.5001, avg_loss=35.5611]Epoch 146: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=38.5001, avg_loss=35.5611]
INFO:__main__:=== EPOCH 146 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.486557
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.794979
INFO:__main__:   • gene_density: 1.167910
INFO:__main__:   • operon_membership: 11.523669
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 146 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.561116
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.459389
INFO:__main__:   • gene_density: 1.186139
INFO:__main__:   • operon_membership: 11.915589
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 146:  91%|█████████ | 10/11 [00:14<00:01,  1.36s/it, loss=36.5583, avg_loss=36.2688]Epoch 146: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=36.5583, avg_loss=36.2688]Epoch 146: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=36.5583, avg_loss=36.2688]
INFO:__main__:=== EPOCH 146 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.268807
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.688104
INFO:__main__:   • gene_density: 1.193300
INFO:__main__:   • operon_membership: 11.387403
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 147/681
INFO:__main__:Epoch 147/681
INFO:__main__:Epoch 147/681
INFO:__main__:Epoch 147/681
Epoch 147:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 147:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 147:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 147:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 147:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.0527, avg_loss=37.0527]Epoch 147:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6383, avg_loss=32.6383]Epoch 147:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8366, avg_loss=35.8366]Epoch 147:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.6658, avg_loss=35.6658]Epoch 147:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  36%|███▋      | 4/11 [00:05<00:09,  1.43s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:  36%|███▋      | 4/11 [00:05<00:09,  1.43s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:  36%|███▋      | 4/11 [00:05<00:09,  1.43s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:  36%|███▋      | 4/11 [00:05<00:10,  1.43s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:  55%|█████▍    | 6/11 [00:08<00:06,  1.33s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  64%|██████▎   | 7/11 [00:09<00:04,  1.25s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:  64%|██████▎   | 7/11 [00:09<00:04,  1.25s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:  73%|███████▎  | 8/11 [00:10<00:03,  1.12s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:  73%|███████▎  | 8/11 [00:10<00:03,  1.12s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:  73%|███████▎  | 8/11 [00:10<00:03,  1.12s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  73%|███████▎  | 8/11 [00:10<00:03,  1.12s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:  82%|████████▏ | 9/11 [00:11<00:02,  1.19s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:  82%|████████▏ | 9/11 [00:11<00:02,  1.19s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:  82%|████████▏ | 9/11 [00:11<00:02,  1.19s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:  82%|████████▏ | 9/11 [00:11<00:02,  1.20s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  91%|█████████ | 10/11 [00:13<00:01,  1.28s/it, loss=32.6383, avg_loss=32.6383]Epoch 147:  91%|█████████ | 10/11 [00:13<00:01,  1.28s/it, loss=37.0527, avg_loss=37.0527]Epoch 147:  91%|█████████ | 10/11 [00:13<00:01,  1.28s/it, loss=35.8366, avg_loss=35.8366]Epoch 147:  91%|█████████ | 10/11 [00:13<00:01,  1.28s/it, loss=35.6658, avg_loss=35.6658]Epoch 147:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=30.5872, avg_loss=35.5723]Epoch 147: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=30.5872, avg_loss=35.5723]Epoch 147: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=30.5872, avg_loss=35.5723]
Epoch 147:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=34.2143, avg_loss=35.7547]Epoch 147: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=34.2143, avg_loss=35.7547]Epoch 147: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=34.2143, avg_loss=35.7547]
Epoch 147:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=33.7174, avg_loss=35.5893]Epoch 147: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=33.7174, avg_loss=35.5893]INFO:__main__:=== EPOCH 147 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.572292
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.977168
INFO:__main__:   • gene_density: 1.181226
INFO:__main__:   • operon_membership: 11.413898
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 147: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=33.7174, avg_loss=35.5893]
INFO:__main__:=== EPOCH 147 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.754736
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.385549
INFO:__main__:   • gene_density: 1.183061
INFO:__main__:   • operon_membership: 11.186126
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 147 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.589294
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.577338
INFO:__main__:   • gene_density: 1.185192
INFO:__main__:   • operon_membership: 11.826764
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 147:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=39.6507, avg_loss=36.1145]Epoch 147: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=39.6507, avg_loss=36.1145]Epoch 147: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=39.6507, avg_loss=36.1145]
INFO:__main__:=== EPOCH 147 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.114485
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.775430
INFO:__main__:   • gene_density: 1.185429
INFO:__main__:   • operon_membership: 12.153626
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 148/681
INFO:__main__:Epoch 148/681
INFO:__main__:Epoch 148/681
INFO:__main__:Epoch 148/681
Epoch 148:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 148:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 148:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 148:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 148:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.5315, avg_loss=31.5315]Epoch 148:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5140, avg_loss=35.5140]Epoch 148:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7331, avg_loss=35.7331]Epoch 148:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.6587, avg_loss=39.6587]Epoch 148:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  64%|██████▎   | 7/11 [00:10<00:05,  1.39s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:  64%|██████▎   | 7/11 [00:10<00:05,  1.39s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:  64%|██████▎   | 7/11 [00:10<00:05,  1.39s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:  64%|██████▎   | 7/11 [00:10<00:05,  1.39s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  73%|███████▎  | 8/11 [00:11<00:03,  1.33s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:  73%|███████▎  | 8/11 [00:11<00:03,  1.33s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:  73%|███████▎  | 8/11 [00:11<00:03,  1.33s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:  73%|███████▎  | 8/11 [00:11<00:03,  1.33s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  82%|████████▏ | 9/11 [00:12<00:02,  1.21s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:  82%|████████▏ | 9/11 [00:12<00:02,  1.21s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:  82%|████████▏ | 9/11 [00:12<00:02,  1.21s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  82%|████████▏ | 9/11 [00:12<00:02,  1.21s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=35.5140, avg_loss=35.5140]Epoch 148:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=31.5315, avg_loss=31.5315]Epoch 148:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=35.7331, avg_loss=35.7331]Epoch 148:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=39.6587, avg_loss=39.6587]Epoch 148:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=31.8143, avg_loss=35.4509]Epoch 148: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=31.8143, avg_loss=35.4509]Epoch 148: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=31.8143, avg_loss=35.4509]
INFO:__main__:=== EPOCH 148 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.450912
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.503334
INFO:__main__:   • gene_density: 1.186612
INFO:__main__:   • operon_membership: 11.760966
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 148:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=36.5420, avg_loss=35.6574]Epoch 148: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=36.5420, avg_loss=35.6574]Epoch 148:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=38.4199, avg_loss=35.9619]Epoch 148: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=38.4199, avg_loss=35.9619]Epoch 148: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=36.5420, avg_loss=35.6574]
Epoch 148: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=38.4199, avg_loss=35.9619]
INFO:__main__:=== EPOCH 148 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.657412
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.837188
INFO:__main__:   • gene_density: 1.180635
INFO:__main__:=== EPOCH 148 TRAINING LOSSES ===
INFO:__main__:   • operon_membership: 11.639589
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 35.961896
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.468859
INFO:__main__:   • gene_density: 1.179569
INFO:__main__:   • operon_membership: 11.313468
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 148:  91%|█████████ | 10/11 [00:14<00:01,  1.14s/it, loss=35.4202, avg_loss=35.9911]Epoch 148: 100%|██████████| 11/11 [00:14<00:00,  1.28s/it, loss=35.4202, avg_loss=35.9911]Epoch 148: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.4202, avg_loss=35.9911]
INFO:__main__:=== EPOCH 148 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.991134
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.842996
INFO:__main__:   • gene_density: 1.184600
INFO:__main__:   • operon_membership: 11.963538
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 149/681
INFO:__main__:Epoch 149/681
INFO:__main__:Epoch 149/681
INFO:__main__:Epoch 149/681
Epoch 149:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 149:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 149:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 149:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 149:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6105, avg_loss=36.6105]Epoch 149:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0617, avg_loss=36.0617]Epoch 149:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4428, avg_loss=34.4428]Epoch 149:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.3764, avg_loss=33.3764]Epoch 149:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  91%|█████████ | 10/11 [00:13<00:01,  1.29s/it, loss=36.6105, avg_loss=36.6105]Epoch 149:  91%|█████████ | 10/11 [00:13<00:01,  1.29s/it, loss=34.4428, avg_loss=34.4428]Epoch 149:  91%|█████████ | 10/11 [00:13<00:01,  1.29s/it, loss=36.0617, avg_loss=36.0617]Epoch 149:  91%|█████████ | 10/11 [00:13<00:01,  1.29s/it, loss=33.3764, avg_loss=33.3764]Epoch 149:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=33.7037, avg_loss=35.8145]Epoch 149: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=33.7037, avg_loss=35.8145]Epoch 149: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.7037, avg_loss=35.8145]
INFO:__main__:=== EPOCH 149 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.814457
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.501670
INFO:__main__:   • gene_density: 1.174657
INFO:__main__:   • operon_membership: 11.138130
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 149:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=37.8985, avg_loss=36.5994]Epoch 149: 100%|██████████| 11/11 [00:15<00:00,  1.24s/it, loss=37.8985, avg_loss=36.5994]Epoch 149:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=33.3745, avg_loss=35.8416]Epoch 149:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=35.5885, avg_loss=34.9484]Epoch 149: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=33.3745, avg_loss=35.8416]Epoch 149: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=35.5885, avg_loss=34.9484]Epoch 149: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.8985, avg_loss=36.5994]
Epoch 149: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=33.3745, avg_loss=35.8416]
Epoch 149: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.5885, avg_loss=34.9484]
INFO:__main__:=== EPOCH 149 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.599357
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.303237
INFO:__main__:   • gene_density: 1.170514
INFO:__main__:   • operon_membership: 12.125605
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 149 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.841605
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.572197
INFO:__main__:   • gene_density: 1.184955
INFO:__main__:   • operon_membership: 12.084453
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 149 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.948444
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.411630
INFO:__main__:   • gene_density: 1.201290
INFO:__main__:   • operon_membership: 11.335523
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 150/681
INFO:__main__:Epoch 150/681
INFO:__main__:Epoch 150/681
INFO:__main__:Epoch 150/681
Epoch 150:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 150:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 150:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 150:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 150:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6632, avg_loss=33.6632]Epoch 150:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6732, avg_loss=33.6732]Epoch 150:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0022, avg_loss=33.0022]Epoch 150:   9%|▉         | 1/11 [00:01<00:14,  1.46s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6474, avg_loss=33.6474]Epoch 150:   9%|▉         | 1/11 [00:01<00:14,  1.47s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  18%|█▊        | 2/11 [00:02<00:12,  1.43s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:  18%|█▊        | 2/11 [00:02<00:12,  1.43s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:  18%|█▊        | 2/11 [00:02<00:12,  1.43s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:  18%|█▊        | 2/11 [00:02<00:13,  1.45s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  36%|███▋      | 4/11 [00:05<00:09,  1.41s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:  36%|███▋      | 4/11 [00:05<00:09,  1.41s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:  36%|███▋      | 4/11 [00:05<00:09,  1.41s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:  36%|███▋      | 4/11 [00:05<00:09,  1.41s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  55%|█████▍    | 6/11 [00:08<00:07,  1.40s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:  55%|█████▍    | 6/11 [00:08<00:07,  1.40s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:  55%|█████▍    | 6/11 [00:08<00:07,  1.40s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:  73%|███████▎  | 8/11 [00:11<00:04,  1.39s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=33.6732, avg_loss=33.6732]Epoch 150:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=33.6632, avg_loss=33.6632]Epoch 150:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=33.0022, avg_loss=33.0022]Epoch 150:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=33.6474, avg_loss=33.6474]Epoch 150:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=31.2125, avg_loss=35.2681]Epoch 150: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=31.2125, avg_loss=35.2681]Epoch 150: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=31.2125, avg_loss=35.2681]
INFO:__main__:=== EPOCH 150 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.268106
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.579117
INFO:__main__:   • gene_density: 1.176787
INFO:__main__:   • operon_membership: 11.512202
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 150:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=36.4522, avg_loss=36.6571]Epoch 150: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=36.4522, avg_loss=36.6571]Epoch 150: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=36.4522, avg_loss=36.6571]
INFO:__main__:=== EPOCH 150 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.657145
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.463473
INFO:__main__:   • gene_density: 1.181167
INFO:__main__:   • operon_membership: 12.012505
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 150:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=36.7363, avg_loss=35.7070]Epoch 150: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=36.7363, avg_loss=35.7070]Epoch 150: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=36.7363, avg_loss=35.7070]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 150 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.707002
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.904950
Epoch 150:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=37.9286, avg_loss=35.3924]INFO:__main__:   • gene_density: 1.192472
INFO:__main__:   • operon_membership: 11.609581
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 150: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=37.9286, avg_loss=35.3924]Epoch 150: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=37.9286, avg_loss=35.3924]
INFO:__main__:=== EPOCH 150 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.392357
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.679771
INFO:__main__:   • gene_density: 1.183831
INFO:__main__:   • operon_membership: 11.528755
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.39it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.40it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.41it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.39it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.79it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.78it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.79it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.77it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.95it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.95it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.96it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.95it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.83it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.83it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.83it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.84it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.80it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.80it/s]

Validation: 100%|██████████| 4/4 [00:02<00:00,  1.80it/s]
INFO:__main__:=== EPOCH 150 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 150 VALIDATION LOSSES ===
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.81it/s]
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:=== EPOCH 150 VALIDATION LOSSES ===
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:=== EPOCH 150 VALIDATION LOSSES ===
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:========================================
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_150.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_150.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_150.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_150.pt
INFO:__main__:Epoch 151/681
INFO:__main__:Epoch 151/681
INFO:__main__:Epoch 151/681
INFO:__main__:Epoch 151/681
Epoch 151:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 151:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 151:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 151:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 151:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3125, avg_loss=34.3125]Epoch 151:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=34.3125, avg_loss=34.3125]Epoch 151:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.3867, avg_loss=37.3867]Epoch 151:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=37.3867, avg_loss=37.3867]Epoch 151:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3124, avg_loss=34.3124]Epoch 151:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=34.3124, avg_loss=34.3124]Epoch 151:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4883, avg_loss=35.4883]Epoch 151:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=35.4883, avg_loss=35.4883]Epoch 151:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=34.3125, avg_loss=34.3125]Epoch 151:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=37.3867, avg_loss=37.3867]Epoch 151:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=34.3124, avg_loss=34.3124]Epoch 151:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=35.4883, avg_loss=35.4883]Epoch 151:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=35.4883, avg_loss=35.4883]Epoch 151:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=34.3125, avg_loss=34.3125]Epoch 151:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=37.3867, avg_loss=37.3867]Epoch 151:  27%|██▋       | 3/11 [00:03<00:09,  1.24s/it, loss=34.3124, avg_loss=34.3124]Epoch 151:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=35.4883, avg_loss=35.4883]Epoch 151:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=34.3125, avg_loss=34.3125]Epoch 151:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=37.3867, avg_loss=37.3867]Epoch 151:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=34.3124, avg_loss=34.3124]Epoch 151:  45%|████▌     | 5/11 [00:05<00:06,  1.10s/it, loss=34.3125, avg_loss=34.3125]Epoch 151:  45%|████▌     | 5/11 [00:05<00:06,  1.10s/it, loss=37.3867, avg_loss=37.3867]Epoch 151:  45%|████▌     | 5/11 [00:05<00:06,  1.10s/it, loss=34.3124, avg_loss=34.3124]Epoch 151:  45%|████▌     | 5/11 [00:05<00:06,  1.10s/it, loss=35.4883, avg_loss=35.4883]Epoch 151:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=34.3125, avg_loss=34.3125]Epoch 151:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=37.3867, avg_loss=37.3867]Epoch 151:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=34.3124, avg_loss=34.3124]Epoch 151:  55%|█████▍    | 6/11 [00:07<00:05,  1.13s/it, loss=35.4883, avg_loss=35.4883]Epoch 151:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=34.3125, avg_loss=34.3125]Epoch 151:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=34.3124, avg_loss=34.3124]Epoch 151:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=37.3867, avg_loss=37.3867]Epoch 151:  64%|██████▎   | 7/11 [00:08<00:04,  1.08s/it, loss=35.4883, avg_loss=35.4883]Epoch 151:  73%|███████▎  | 8/11 [00:08<00:03,  1.00s/it, loss=34.3125, avg_loss=34.3125]Epoch 151:  73%|███████▎  | 8/11 [00:08<00:03,  1.00s/it, loss=35.4883, avg_loss=35.4883]Epoch 151:  73%|███████▎  | 8/11 [00:08<00:03,  1.00s/it, loss=37.3867, avg_loss=37.3867]Epoch 151:  73%|███████▎  | 8/11 [00:08<00:03,  1.00s/it, loss=34.3124, avg_loss=34.3124]Epoch 151:  82%|████████▏ | 9/11 [00:09<00:01,  1.05it/s, loss=34.3125, avg_loss=34.3125]Epoch 151:  82%|████████▏ | 9/11 [00:09<00:01,  1.05it/s, loss=35.4883, avg_loss=35.4883]Epoch 151:  82%|████████▏ | 9/11 [00:09<00:01,  1.05it/s, loss=37.3867, avg_loss=37.3867]Epoch 151:  82%|████████▏ | 9/11 [00:09<00:01,  1.05it/s, loss=34.3124, avg_loss=34.3124]Epoch 151:  91%|█████████ | 10/11 [00:10<00:00,  1.09it/s, loss=35.4883, avg_loss=35.4883]Epoch 151:  91%|█████████ | 10/11 [00:10<00:00,  1.09it/s, loss=34.3125, avg_loss=34.3125]Epoch 151:  91%|█████████ | 10/11 [00:10<00:00,  1.09it/s, loss=37.3867, avg_loss=37.3867]Epoch 151:  91%|█████████ | 10/11 [00:10<00:00,  1.09it/s, loss=34.3124, avg_loss=34.3124]Epoch 151:  91%|█████████ | 10/11 [00:11<00:00,  1.09it/s, loss=33.9211, avg_loss=36.4114]Epoch 151: 100%|██████████| 11/11 [00:11<00:00,  1.05it/s, loss=33.9211, avg_loss=36.4114]Epoch 151: 100%|██████████| 11/11 [00:11<00:00,  1.06s/it, loss=33.9211, avg_loss=36.4114]
INFO:__main__:=== EPOCH 151 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.411431
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.413428
INFO:__main__:   • gene_density: 1.193063
INFO:__main__:   • operon_membership: 11.804939
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 151:  91%|█████████ | 10/11 [00:11<00:00,  1.09it/s, loss=32.1934, avg_loss=35.3197]Epoch 151: 100%|██████████| 11/11 [00:11<00:00,  1.04it/s, loss=32.1934, avg_loss=35.3197]Epoch 151:  91%|█████████ | 10/11 [00:11<00:00,  1.09it/s, loss=34.4262, avg_loss=35.6400]Epoch 151: 100%|██████████| 11/11 [00:11<00:00,  1.05it/s, loss=34.4262, avg_loss=35.6400]Epoch 151: 100%|██████████| 11/11 [00:11<00:00,  1.06s/it, loss=32.1934, avg_loss=35.3197]
Epoch 151: 100%|██████████| 11/11 [00:11<00:00,  1.06s/it, loss=34.4262, avg_loss=35.6400]
Epoch 151:  91%|█████████ | 10/11 [00:11<00:00,  1.09it/s, loss=33.3382, avg_loss=35.8909]Epoch 151: 100%|██████████| 11/11 [00:11<00:00,  1.05it/s, loss=33.3382, avg_loss=35.8909]INFO:__main__:=== EPOCH 151 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.319709
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.336805
INFO:__main__:   • gene_density: 1.168857
INFO:__main__:   • operon_membership: 11.814048
INFO:__main__:👥 Samples processed: 22
Epoch 151: 100%|██████████| 11/11 [00:11<00:00,  1.06s/it, loss=33.3382, avg_loss=35.8909]INFO:__main__:========================================

INFO:__main__:=== EPOCH 151 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.639955
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.657609
INFO:__main__:   • gene_density: 1.181759
INFO:__main__:   • operon_membership: 10.800587
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 151 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.890865
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.376618
INFO:__main__:   • gene_density: 1.186671
INFO:__main__:   • operon_membership: 12.327576
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 152/681
INFO:__main__:Epoch 152/681
INFO:__main__:Epoch 152/681
INFO:__main__:Epoch 152/681
Epoch 152:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 152:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 152:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 152:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 152:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1138, avg_loss=36.1138]Epoch 152:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=36.1138, avg_loss=36.1138]Epoch 152:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9980, avg_loss=35.9980]Epoch 152:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=35.9980, avg_loss=35.9980]Epoch 152:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9052, avg_loss=35.9052]Epoch 152:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6976, avg_loss=37.6976]Epoch 152:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=35.9052, avg_loss=35.9052]Epoch 152:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=37.6976, avg_loss=37.6976]Epoch 152:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=36.1138, avg_loss=36.1138]Epoch 152:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=37.6976, avg_loss=37.6976]Epoch 152:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=35.9980, avg_loss=35.9980]Epoch 152:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=35.9052, avg_loss=35.9052]Epoch 152:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=37.6976, avg_loss=37.6976]Epoch 152:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=36.1138, avg_loss=36.1138]Epoch 152:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=35.9980, avg_loss=35.9980]Epoch 152:  27%|██▋       | 3/11 [00:02<00:07,  1.11it/s, loss=35.9052, avg_loss=35.9052]Epoch 152:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=35.9980, avg_loss=35.9980]Epoch 152:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=37.6976, avg_loss=37.6976]Epoch 152:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=35.9052, avg_loss=35.9052]Epoch 152:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=36.1138, avg_loss=36.1138]Epoch 152:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, loss=37.6976, avg_loss=37.6976]Epoch 152:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, loss=35.9052, avg_loss=35.9052]Epoch 152:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, loss=35.9980, avg_loss=35.9980]Epoch 152:  45%|████▌     | 5/11 [00:04<00:05,  1.15it/s, loss=36.1138, avg_loss=36.1138]Epoch 152:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, loss=37.6976, avg_loss=37.6976]Epoch 152:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, loss=35.9052, avg_loss=35.9052]Epoch 152:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, loss=36.1138, avg_loss=36.1138]Epoch 152:  55%|█████▍    | 6/11 [00:05<00:04,  1.14it/s, loss=35.9980, avg_loss=35.9980]Epoch 152:  64%|██████▎   | 7/11 [00:06<00:04,  1.04s/it, loss=37.6976, avg_loss=37.6976]Epoch 152:  64%|██████▎   | 7/11 [00:06<00:04,  1.04s/it, loss=35.9052, avg_loss=35.9052]Epoch 152:  64%|██████▎   | 7/11 [00:06<00:04,  1.04s/it, loss=35.9980, avg_loss=35.9980]Epoch 152:  64%|██████▎   | 7/11 [00:06<00:04,  1.05s/it, loss=36.1138, avg_loss=36.1138]Epoch 152:  73%|███████▎  | 8/11 [00:08<00:03,  1.16s/it, loss=37.6976, avg_loss=37.6976]Epoch 152:  73%|███████▎  | 8/11 [00:08<00:03,  1.16s/it, loss=35.9980, avg_loss=35.9980]Epoch 152:  73%|███████▎  | 8/11 [00:08<00:03,  1.16s/it, loss=35.9052, avg_loss=35.9052]Epoch 152:  73%|███████▎  | 8/11 [00:08<00:03,  1.16s/it, loss=36.1138, avg_loss=36.1138]Epoch 152:  82%|████████▏ | 9/11 [00:09<00:02,  1.24s/it, loss=35.9052, avg_loss=35.9052]Epoch 152:  82%|████████▏ | 9/11 [00:09<00:02,  1.24s/it, loss=35.9980, avg_loss=35.9980]Epoch 152:  82%|████████▏ | 9/11 [00:09<00:02,  1.24s/it, loss=37.6976, avg_loss=37.6976]Epoch 152:  82%|████████▏ | 9/11 [00:09<00:02,  1.24s/it, loss=36.1138, avg_loss=36.1138]Epoch 152:  91%|█████████ | 10/11 [00:11<00:01,  1.29s/it, loss=37.6976, avg_loss=37.6976]Epoch 152:  91%|█████████ | 10/11 [00:11<00:01,  1.29s/it, loss=35.9980, avg_loss=35.9980]Epoch 152:  91%|█████████ | 10/11 [00:11<00:01,  1.29s/it, loss=35.9052, avg_loss=35.9052]Epoch 152:  91%|█████████ | 10/11 [00:11<00:01,  1.29s/it, loss=36.1138, avg_loss=36.1138]Epoch 152:  91%|█████████ | 10/11 [00:12<00:01,  1.29s/it, loss=36.5019, avg_loss=35.7432]Epoch 152: 100%|██████████| 11/11 [00:12<00:00,  1.37s/it, loss=36.5019, avg_loss=35.7432]Epoch 152: 100%|██████████| 11/11 [00:12<00:00,  1.14s/it, loss=36.5019, avg_loss=35.7432]
Epoch 152:  91%|█████████ | 10/11 [00:12<00:01,  1.29s/it, loss=35.6275, avg_loss=35.9862]Epoch 152: 100%|██████████| 11/11 [00:12<00:00,  1.37s/it, loss=35.6275, avg_loss=35.9862]INFO:__main__:=== EPOCH 152 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.743217
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.275525
INFO:__main__:   • gene_density: 1.187974
INFO:__main__:   • operon_membership: 12.279719
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 152: 100%|██████████| 11/11 [00:12<00:00,  1.14s/it, loss=35.6275, avg_loss=35.9862]
INFO:__main__:=== EPOCH 152 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.986172
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.297788
INFO:__main__:   • gene_density: 1.186494
INFO:__main__:   • operon_membership: 11.501891
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 152:  91%|█████████ | 10/11 [00:12<00:01,  1.29s/it, loss=39.5572, avg_loss=36.2332]Epoch 152: 100%|██████████| 11/11 [00:12<00:00,  1.37s/it, loss=39.5572, avg_loss=36.2332]Epoch 152: 100%|██████████| 11/11 [00:12<00:00,  1.14s/it, loss=39.5572, avg_loss=36.2332]
INFO:__main__:=== EPOCH 152 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.233190
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.879431
INFO:__main__:   • gene_density: 1.176551
INFO:__main__:   • operon_membership: 12.177208
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 152:  91%|█████████ | 10/11 [00:12<00:01,  1.29s/it, loss=32.8607, avg_loss=35.1806]Epoch 152: 100%|██████████| 11/11 [00:12<00:00,  1.37s/it, loss=32.8607, avg_loss=35.1806]Epoch 152: 100%|██████████| 11/11 [00:12<00:00,  1.14s/it, loss=32.8607, avg_loss=35.1806]
INFO:__main__:=== EPOCH 152 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.180627
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.307778
INFO:__main__:   • gene_density: 1.181108
INFO:__main__:   • operon_membership: 10.691741
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 153/681
INFO:__main__:Epoch 153/681
INFO:__main__:Epoch 153/681
INFO:__main__:Epoch 153/681
Epoch 153:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 153:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 153:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 153:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 153:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9815, avg_loss=35.9815]Epoch 153:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2748, avg_loss=34.2748]Epoch 153:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3493, avg_loss=35.3493]Epoch 153:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2828, avg_loss=35.2828]Epoch 153:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:  18%|█▊        | 2/11 [00:03<00:13,  1.49s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:  18%|█▊        | 2/11 [00:03<00:13,  1.50s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:  82%|████████▏ | 9/11 [00:11<00:02,  1.09s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:  82%|████████▏ | 9/11 [00:11<00:02,  1.09s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:  82%|████████▏ | 9/11 [00:11<00:02,  1.09s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:  82%|████████▏ | 9/11 [00:11<00:02,  1.09s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  91%|█████████ | 10/11 [00:12<00:01,  1.19s/it, loss=35.3493, avg_loss=35.3493]Epoch 153:  91%|█████████ | 10/11 [00:12<00:01,  1.19s/it, loss=34.2748, avg_loss=34.2748]Epoch 153:  91%|█████████ | 10/11 [00:12<00:01,  1.19s/it, loss=35.9815, avg_loss=35.9815]Epoch 153:  91%|█████████ | 10/11 [00:12<00:01,  1.19s/it, loss=35.2828, avg_loss=35.2828]Epoch 153:  91%|█████████ | 10/11 [00:14<00:01,  1.19s/it, loss=37.5734, avg_loss=36.0704]Epoch 153: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=37.5734, avg_loss=36.0704]Epoch 153: 100%|██████████| 11/11 [00:14<00:00,  1.30s/it, loss=37.5734, avg_loss=36.0704]
INFO:__main__:=== EPOCH 153 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.070412
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.632578
INFO:__main__:   • gene_density: 1.174953
INFO:__main__:   • operon_membership: 11.262882
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 153:  91%|█████████ | 10/11 [00:14<00:01,  1.19s/it, loss=36.4889, avg_loss=35.7305]Epoch 153: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=36.4889, avg_loss=35.7305]Epoch 153: 100%|██████████| 11/11 [00:14<00:00,  1.30s/it, loss=36.4889, avg_loss=35.7305]
INFO:__main__:=== EPOCH 153 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.730485
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.708846
INFO:__main__:   • gene_density: 1.183594
INFO:__main__:   • operon_membership: 11.838046
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 153:  91%|█████████ | 10/11 [00:14<00:01,  1.19s/it, loss=40.6554, avg_loss=35.5776]Epoch 153: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=40.6554, avg_loss=35.5776]Epoch 153: 100%|██████████| 11/11 [00:14<00:00,  1.30s/it, loss=40.6554, avg_loss=35.5776]
INFO:__main__:=== EPOCH 153 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.577602
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.245626
INFO:__main__:   • gene_density: 1.180575
INFO:__main__:   • operon_membership: 11.151401
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 153:  91%|█████████ | 10/11 [00:14<00:01,  1.19s/it, loss=34.3771, avg_loss=35.6150]Epoch 153: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=34.3771, avg_loss=35.6150]Epoch 153: 100%|██████████| 11/11 [00:14<00:00,  1.30s/it, loss=34.3771, avg_loss=35.6150]
INFO:__main__:=== EPOCH 153 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.614952
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.166650
INFO:__main__:   • gene_density: 1.193182
INFO:__main__:   • operon_membership: 12.255120
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 154/681
INFO:__main__:Epoch 154/681
INFO:__main__:Epoch 154/681
INFO:__main__:Epoch 154/681
Epoch 154:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 154:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 154:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 154:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 154:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.7347, avg_loss=39.7347]Epoch 154:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.4149, avg_loss=38.4149]Epoch 154:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0961, avg_loss=34.0961]Epoch 154:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.1188, avg_loss=39.1188]Epoch 154:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:  64%|██████▎   | 7/11 [00:10<00:05,  1.43s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  73%|███████▎  | 8/11 [00:11<00:04,  1.38s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:  73%|███████▎  | 8/11 [00:11<00:04,  1.37s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  73%|███████▎  | 8/11 [00:11<00:04,  1.38s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:  73%|███████▎  | 8/11 [00:11<00:04,  1.38s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=38.4149, avg_loss=38.4149]Epoch 154:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=39.1188, avg_loss=39.1188]Epoch 154:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=39.7347, avg_loss=39.7347]Epoch 154:  91%|█████████ | 10/11 [00:13<00:01,  1.23s/it, loss=34.0961, avg_loss=34.0961]Epoch 154:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=37.8389, avg_loss=36.5678]Epoch 154: 100%|██████████| 11/11 [00:14<00:00,  1.21s/it, loss=37.8389, avg_loss=36.5678]Epoch 154:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=34.1584, avg_loss=35.8784]Epoch 154: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=37.8389, avg_loss=36.5678]Epoch 154: 100%|██████████| 11/11 [00:14<00:00,  1.21s/it, loss=34.1584, avg_loss=35.8784]
Epoch 154: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.1584, avg_loss=35.8784]
INFO:__main__:=== EPOCH 154 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.567795
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.394839
INFO:__main__:   • gene_density: 1.178622
INFO:__main__:   • operon_membership: 11.994333
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 154 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.878350
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.063414
INFO:__main__:   • gene_density: 1.193241
INFO:__main__:   • operon_membership: 11.621695
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 154:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=35.6228, avg_loss=34.8099]Epoch 154: 100%|██████████| 11/11 [00:14<00:00,  1.21s/it, loss=35.6228, avg_loss=34.8099]Epoch 154: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.6228, avg_loss=34.8099]
INFO:__main__:=== EPOCH 154 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.809913
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.272547
INFO:__main__:   • gene_density: 1.178030
INFO:__main__:   • operon_membership: 11.359337
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 154:  91%|█████████ | 10/11 [00:14<00:01,  1.23s/it, loss=34.5626, avg_loss=35.6771]Epoch 154: 100%|██████████| 11/11 [00:14<00:00,  1.21s/it, loss=34.5626, avg_loss=35.6771]Epoch 154: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.5626, avg_loss=35.6771]
INFO:__main__:=== EPOCH 154 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.677065
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.709778
INFO:__main__:   • gene_density: 1.181167
INFO:__main__:   • operon_membership: 11.786120
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 155/681
INFO:__main__:Epoch 155/681
INFO:__main__:Epoch 155/681
INFO:__main__:Epoch 155/681
Epoch 155:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 155:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 155:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 155:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 155:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7535, avg_loss=37.7535]Epoch 155:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6146, avg_loss=37.6146]Epoch 155:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9612, avg_loss=33.9612]Epoch 155:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5171, avg_loss=35.5171]Epoch 155:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:  82%|████████▏ | 9/11 [00:13<00:02,  1.44s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=37.7535, avg_loss=37.7535]Epoch 155:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=37.6146, avg_loss=37.6146]Epoch 155:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=33.9612, avg_loss=33.9612]Epoch 155:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.5171, avg_loss=35.5171]Epoch 155:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=36.0249, avg_loss=35.1810]Epoch 155: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=36.0249, avg_loss=35.1810]Epoch 155: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=36.0249, avg_loss=35.1810]
INFO:__main__:=== EPOCH 155 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.181025
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.853689
INFO:__main__:   • gene_density: 1.173710
INFO:__main__:   • operon_membership: 12.153626
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 155:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=35.6493, avg_loss=35.1536]Epoch 155: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=35.6493, avg_loss=35.1536]Epoch 155: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=35.6493, avg_loss=35.1536]
Epoch 155:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=39.5769, avg_loss=37.2275]Epoch 155: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=39.5769, avg_loss=37.2275]Epoch 155: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=39.5769, avg_loss=37.2275]
Epoch 155:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=38.5915, avg_loss=35.4858]Epoch 155: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=38.5915, avg_loss=35.4858]INFO:__main__:=== EPOCH 155 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.153579
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.345075
INFO:__main__:   • gene_density: 1.179688
INFO:__main__:   • operon_membership: 11.628816
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 155: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=38.5915, avg_loss=35.4858]
INFO:__main__:=== EPOCH 155 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 37.227454
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.879878
INFO:__main__:   • gene_density: 1.185724
INFO:__main__:   • operon_membership: 11.161851
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 155 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.485775
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.576970
INFO:__main__:   • gene_density: 1.193892
INFO:__main__:   • operon_membership: 11.714913
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.64it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.63it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.64it/s]Validation:  25%|██▌       | 1/4 [00:00<00:01,  1.62it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.22it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.22it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.21it/s]Validation:  50%|█████     | 2/4 [00:00<00:00,  2.22it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.21it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.21it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.20it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.14it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.76it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.76it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.76it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]

Validation: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]INFO:__main__:=== EPOCH 155 VALIDATION LOSSES ===

INFO:__main__:=== EPOCH 155 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 155 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.74it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.84it/s]
INFO:__main__:=== EPOCH 155 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 156/681
INFO:__main__:Epoch 156/681
INFO:__main__:Epoch 156/681
INFO:__main__:Epoch 156/681
Epoch 156:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 156:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 156:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 156:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 156:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6545, avg_loss=37.6545]Epoch 156:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.2215, avg_loss=38.2215]Epoch 156:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:   0%|          | 0/11 [00:01<?, ?it/s, loss=40.1673, avg_loss=40.1673]Epoch 156:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7584, avg_loss=37.7584]Epoch 156:   9%|▉         | 1/11 [00:01<00:17,  1.77s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  18%|█▊        | 2/11 [00:03<00:14,  1.58s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:  18%|█▊        | 2/11 [00:03<00:14,  1.59s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:  27%|██▋       | 3/11 [00:04<00:12,  1.54s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:  36%|███▋      | 4/11 [00:06<00:10,  1.51s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:  36%|███▋      | 4/11 [00:06<00:10,  1.52s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  45%|████▌     | 5/11 [00:07<00:08,  1.50s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:  45%|████▌     | 5/11 [00:07<00:09,  1.50s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:  55%|█████▍    | 6/11 [00:09<00:07,  1.50s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  64%|██████▎   | 7/11 [00:10<00:05,  1.50s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:  64%|██████▎   | 7/11 [00:10<00:05,  1.50s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:  64%|██████▎   | 7/11 [00:10<00:05,  1.50s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:  64%|██████▎   | 7/11 [00:10<00:05,  1.50s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:  73%|███████▎  | 8/11 [00:12<00:04,  1.47s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  82%|████████▏ | 9/11 [00:13<00:02,  1.37s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:  82%|████████▏ | 9/11 [00:13<00:02,  1.37s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:  82%|████████▏ | 9/11 [00:13<00:02,  1.37s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  82%|████████▏ | 9/11 [00:13<00:02,  1.37s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=38.2215, avg_loss=38.2215]Epoch 156:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=40.1673, avg_loss=40.1673]Epoch 156:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=37.7584, avg_loss=37.7584]Epoch 156:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=37.6545, avg_loss=37.6545]Epoch 156:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=33.4199, avg_loss=35.6323]Epoch 156: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=33.4199, avg_loss=35.6323]Epoch 156: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.4199, avg_loss=35.6323]
INFO:__main__:=== EPOCH 156 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.632266
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.626326
INFO:__main__:   • gene_density: 1.187263
INFO:__main__:   • operon_membership: 12.818678
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 156:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=38.5038, avg_loss=35.7458]Epoch 156: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=38.5038, avg_loss=35.7458]Epoch 156: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=38.5038, avg_loss=35.7458]
Epoch 156:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=36.4280, avg_loss=36.0178]Epoch 156: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=36.4280, avg_loss=36.0178]Epoch 156:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=35.9774, avg_loss=35.4608]Epoch 156: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=35.9774, avg_loss=35.4608]Epoch 156: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=36.4280, avg_loss=36.0178]
INFO:__main__:=== EPOCH 156 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.745820
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.271487
INFO:__main__:   • gene_density: 1.164240
INFO:__main__:   • operon_membership: 11.310092
Epoch 156: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=35.9774, avg_loss=35.4608]INFO:__main__:👥 Samples processed: 22

INFO:__main__:========================================
INFO:__main__:=== EPOCH 156 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.017844
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.186728
INFO:__main__:   • gene_density: 1.194070
INFO:__main__:   • operon_membership: 11.637046
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 156 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.460781
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.534618
INFO:__main__:   • gene_density: 1.187027
INFO:__main__:   • operon_membership: 10.739136
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 157/681
INFO:__main__:Epoch 157/681
INFO:__main__:Epoch 157/681
INFO:__main__:Epoch 157/681
Epoch 157:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 157:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 157:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 157:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 157:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1568, avg_loss=36.1568]Epoch 157:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.6434, avg_loss=34.6434]Epoch 157:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8230, avg_loss=33.8230]Epoch 157:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9675, avg_loss=33.9675]Epoch 157:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:  18%|█▊        | 2/11 [00:02<00:12,  1.43s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:  27%|██▋       | 3/11 [00:04<00:11,  1.42s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:  36%|███▋      | 4/11 [00:05<00:09,  1.42s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:  45%|████▌     | 5/11 [00:07<00:08,  1.42s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:  73%|███████▎  | 8/11 [00:11<00:04,  1.40s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:  82%|████████▏ | 9/11 [00:12<00:02,  1.41s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=34.6434, avg_loss=34.6434]Epoch 157:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=36.1568, avg_loss=36.1568]Epoch 157:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=33.8230, avg_loss=33.8230]Epoch 157:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=33.9675, avg_loss=33.9675]Epoch 157:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=30.9097, avg_loss=35.2530]Epoch 157: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=30.9097, avg_loss=35.2530]Epoch 157: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=30.9097, avg_loss=35.2530]
INFO:__main__:=== EPOCH 157 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.253028
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.856741
INFO:__main__:   • gene_density: 1.188151
INFO:__main__:   • operon_membership: 11.208136
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 157:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.5049, avg_loss=36.4511]Epoch 157: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.5049, avg_loss=36.4511]Epoch 157: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.5049, avg_loss=36.4511]
INFO:__main__:=== EPOCH 157 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.451084
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.227504
INFO:__main__:   • gene_density: 1.183475
INFO:__main__:   • operon_membership: 11.040104
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 157:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=34.6460, avg_loss=35.0600]Epoch 157: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=34.6460, avg_loss=35.0600]Epoch 157: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=34.6460, avg_loss=35.0600]
INFO:__main__:=== EPOCH 157 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.060016
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.608744
INFO:__main__:   • gene_density: 1.187737
INFO:__main__:   • operon_membership: 12.263535
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 157:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.9581, avg_loss=36.3868]Epoch 157: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.9581, avg_loss=36.3868]Epoch 157: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.9581, avg_loss=36.3868]
INFO:__main__:=== EPOCH 157 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.386816
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.141077
INFO:__main__:   • gene_density: 1.174834
INFO:__main__:   • operon_membership: 12.070905
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 158/681
INFO:__main__:Epoch 158/681
INFO:__main__:Epoch 158/681
INFO:__main__:Epoch 158/681
Epoch 158:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 158:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 158:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 158:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 158:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.8779, avg_loss=39.8779]Epoch 158:   9%|▉         | 1/11 [00:01<00:14,  1.40s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.0055, avg_loss=38.0055]Epoch 158:   9%|▉         | 1/11 [00:01<00:14,  1.41s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.4752, avg_loss=37.4752]Epoch 158:   9%|▉         | 1/11 [00:01<00:14,  1.41s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1253, avg_loss=38.1253]Epoch 158:   9%|▉         | 1/11 [00:01<00:14,  1.41s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  18%|█▊        | 2/11 [00:02<00:10,  1.17s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:  18%|█▊        | 2/11 [00:02<00:10,  1.17s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:  18%|█▊        | 2/11 [00:02<00:10,  1.17s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  18%|█▊        | 2/11 [00:02<00:10,  1.17s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:  27%|██▋       | 3/11 [00:03<00:08,  1.01s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:  27%|██▋       | 3/11 [00:03<00:08,  1.02s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  27%|██▋       | 3/11 [00:03<00:08,  1.02s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:  27%|██▋       | 3/11 [00:03<00:08,  1.02s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:  36%|███▋      | 4/11 [00:04<00:07,  1.14s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:  36%|███▋      | 4/11 [00:04<00:07,  1.14s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  36%|███▋      | 4/11 [00:04<00:07,  1.14s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:  36%|███▋      | 4/11 [00:04<00:08,  1.15s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:  45%|████▌     | 5/11 [00:06<00:07,  1.25s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  45%|████▌     | 5/11 [00:06<00:07,  1.26s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  55%|█████▍    | 6/11 [00:07<00:06,  1.31s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:  64%|██████▎   | 7/11 [00:08<00:05,  1.35s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:  64%|██████▎   | 7/11 [00:08<00:05,  1.35s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:  64%|██████▎   | 7/11 [00:08<00:05,  1.35s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  64%|██████▎   | 7/11 [00:08<00:05,  1.36s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  82%|████████▏ | 9/11 [00:11<00:02,  1.40s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=39.8779, avg_loss=39.8779]Epoch 158:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=38.0055, avg_loss=38.0055]Epoch 158:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=38.1253, avg_loss=38.1253]Epoch 158:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=37.4752, avg_loss=37.4752]Epoch 158:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.2714, avg_loss=36.6166]Epoch 158: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.2714, avg_loss=36.6166]Epoch 158: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.2714, avg_loss=36.6166]
Epoch 158:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.2977, avg_loss=36.5107]Epoch 158: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.2977, avg_loss=36.5107]Epoch 158: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.2977, avg_loss=36.5107]
INFO:__main__:=== EPOCH 158 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.616570
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.126856
INFO:__main__:   • gene_density: 1.187204
INFO:__main__:   • operon_membership: 11.302509
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 158:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.2581, avg_loss=35.2507]Epoch 158: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.2581, avg_loss=35.2507]INFO:__main__:=== EPOCH 158 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.510689
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.376938
INFO:__main__:   • gene_density: 1.178859
INFO:__main__:   • operon_membership: 11.954892
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 158: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.2581, avg_loss=35.2507]
INFO:__main__:=== EPOCH 158 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.250696
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.120835
INFO:__main__:   • gene_density: 1.175663
INFO:__main__:   • operon_membership: 11.954198
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 158:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=33.7800, avg_loss=34.5992]Epoch 158: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=33.7800, avg_loss=34.5992]Epoch 158: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=33.7800, avg_loss=34.5992]
INFO:__main__:=== EPOCH 158 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.599206
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.875345
INFO:__main__:   • gene_density: 1.189927
INFO:__main__:   • operon_membership: 11.533934
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 159/681
INFO:__main__:Epoch 159/681
INFO:__main__:Epoch 159/681
INFO:__main__:Epoch 159/681
Epoch 159:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 159:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 159:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 159:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 159:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9024, avg_loss=36.9024]Epoch 159:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5302, avg_loss=35.5302]Epoch 159:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4732, avg_loss=36.4732]Epoch 159:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.4863, avg_loss=39.4863]Epoch 159:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  18%|█▊        | 2/11 [00:02<00:13,  1.45s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:  18%|█▊        | 2/11 [00:02<00:13,  1.45s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:  18%|█▊        | 2/11 [00:02<00:13,  1.45s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:  18%|█▊        | 2/11 [00:02<00:13,  1.45s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  36%|███▋      | 4/11 [00:05<00:08,  1.19s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:  36%|███▋      | 4/11 [00:05<00:08,  1.18s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  36%|███▋      | 4/11 [00:05<00:08,  1.19s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:  36%|███▋      | 4/11 [00:05<00:08,  1.19s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:  45%|████▌     | 5/11 [00:06<00:06,  1.10s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:  45%|████▌     | 5/11 [00:06<00:06,  1.10s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:  45%|████▌     | 5/11 [00:06<00:06,  1.10s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:  45%|████▌     | 5/11 [00:06<00:06,  1.11s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:  55%|█████▍    | 6/11 [00:07<00:06,  1.22s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:  55%|█████▍    | 6/11 [00:07<00:06,  1.22s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:  55%|█████▍    | 6/11 [00:07<00:06,  1.22s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  64%|██████▎   | 7/11 [00:08<00:05,  1.29s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:  64%|██████▎   | 7/11 [00:08<00:05,  1.29s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:  64%|██████▎   | 7/11 [00:08<00:05,  1.29s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:  64%|██████▎   | 7/11 [00:08<00:05,  1.30s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:  73%|███████▎  | 8/11 [00:10<00:04,  1.35s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=35.5302, avg_loss=35.5302]Epoch 159:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=36.9024, avg_loss=36.9024]Epoch 159:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=36.4732, avg_loss=36.4732]Epoch 159:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=39.4863, avg_loss=39.4863]Epoch 159:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=41.5234, avg_loss=35.5729]Epoch 159: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=41.5234, avg_loss=35.5729]Epoch 159:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=33.7792, avg_loss=35.4053]Epoch 159: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=41.5234, avg_loss=35.5729]
Epoch 159: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=33.7792, avg_loss=35.4053]Epoch 159: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=33.7792, avg_loss=35.4053]
Epoch 159:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=37.5138, avg_loss=36.0187]Epoch 159: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=37.5138, avg_loss=36.0187]INFO:__main__:=== EPOCH 159 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.572859
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.030149
INFO:__main__:   • gene_density: 1.164832
INFO:__main__:   • operon_membership: 11.377878
Epoch 159: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=37.5138, avg_loss=36.0187]INFO:__main__:👥 Samples processed: 22

INFO:__main__:========================================
INFO:__main__:=== EPOCH 159 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.405328
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.295521
INFO:__main__:   • gene_density: 1.193063
INFO:__main__:   • operon_membership: 11.916745
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 159 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.018748
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.299244
INFO:__main__:   • gene_density: 1.195372
INFO:__main__:   • operon_membership: 11.524132
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 159:  91%|█████████ | 10/11 [00:14<00:01,  1.39s/it, loss=35.9777, avg_loss=36.1134]Epoch 159: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=35.9777, avg_loss=36.1134]Epoch 159: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.9777, avg_loss=36.1134]
INFO:__main__:=== EPOCH 159 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.113402
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.135090
INFO:__main__:   • gene_density: 1.182528
INFO:__main__:   • operon_membership: 11.795784
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 160/681
INFO:__main__:Epoch 160/681
INFO:__main__:Epoch 160/681
INFO:__main__:Epoch 160/681
Epoch 160:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 160:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 160:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 160:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 160:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3358, avg_loss=35.3358]Epoch 160:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:   0%|          | 0/11 [00:01<?, ?it/s, loss=40.5586, avg_loss=40.5586]Epoch 160:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.6260, avg_loss=39.6260]Epoch 160:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2934, avg_loss=35.2934]Epoch 160:   9%|▉         | 1/11 [00:01<00:17,  1.76s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:  55%|█████▍    | 6/11 [00:07<00:05,  1.16s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:  64%|██████▎   | 7/11 [00:08<00:04,  1.06s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:  64%|██████▎   | 7/11 [00:08<00:04,  1.06s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:  64%|██████▎   | 7/11 [00:08<00:04,  1.06s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:  64%|██████▎   | 7/11 [00:08<00:04,  1.06s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:  73%|███████▎  | 8/11 [00:10<00:03,  1.15s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:  73%|███████▎  | 8/11 [00:10<00:03,  1.16s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  82%|████████▏ | 9/11 [00:11<00:02,  1.23s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:  82%|████████▏ | 9/11 [00:11<00:02,  1.23s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:  82%|████████▏ | 9/11 [00:11<00:02,  1.23s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:  82%|████████▏ | 9/11 [00:11<00:02,  1.23s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  91%|█████████ | 10/11 [00:12<00:01,  1.28s/it, loss=40.5586, avg_loss=40.5586]Epoch 160:  91%|█████████ | 10/11 [00:12<00:01,  1.28s/it, loss=35.3358, avg_loss=35.3358]Epoch 160:  91%|█████████ | 10/11 [00:12<00:01,  1.28s/it, loss=39.6260, avg_loss=39.6260]Epoch 160:  91%|█████████ | 10/11 [00:12<00:01,  1.28s/it, loss=35.2934, avg_loss=35.2934]Epoch 160:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=34.0807, avg_loss=37.0609]Epoch 160: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=34.0807, avg_loss=37.0609]Epoch 160:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=35.4074, avg_loss=35.2161]Epoch 160: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=35.4074, avg_loss=35.2161]Epoch 160: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=34.0807, avg_loss=37.0609]
Epoch 160:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=36.9854, avg_loss=35.5130]Epoch 160: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=36.9854, avg_loss=35.5130]Epoch 160: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=35.4074, avg_loss=35.2161]
Epoch 160: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=36.9854, avg_loss=35.5130]
INFO:__main__:=== EPOCH 160 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 37.060942
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.379637
INFO:__main__:   • gene_density: 1.171461
INFO:__main__:   • operon_membership: 11.509844
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 160 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.216141
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.689788
INFO:__main__:   • gene_density: 1.182824
INFO:__main__:   • operon_membership: 12.343528
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 160 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.513022
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.371388
INFO:__main__:   • gene_density: 1.187204
INFO:__main__:   • operon_membership: 11.954429
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 160:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=35.9221, avg_loss=35.2033]Epoch 160: 100%|██████████| 11/11 [00:14<00:00,  1.37s/it, loss=35.9221, avg_loss=35.2033]Epoch 160: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=35.9221, avg_loss=35.2033]
INFO:__main__:=== EPOCH 160 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.203349
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.312886
INFO:__main__:   • gene_density: 1.190814
INFO:__main__:   • operon_membership: 10.699648
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.26it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.25it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.53it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]INFO:__main__:=== EPOCH 160 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:=== EPOCH 160 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]
INFO:__main__:=== EPOCH 160 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]
INFO:__main__:=== EPOCH 160 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_160.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_160.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_160.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_160.pt
INFO:__main__:Epoch 161/681
INFO:__main__:Epoch 161/681
INFO:__main__:Epoch 161/681
INFO:__main__:Epoch 161/681
Epoch 161:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 161:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 161:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 161:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 161:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.6392, avg_loss=34.6392]Epoch 161:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9956, avg_loss=33.9956]Epoch 161:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3716, avg_loss=35.3716]Epoch 161:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6304, avg_loss=36.6304]Epoch 161:   9%|▉         | 1/11 [00:01<00:11,  1.12s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  18%|█▊        | 2/11 [00:02<00:10,  1.18s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:  18%|█▊        | 2/11 [00:02<00:10,  1.18s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:  18%|█▊        | 2/11 [00:02<00:10,  1.19s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  18%|█▊        | 2/11 [00:02<00:10,  1.19s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:  27%|██▋       | 3/11 [00:03<00:10,  1.30s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  27%|██▋       | 3/11 [00:03<00:10,  1.31s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:  27%|██▋       | 3/11 [00:03<00:10,  1.31s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:  27%|██▋       | 3/11 [00:03<00:10,  1.31s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  36%|███▋      | 4/11 [00:05<00:09,  1.36s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  45%|████▌     | 5/11 [00:06<00:08,  1.39s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:  64%|██████▎   | 7/11 [00:09<00:05,  1.42s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  64%|██████▎   | 7/11 [00:09<00:05,  1.43s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  73%|███████▎  | 8/11 [00:11<00:04,  1.42s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=35.3716, avg_loss=35.3716]Epoch 161:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=34.6392, avg_loss=34.6392]Epoch 161:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=36.6304, avg_loss=36.6304]Epoch 161:  91%|█████████ | 10/11 [00:13<00:01,  1.39s/it, loss=33.9956, avg_loss=33.9956]Epoch 161:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=34.4821, avg_loss=36.0796]Epoch 161: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=34.4821, avg_loss=36.0796]Epoch 161: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.4821, avg_loss=36.0796]
INFO:__main__:=== EPOCH 161 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.079591
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.450768
INFO:__main__:   • gene_density: 1.184778
INFO:__main__:   • operon_membership: 11.444046
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 161:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=33.0830, avg_loss=35.3275]Epoch 161: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=33.0830, avg_loss=35.3275]Epoch 161: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=33.0830, avg_loss=35.3275]
Epoch 161:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=32.7607, avg_loss=36.1756]Epoch 161: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=32.7607, avg_loss=36.1756]Epoch 161: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=32.7607, avg_loss=36.1756]
INFO:__main__:=== EPOCH 161 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.327486
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.453897
INFO:__main__:   • gene_density: 1.182351
INFO:__main__:   • operon_membership: 11.691238
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 161 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.175620
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.207754
INFO:__main__:   • gene_density: 1.175545
INFO:__main__:   • operon_membership: 12.792322
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 161:  91%|█████████ | 10/11 [00:15<00:01,  1.39s/it, loss=34.5002, avg_loss=35.2836]Epoch 161: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=34.5002, avg_loss=35.2836]Epoch 161: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.5002, avg_loss=35.2836]
INFO:__main__:=== EPOCH 161 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.283613
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.255200
INFO:__main__:   • gene_density: 1.189216
INFO:__main__:   • operon_membership: 10.839197
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 162/681
INFO:__main__:Epoch 162/681
INFO:__main__:Epoch 162/681
INFO:__main__:Epoch 162/681
Epoch 162:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 162:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 162:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 162:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 162:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7579, avg_loss=35.7579]Epoch 162:   9%|▉         | 1/11 [00:01<00:14,  1.42s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5626, avg_loss=34.5626]Epoch 162:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6938, avg_loss=33.6938]Epoch 162:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.1608, avg_loss=33.1608]Epoch 162:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  18%|█▊        | 2/11 [00:02<00:11,  1.26s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:  18%|█▊        | 2/11 [00:02<00:11,  1.26s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:  18%|█▊        | 2/11 [00:02<00:11,  1.26s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:  18%|█▊        | 2/11 [00:02<00:11,  1.26s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:  27%|██▋       | 3/11 [00:03<00:08,  1.09s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  27%|██▋       | 3/11 [00:03<00:08,  1.10s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  45%|████▌     | 5/11 [00:05<00:07,  1.20s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:  45%|████▌     | 5/11 [00:05<00:07,  1.20s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:  45%|████▌     | 5/11 [00:05<00:07,  1.20s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:  45%|████▌     | 5/11 [00:05<00:07,  1.20s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  55%|█████▍    | 6/11 [00:07<00:06,  1.28s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:  55%|█████▍    | 6/11 [00:07<00:06,  1.27s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:  55%|█████▍    | 6/11 [00:07<00:06,  1.28s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:  55%|█████▍    | 6/11 [00:07<00:06,  1.28s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:  64%|██████▎   | 7/11 [00:08<00:05,  1.33s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:  73%|███████▎  | 8/11 [00:10<00:04,  1.36s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:  82%|████████▏ | 9/11 [00:11<00:02,  1.38s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=35.7579, avg_loss=35.7579]Epoch 162:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=34.5626, avg_loss=34.5626]Epoch 162:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=33.6938, avg_loss=33.6938]Epoch 162:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=33.1608, avg_loss=33.1608]Epoch 162:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=39.5019, avg_loss=36.8221]Epoch 162: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=39.5019, avg_loss=36.8221]Epoch 162: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=39.5019, avg_loss=36.8221]
INFO:__main__:=== EPOCH 162 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.822083
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.957749
INFO:__main__:   • gene_density: 1.195845
INFO:__main__:   • operon_membership: 11.668489
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 162:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=35.3400, avg_loss=35.9277]Epoch 162: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=35.3400, avg_loss=35.9277]Epoch 162: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=35.3400, avg_loss=35.9277]
Epoch 162:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=38.1594, avg_loss=35.5974]INFO:__main__:=== EPOCH 162 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.927703
Epoch 162: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=38.1594, avg_loss=35.5974]INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.707150
INFO:__main__:   • gene_density: 1.186316
INFO:__main__:   • operon_membership: 12.034237
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 162: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.1594, avg_loss=35.5974]
INFO:__main__:=== EPOCH 162 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.597422
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.544292
INFO:__main__:   • gene_density: 1.174302
INFO:__main__:   • operon_membership: 11.878829
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 162:  91%|█████████ | 10/11 [00:14<00:01,  1.40s/it, loss=32.6810, avg_loss=34.7523]Epoch 162: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=32.6810, avg_loss=34.7523]Epoch 162: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=32.6810, avg_loss=34.7523]
INFO:__main__:=== EPOCH 162 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.752270
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.646395
INFO:__main__:   • gene_density: 1.177853
INFO:__main__:   • operon_membership: 10.928021
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 163/681
INFO:__main__:Epoch 163/681
INFO:__main__:Epoch 163/681
INFO:__main__:Epoch 163/681
Epoch 163:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 163:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 163:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 163:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 163:   0%|          | 0/11 [00:01<?, ?it/s, loss=40.6789, avg_loss=40.6789]Epoch 163:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.1367, avg_loss=32.1367]Epoch 163:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3073, avg_loss=34.3073]Epoch 163:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.6686, avg_loss=34.6686]Epoch 163:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  27%|██▋       | 3/11 [00:04<00:11,  1.38s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:  27%|██▋       | 3/11 [00:04<00:11,  1.38s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:  27%|██▋       | 3/11 [00:04<00:11,  1.38s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:  27%|██▋       | 3/11 [00:04<00:11,  1.38s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  36%|███▋      | 4/11 [00:05<00:08,  1.28s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:  36%|███▋      | 4/11 [00:05<00:08,  1.28s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:  36%|███▋      | 4/11 [00:05<00:08,  1.28s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:  36%|███▋      | 4/11 [00:05<00:08,  1.28s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  45%|████▌     | 5/11 [00:06<00:07,  1.20s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:  45%|████▌     | 5/11 [00:06<00:07,  1.20s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:  45%|████▌     | 5/11 [00:06<00:07,  1.20s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:  45%|████▌     | 5/11 [00:06<00:07,  1.20s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  55%|█████▍    | 6/11 [00:07<00:05,  1.08s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  55%|█████▍    | 6/11 [00:07<00:05,  1.08s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:  55%|█████▍    | 6/11 [00:07<00:05,  1.08s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:  55%|█████▍    | 6/11 [00:07<00:05,  1.08s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:  64%|██████▎   | 7/11 [00:08<00:04,  1.15s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:  64%|██████▎   | 7/11 [00:08<00:04,  1.15s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:  64%|██████▎   | 7/11 [00:08<00:04,  1.15s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:  64%|██████▎   | 7/11 [00:08<00:04,  1.16s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=32.1367, avg_loss=32.1367]Epoch 163:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=34.3073, avg_loss=34.3073]Epoch 163:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=40.6789, avg_loss=40.6789]Epoch 163:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=34.6686, avg_loss=34.6686]Epoch 163:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=36.6803, avg_loss=35.2256]Epoch 163:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=41.2151, avg_loss=36.6806]Epoch 163: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=36.6803, avg_loss=35.2256]Epoch 163: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=41.2151, avg_loss=36.6806]Epoch 163: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.6803, avg_loss=35.2256]Epoch 163: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=41.2151, avg_loss=36.6806]

Epoch 163:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=33.9254, avg_loss=35.4360]Epoch 163: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=33.9254, avg_loss=35.4360]Epoch 163: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=33.9254, avg_loss=35.4360]
INFO:__main__:=== EPOCH 163 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 163 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.225597
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 36.680606
INFO:__main__:   • gene_expression: 22.720085
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.190519
INFO:__main__:   • gene_expression: 24.326112
INFO:__main__:   • operon_membership: 11.314994
INFO:__main__:   • gene_density: 1.180575
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • operon_membership: 11.173919
INFO:__main__:========================================
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 163 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.436049
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.898800
INFO:__main__:   • gene_density: 1.196911
INFO:__main__:   • operon_membership: 12.340338
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 163:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=37.1744, avg_loss=35.7543]Epoch 163: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=37.1744, avg_loss=35.7543]Epoch 163: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=37.1744, avg_loss=35.7543]
INFO:__main__:=== EPOCH 163 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.754345
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.692841
INFO:__main__:   • gene_density: 1.166075
INFO:__main__:   • operon_membership: 11.895429
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 164/681
INFO:__main__:Epoch 164/681
INFO:__main__:Epoch 164/681
INFO:__main__:Epoch 164/681
Epoch 164:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 164:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 164:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 164:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 164:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2636, avg_loss=35.2636]Epoch 164:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.7550, avg_loss=32.7550]Epoch 164:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1509, avg_loss=38.1509]Epoch 164:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.3564, avg_loss=37.3564]Epoch 164:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:  45%|████▌     | 5/11 [00:07<00:08,  1.41s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:  45%|████▌     | 5/11 [00:07<00:08,  1.40s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:  55%|█████▍    | 6/11 [00:08<00:06,  1.32s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:  64%|██████▎   | 7/11 [00:09<00:05,  1.25s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  64%|██████▎   | 7/11 [00:09<00:05,  1.26s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:  64%|██████▎   | 7/11 [00:09<00:05,  1.26s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:  73%|███████▎  | 8/11 [00:10<00:03,  1.12s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  73%|███████▎  | 8/11 [00:10<00:03,  1.12s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:  73%|███████▎  | 8/11 [00:10<00:03,  1.12s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:  73%|███████▎  | 8/11 [00:10<00:03,  1.12s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  91%|█████████ | 10/11 [00:12<00:01,  1.22s/it, loss=35.2636, avg_loss=35.2636]Epoch 164:  91%|█████████ | 10/11 [00:12<00:01,  1.21s/it, loss=38.1509, avg_loss=38.1509]Epoch 164:  91%|█████████ | 10/11 [00:12<00:01,  1.22s/it, loss=32.7550, avg_loss=32.7550]Epoch 164:  91%|█████████ | 10/11 [00:12<00:01,  1.22s/it, loss=37.3564, avg_loss=37.3564]Epoch 164:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=36.2812, avg_loss=35.3297]Epoch 164: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=36.2812, avg_loss=35.3297]Epoch 164: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.2812, avg_loss=35.3297]
INFO:__main__:=== EPOCH 164 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.329653
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.162894
INFO:__main__:   • gene_density: 1.190459
INFO:__main__:   • operon_membership: 11.976300
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 164:  91%|█████████ | 10/11 [00:14<00:01,  1.21s/it, loss=33.1713, avg_loss=35.9510]Epoch 164: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=33.1713, avg_loss=35.9510]Epoch 164: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=33.1713, avg_loss=35.9510]
INFO:__main__:=== EPOCH 164 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.951010
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.359504
INFO:__main__:   • gene_density: 1.181167
INFO:__main__:   • operon_membership: 11.410338
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 164:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=38.0404, avg_loss=35.7847]Epoch 164: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.0404, avg_loss=35.7847]Epoch 164: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=38.0404, avg_loss=35.7847]
INFO:__main__:=== EPOCH 164 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.784662
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.830880
INFO:__main__:   • gene_density: 1.183475
INFO:__main__:   • operon_membership: 11.770307
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 164:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=39.8828, avg_loss=35.8499]Epoch 164: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=39.8828, avg_loss=35.8499]Epoch 164: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=39.8828, avg_loss=35.8499]
INFO:__main__:=== EPOCH 164 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.849931
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.051929
INFO:__main__:   • gene_density: 1.177971
INFO:__main__:   • operon_membership: 11.620031
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 165/681
INFO:__main__:Epoch 165/681
INFO:__main__:Epoch 165/681
INFO:__main__:Epoch 165/681
Epoch 165:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 165:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 165:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 165:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 165:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.6033, avg_loss=35.6033]Epoch 165:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0430, avg_loss=35.0430]Epoch 165:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0887, avg_loss=36.0887]Epoch 165:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1105, avg_loss=35.1105]Epoch 165:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  73%|███████▎  | 8/11 [00:11<00:04,  1.36s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:  73%|███████▎  | 8/11 [00:11<00:04,  1.36s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:  73%|███████▎  | 8/11 [00:11<00:04,  1.36s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:  73%|███████▎  | 8/11 [00:11<00:04,  1.36s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:  82%|████████▏ | 9/11 [00:12<00:02,  1.30s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:  82%|████████▏ | 9/11 [00:12<00:02,  1.31s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:  91%|█████████ | 10/11 [00:13<00:01,  1.16s/it, loss=35.0430, avg_loss=35.0430]Epoch 165:  91%|█████████ | 10/11 [00:13<00:01,  1.17s/it, loss=35.6033, avg_loss=35.6033]Epoch 165:  91%|█████████ | 10/11 [00:13<00:01,  1.16s/it, loss=35.1105, avg_loss=35.1105]Epoch 165:  91%|█████████ | 10/11 [00:13<00:01,  1.16s/it, loss=36.0887, avg_loss=36.0887]Epoch 165:  91%|█████████ | 10/11 [00:14<00:01,  1.17s/it, loss=35.2951, avg_loss=35.3115]Epoch 165: 100%|██████████| 11/11 [00:14<00:00,  1.26s/it, loss=35.2951, avg_loss=35.3115]Epoch 165: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.2951, avg_loss=35.3115]
INFO:__main__:=== EPOCH 165 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.311539
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.800787
INFO:__main__:   • gene_density: 1.169448
INFO:__main__:   • operon_membership: 11.341303
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 165:  91%|█████████ | 10/11 [00:14<00:01,  1.16s/it, loss=33.8746, avg_loss=35.5619]Epoch 165: 100%|██████████| 11/11 [00:14<00:00,  1.26s/it, loss=33.8746, avg_loss=35.5619]Epoch 165: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=33.8746, avg_loss=35.5619]
INFO:__main__:=== EPOCH 165 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.561929
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.663534
INFO:__main__:   • gene_density: 1.206972
INFO:__main__:   • operon_membership: 11.691423
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 165:  91%|█████████ | 10/11 [00:14<00:01,  1.16s/it, loss=37.3039, avg_loss=36.0999]Epoch 165: 100%|██████████| 11/11 [00:14<00:00,  1.26s/it, loss=37.3039, avg_loss=36.0999]Epoch 165: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.3039, avg_loss=36.0999]
INFO:__main__:=== EPOCH 165 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.099878
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.298208
INFO:__main__:   • gene_density: 1.167259
INFO:__main__:   • operon_membership: 11.634411
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 165:  91%|█████████ | 10/11 [00:14<00:01,  1.16s/it, loss=38.3201, avg_loss=36.2886]Epoch 165: 100%|██████████| 11/11 [00:14<00:00,  1.26s/it, loss=38.3201, avg_loss=36.2886]Epoch 165: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=38.3201, avg_loss=36.2886]
INFO:__main__:=== EPOCH 165 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.288619
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.021934
INFO:__main__:   • gene_density: 1.186671
INFO:__main__:   • operon_membership: 12.080014
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.58it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.58it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.58it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
INFO:__main__:=== EPOCH 165 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 165 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]
INFO:__main__:=== EPOCH 165 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
INFO:__main__:=== EPOCH 165 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 166/681
INFO:__main__:Epoch 166/681
INFO:__main__:Epoch 166/681
INFO:__main__:Epoch 166/681
Epoch 166:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 166:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 166:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 166:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 166:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.8104, avg_loss=32.8104]Epoch 166:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1284, avg_loss=38.1284]Epoch 166:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.8429, avg_loss=34.8429]Epoch 166:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9211, avg_loss=33.9211]Epoch 166:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:  64%|██████▎   | 7/11 [00:10<00:05,  1.41s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:  64%|██████▎   | 7/11 [00:10<00:05,  1.40s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:  73%|███████▎  | 8/11 [00:11<00:04,  1.34s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:  73%|███████▎  | 8/11 [00:11<00:04,  1.33s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  82%|████████▏ | 9/11 [00:12<00:02,  1.22s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  82%|████████▏ | 9/11 [00:12<00:02,  1.22s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:  82%|████████▏ | 9/11 [00:12<00:02,  1.23s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:  82%|████████▏ | 9/11 [00:12<00:02,  1.23s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=38.1284, avg_loss=38.1284]Epoch 166:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=34.8429, avg_loss=34.8429]Epoch 166:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=32.8104, avg_loss=32.8104]Epoch 166:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=33.9211, avg_loss=33.9211]Epoch 166:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=35.7553, avg_loss=36.3462]Epoch 166: 100%|██████████| 11/11 [00:14<00:00,  1.29s/it, loss=35.7553, avg_loss=36.3462]Epoch 166: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.7553, avg_loss=36.3462]
INFO:__main__:=== EPOCH 166 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.346196
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.053329
INFO:__main__:   • gene_density: 1.198982
INFO:__main__:   • operon_membership: 12.093885
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 166:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=37.7119, avg_loss=35.5857]Epoch 166: 100%|██████████| 11/11 [00:14<00:00,  1.29s/it, loss=37.7119, avg_loss=35.5857]Epoch 166: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=37.7119, avg_loss=35.5857]
Epoch 166:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=34.2358, avg_loss=35.6472]Epoch 166: 100%|██████████| 11/11 [00:14<00:00,  1.29s/it, loss=34.2358, avg_loss=35.6472]Epoch 166: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.2358, avg_loss=35.6472]
INFO:__main__:=== EPOCH 166 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.585668
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.020842
INFO:__main__:   • gene_density: 1.175249
INFO:__main__:   • operon_membership: 11.389577
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 166 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.647238
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.053236
INFO:__main__:   • gene_density: 1.170810
INFO:__main__:   • operon_membership: 11.423192
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 166:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=34.8318, avg_loss=35.4791]Epoch 166: 100%|██████████| 11/11 [00:14<00:00,  1.29s/it, loss=34.8318, avg_loss=35.4791]Epoch 166: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.8318, avg_loss=35.4791]
INFO:__main__:=== EPOCH 166 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.479097
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.573769
INFO:__main__:   • gene_density: 1.187086
INFO:__main__:   • operon_membership: 11.718242
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 167/681
INFO:__main__:Epoch 167/681
INFO:__main__:Epoch 167/681
INFO:__main__:Epoch 167/681
Epoch 167:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 167:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 167:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 167:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 167:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.1386, avg_loss=33.1386]Epoch 167:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.2137, avg_loss=38.2137]Epoch 167:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.7974, avg_loss=34.7974]Epoch 167:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9076, avg_loss=36.9076]Epoch 167:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:  45%|████▌     | 5/11 [00:07<00:08,  1.49s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  55%|█████▍    | 6/11 [00:08<00:07,  1.48s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:  55%|█████▍    | 6/11 [00:09<00:07,  1.48s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  82%|████████▏ | 9/11 [00:13<00:02,  1.37s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:  82%|████████▏ | 9/11 [00:13<00:02,  1.37s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:  82%|████████▏ | 9/11 [00:13<00:02,  1.37s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:  82%|████████▏ | 9/11 [00:13<00:02,  1.37s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=36.9076, avg_loss=36.9076]Epoch 167:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=33.1386, avg_loss=33.1386]Epoch 167:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=38.2137, avg_loss=38.2137]Epoch 167:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=34.7974, avg_loss=34.7974]Epoch 167:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=38.1594, avg_loss=35.8809]Epoch 167:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=34.4048, avg_loss=36.5824]Epoch 167: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=38.1594, avg_loss=35.8809]Epoch 167: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=34.4048, avg_loss=36.5824]Epoch 167: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.4048, avg_loss=36.5824]Epoch 167: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=38.1594, avg_loss=35.8809]

INFO:__main__:=== EPOCH 167 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 167 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.582432
INFO:__main__:🔢 Total Loss: 35.880871
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.758368
INFO:__main__:   • gene_expression: 23.402272
INFO:__main__:   • gene_density: 1.163944
INFO:__main__:   • gene_density: 1.190933
INFO:__main__:   • operon_membership: 11.660120
INFO:__main__:   • operon_membership: 11.287666
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 167:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=36.4867, avg_loss=35.5999]Epoch 167: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=36.4867, avg_loss=35.5999]Epoch 167: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=36.4867, avg_loss=35.5999]
INFO:__main__:=== EPOCH 167 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.599902
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.581164
INFO:__main__:   • gene_density: 1.184067
INFO:__main__:   • operon_membership: 11.834671
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 167:  91%|█████████ | 10/11 [00:15<00:01,  1.28s/it, loss=33.2731, avg_loss=34.9701]Epoch 167: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=33.2731, avg_loss=34.9701]Epoch 167: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=33.2731, avg_loss=34.9701]
INFO:__main__:=== EPOCH 167 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.970064
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.878717
INFO:__main__:   • gene_density: 1.192590
INFO:__main__:   • operon_membership: 11.898758
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 168/681
INFO:__main__:Epoch 168/681
INFO:__main__:Epoch 168/681
INFO:__main__:Epoch 168/681
Epoch 168:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 168:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 168:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 168:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 168:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4765, avg_loss=34.4765]Epoch 168:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3046, avg_loss=35.3046]Epoch 168:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.3447, avg_loss=35.3447]Epoch 168:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.2338, avg_loss=37.2338]Epoch 168:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  82%|████████▏ | 9/11 [00:13<00:02,  1.42s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:  82%|████████▏ | 9/11 [00:13<00:02,  1.42s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:  82%|████████▏ | 9/11 [00:13<00:02,  1.42s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:  82%|████████▏ | 9/11 [00:13<00:02,  1.42s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=34.4765, avg_loss=34.4765]Epoch 168:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.3046, avg_loss=35.3046]Epoch 168:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.3447, avg_loss=35.3447]Epoch 168:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=37.2338, avg_loss=37.2338]Epoch 168:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=32.0967, avg_loss=35.0930]Epoch 168:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=33.2458, avg_loss=35.0603]Epoch 168: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=32.0967, avg_loss=35.0930]Epoch 168: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=33.2458, avg_loss=35.0603]Epoch 168: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=32.0967, avg_loss=35.0930]Epoch 168: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=33.2458, avg_loss=35.0603]

INFO:__main__:=== EPOCH 168 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 168 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.060268
INFO:__main__:🔢 Total Loss: 35.093018
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.098501
INFO:__main__:   • gene_expression: 22.793044
INFO:__main__:   • gene_density: 1.183831
INFO:__main__:   • gene_density: 1.186257
INFO:__main__:   • operon_membership: 11.777936
INFO:__main__:   • operon_membership: 11.113716
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 168:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=39.4456, avg_loss=37.0719]Epoch 168: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=39.4456, avg_loss=37.0719]Epoch 168: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=39.4456, avg_loss=37.0719]
INFO:__main__:=== EPOCH 168 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 37.071914
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.575870
INFO:__main__:   • gene_density: 1.192472
INFO:__main__:   • operon_membership: 11.303573
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 168:  91%|█████████ | 10/11 [00:15<00:01,  1.38s/it, loss=35.0851, avg_loss=36.0064]Epoch 168: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=35.0851, avg_loss=36.0064]Epoch 168: 100%|██████████| 11/11 [00:15<00:00,  1.43s/it, loss=35.0851, avg_loss=36.0064]
INFO:__main__:=== EPOCH 168 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.006422
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.261423
INFO:__main__:   • gene_density: 1.168797
INFO:__main__:   • operon_membership: 12.576202
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 169/681
INFO:__main__:Epoch 169/681
INFO:__main__:Epoch 169/681
INFO:__main__:Epoch 169/681
Epoch 169:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 169:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 169:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 169:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 169:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4813, avg_loss=35.4813]Epoch 169:   9%|▉         | 1/11 [00:01<00:12,  1.23s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9563, avg_loss=35.9563]Epoch 169:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.1835, avg_loss=37.1835]Epoch 169:   9%|▉         | 1/11 [00:01<00:12,  1.23s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:   9%|▉         | 1/11 [00:01<00:12,  1.24s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1284, avg_loss=38.1284]Epoch 169:   9%|▉         | 1/11 [00:01<00:12,  1.24s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  18%|█▊        | 2/11 [00:02<00:09,  1.07s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:  18%|█▊        | 2/11 [00:02<00:09,  1.08s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  18%|█▊        | 2/11 [00:02<00:09,  1.08s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:  18%|█▊        | 2/11 [00:02<00:09,  1.08s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:  27%|██▋       | 3/11 [00:03<00:09,  1.22s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:  36%|███▋      | 4/11 [00:05<00:09,  1.30s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:  36%|███▋      | 4/11 [00:05<00:09,  1.30s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:  36%|███▋      | 4/11 [00:05<00:09,  1.30s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  36%|███▋      | 4/11 [00:05<00:09,  1.30s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  45%|████▌     | 5/11 [00:06<00:08,  1.34s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  73%|███████▎  | 8/11 [00:10<00:04,  1.38s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  82%|████████▏ | 9/11 [00:12<00:02,  1.39s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=35.4813, avg_loss=35.4813]Epoch 169:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=38.1284, avg_loss=38.1284]Epoch 169:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=35.9563, avg_loss=35.9563]Epoch 169:  91%|█████████ | 10/11 [00:13<00:01,  1.40s/it, loss=37.1835, avg_loss=37.1835]Epoch 169:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=34.8264, avg_loss=35.1405]Epoch 169: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=34.8264, avg_loss=35.1405]Epoch 169: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.8264, avg_loss=35.1405]
Epoch 169:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=37.5115, avg_loss=36.3465]Epoch 169:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=32.5908, avg_loss=34.6451]Epoch 169: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=37.5115, avg_loss=36.3465]Epoch 169: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=32.5908, avg_loss=34.6451]Epoch 169: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=37.5115, avg_loss=36.3465]
Epoch 169: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=32.5908, avg_loss=34.6451]
INFO:__main__:=== EPOCH 169 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.140494
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.205036
INFO:__main__:   • gene_density: 1.178977
INFO:__main__:   • operon_membership: 11.756481
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 169 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 169 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.346461
INFO:__main__:🔢 Total Loss: 34.645097
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 24.063375
INFO:__main__:   • gene_expression: 21.916700
INFO:__main__:   • gene_density: 1.188743
INFO:__main__:   • gene_density: 1.184245
INFO:__main__:   • operon_membership: 11.094342
INFO:__main__:   • operon_membership: 11.544153
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 169:  91%|█████████ | 10/11 [00:15<00:01,  1.40s/it, loss=35.8232, avg_loss=37.1616]Epoch 169: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=35.8232, avg_loss=37.1616]Epoch 169: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.8232, avg_loss=37.1616]
INFO:__main__:=== EPOCH 169 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 37.161601
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.749095
INFO:__main__:   • gene_density: 1.180043
INFO:__main__:   • operon_membership: 12.232463
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 170/681
INFO:__main__:Epoch 170/681
INFO:__main__:Epoch 170/681
INFO:__main__:Epoch 170/681
Epoch 170:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 170:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 170:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 170:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 170:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0194, avg_loss=33.0194]Epoch 170:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4010, avg_loss=34.4010]Epoch 170:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2668, avg_loss=35.2668]Epoch 170:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2610, avg_loss=34.2610]Epoch 170:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  18%|█▊        | 2/11 [00:02<00:11,  1.30s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:  18%|█▊        | 2/11 [00:02<00:11,  1.30s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:  18%|█▊        | 2/11 [00:02<00:11,  1.30s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  18%|█▊        | 2/11 [00:02<00:11,  1.31s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:  27%|██▋       | 3/11 [00:03<00:09,  1.23s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:  45%|████▌     | 5/11 [00:05<00:06,  1.07s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:  45%|████▌     | 5/11 [00:05<00:06,  1.07s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:  45%|████▌     | 5/11 [00:05<00:06,  1.08s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  45%|████▌     | 5/11 [00:05<00:06,  1.08s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:  55%|█████▍    | 6/11 [00:07<00:06,  1.20s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:  55%|█████▍    | 6/11 [00:07<00:06,  1.20s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:  55%|█████▍    | 6/11 [00:07<00:06,  1.20s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:  64%|██████▎   | 7/11 [00:08<00:05,  1.29s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:  73%|███████▎  | 8/11 [00:10<00:04,  1.33s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:  73%|███████▎  | 8/11 [00:10<00:04,  1.33s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:  73%|███████▎  | 8/11 [00:10<00:04,  1.34s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  73%|███████▎  | 8/11 [00:10<00:04,  1.34s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:  82%|████████▏ | 9/11 [00:11<00:02,  1.36s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  82%|████████▏ | 9/11 [00:11<00:02,  1.36s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:  82%|████████▏ | 9/11 [00:11<00:02,  1.36s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:  82%|████████▏ | 9/11 [00:11<00:02,  1.36s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:  91%|█████████ | 10/11 [00:12<00:01,  1.37s/it, loss=35.2668, avg_loss=35.2668]Epoch 170:  91%|█████████ | 10/11 [00:12<00:01,  1.37s/it, loss=33.0194, avg_loss=33.0194]Epoch 170:  91%|█████████ | 10/11 [00:12<00:01,  1.37s/it, loss=34.2610, avg_loss=34.2610]Epoch 170:  91%|█████████ | 10/11 [00:12<00:01,  1.37s/it, loss=34.4010, avg_loss=34.4010]Epoch 170:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=31.8687, avg_loss=35.0325]Epoch 170: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=31.8687, avg_loss=35.0325]Epoch 170:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=37.0584, avg_loss=36.0489]Epoch 170: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=37.0584, avg_loss=36.0489]Epoch 170: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=31.8687, avg_loss=35.0325]
Epoch 170: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=37.0584, avg_loss=36.0489]
INFO:__main__:=== EPOCH 170 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.032533
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.531249
INFO:__main__:   • gene_density: 1.172881
INFO:__main__:   • operon_membership: 11.328403
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 170 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.048939
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.169066
INFO:__main__:   • gene_density: 1.188033
INFO:__main__:   • operon_membership: 11.691839
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 170:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=34.2738, avg_loss=35.4042]Epoch 170: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=34.2738, avg_loss=35.4042]Epoch 170: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=34.2738, avg_loss=35.4042]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 170 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.404207
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.862921
INFO:__main__:   • gene_density: 1.189394
INFO:__main__:   • operon_membership: 11.351892
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 170:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=37.9286, avg_loss=36.7888]Epoch 170: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=37.9286, avg_loss=36.7888]Epoch 170: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=37.9286, avg_loss=36.7888]
INFO:__main__:=== EPOCH 170 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.788775
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.456162
INFO:__main__:   • gene_density: 1.178385
INFO:__main__:   • operon_membership: 12.154227
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.50it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
INFO:__main__:=== EPOCH 170 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 170 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:=== EPOCH 170 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]
INFO:__main__:=== EPOCH 170 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_170.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_170.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_170.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_170.pt
INFO:__main__:Epoch 171/681
INFO:__main__:Epoch 171/681
INFO:__main__:Epoch 171/681
INFO:__main__:Epoch 171/681
Epoch 171:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 171:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 171:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 171:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 171:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9280, avg_loss=36.9280]Epoch 171:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.9269, avg_loss=31.9269]Epoch 171:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5386, avg_loss=37.5386]Epoch 171:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.6735, avg_loss=31.6735]Epoch 171:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:  36%|███▋      | 4/11 [00:06<00:10,  1.47s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:  64%|██████▎   | 7/11 [00:10<00:05,  1.42s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:  73%|███████▎  | 8/11 [00:11<00:04,  1.41s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  82%|████████▏ | 9/11 [00:12<00:02,  1.36s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:  82%|████████▏ | 9/11 [00:12<00:02,  1.36s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:  82%|████████▏ | 9/11 [00:12<00:02,  1.36s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:  82%|████████▏ | 9/11 [00:12<00:02,  1.36s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=36.9280, avg_loss=36.9280]Epoch 171:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=37.5386, avg_loss=37.5386]Epoch 171:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=31.9269, avg_loss=31.9269]Epoch 171:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=31.6735, avg_loss=31.6735]Epoch 171:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=32.6383, avg_loss=34.6906]Epoch 171: 100%|██████████| 11/11 [00:15<00:00,  1.26s/it, loss=32.6383, avg_loss=34.6906]Epoch 171: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=32.6383, avg_loss=34.6906]
INFO:__main__:=== EPOCH 171 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.690601
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.235880
INFO:__main__:   • gene_density: 1.177083
INFO:__main__:   • operon_membership: 12.277638
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 171:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=36.8567, avg_loss=36.5393]Epoch 171: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=36.8567, avg_loss=36.5393]Epoch 171: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=36.8567, avg_loss=36.5393]
Epoch 171:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=37.1176, avg_loss=36.0310]Epoch 171: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=37.1176, avg_loss=36.0310]Epoch 171: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.1176, avg_loss=36.0310]
Epoch 171:  91%|█████████ | 10/11 [00:15<00:01,  1.30s/it, loss=34.7470, avg_loss=35.9437]INFO:__main__:=== EPOCH 171 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.539320
INFO:__main__:📊 Individual Modality Losses:
Epoch 171: 100%|██████████| 11/11 [00:15<00:00,  1.27s/it, loss=34.7470, avg_loss=35.9437]INFO:__main__:   • gene_expression: 23.347497
INFO:__main__:   • gene_density: 1.181167
INFO:__main__:   • operon_membership: 12.010656
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 171: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=34.7470, avg_loss=35.9437]
INFO:__main__:=== EPOCH 171 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.031008
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.679824
INFO:__main__:   • gene_density: 1.182351
INFO:__main__:   • operon_membership: 11.168833
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 171 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.943701
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.623906
INFO:__main__:   • gene_density: 1.192531
INFO:__main__:   • operon_membership: 11.127264
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 172/681
INFO:__main__:Epoch 172/681
INFO:__main__:Epoch 172/681
INFO:__main__:Epoch 172/681
Epoch 172:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 172:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 172:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 172:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 172:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4490, avg_loss=35.4490]Epoch 172:   9%|▉         | 1/11 [00:01<00:13,  1.37s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5573, avg_loss=35.5573]Epoch 172:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.0716, avg_loss=35.0716]Epoch 172:   9%|▉         | 1/11 [00:01<00:13,  1.38s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0591, avg_loss=36.0591]Epoch 172:   9%|▉         | 1/11 [00:01<00:13,  1.39s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:  18%|█▊        | 2/11 [00:02<00:12,  1.41s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:  18%|█▊        | 2/11 [00:02<00:12,  1.42s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:  27%|██▋       | 3/11 [00:04<00:11,  1.43s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:  27%|██▋       | 3/11 [00:04<00:11,  1.44s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.5573, avg_loss=35.5573]Epoch 172:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.0716, avg_loss=35.0716]Epoch 172:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.4490, avg_loss=35.4490]Epoch 172:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=36.0591, avg_loss=36.0591]Epoch 172:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=35.8633, avg_loss=35.9410]Epoch 172: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.8633, avg_loss=35.9410]Epoch 172: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.8633, avg_loss=35.9410]
INFO:__main__:=== EPOCH 172 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.940967
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.947522
INFO:__main__:   • gene_density: 1.188506
INFO:__main__:   • operon_membership: 11.804939
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 172:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=33.0727, avg_loss=35.1015]Epoch 172:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=35.4036, avg_loss=35.1958]Epoch 172: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.0727, avg_loss=35.1015]Epoch 172: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=35.4036, avg_loss=35.1958]Epoch 172: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.4036, avg_loss=35.1958]Epoch 172: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=33.0727, avg_loss=35.1015]

INFO:__main__:=== EPOCH 172 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 172 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.195839
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:🔢 Total Loss: 35.101506
INFO:__main__:   • gene_expression: 22.770524
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_density: 1.180279
INFO:__main__:   • operon_membership: 11.245034
INFO:__main__:   • gene_expression: 22.306821
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_density: 1.187322
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 11.607361
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 172:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=36.1529, avg_loss=36.6184]Epoch 172: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=36.1529, avg_loss=36.6184]Epoch 172: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=36.1529, avg_loss=36.6184]
INFO:__main__:=== EPOCH 172 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.618402
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.594292
INFO:__main__:   • gene_density: 1.176492
INFO:__main__:   • operon_membership: 11.847618
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 173/681
INFO:__main__:Epoch 173/681
INFO:__main__:Epoch 173/681
INFO:__main__:Epoch 173/681
Epoch 173:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 173:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 173:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 173:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 173:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.4889, avg_loss=32.4889]Epoch 173:   9%|▉         | 1/11 [00:01<00:14,  1.42s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:   0%|          | 0/11 [00:01<?, ?it/s, loss=30.9475, avg_loss=30.9475]Epoch 173:   9%|▉         | 1/11 [00:01<00:14,  1.42s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.9785, avg_loss=36.9785]Epoch 173:   9%|▉         | 1/11 [00:01<00:14,  1.42s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9457, avg_loss=35.9457]Epoch 173:   9%|▉         | 1/11 [00:01<00:14,  1.43s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:  27%|██▋       | 3/11 [00:03<00:08,  1.02s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:  27%|██▋       | 3/11 [00:03<00:08,  1.02s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:  27%|██▋       | 3/11 [00:03<00:08,  1.02s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:  27%|██▋       | 3/11 [00:03<00:08,  1.02s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  36%|███▋      | 4/11 [00:04<00:08,  1.20s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:  36%|███▋      | 4/11 [00:04<00:08,  1.20s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:  36%|███▋      | 4/11 [00:04<00:08,  1.20s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:  36%|███▋      | 4/11 [00:04<00:08,  1.21s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:  55%|█████▍    | 6/11 [00:07<00:06,  1.36s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:  55%|█████▍    | 6/11 [00:07<00:06,  1.37s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  73%|███████▎  | 8/11 [00:10<00:04,  1.43s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:  73%|███████▎  | 8/11 [00:10<00:04,  1.43s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:  73%|███████▎  | 8/11 [00:10<00:04,  1.43s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:  73%|███████▎  | 8/11 [00:10<00:04,  1.43s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:  82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:  82%|████████▏ | 9/11 [00:12<00:02,  1.44s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=30.9475, avg_loss=30.9475]Epoch 173:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=36.9785, avg_loss=36.9785]Epoch 173:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=32.4889, avg_loss=32.4889]Epoch 173:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=35.9457, avg_loss=35.9457]Epoch 173:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=38.3567, avg_loss=34.6632]Epoch 173: 100%|██████████| 11/11 [00:15<00:00,  1.50s/it, loss=38.3567, avg_loss=34.6632]Epoch 173: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.3567, avg_loss=34.6632]
Epoch 173:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=33.3081, avg_loss=36.2291]Epoch 173: 100%|██████████| 11/11 [00:15<00:00,  1.50s/it, loss=33.3081, avg_loss=36.2291]INFO:__main__:=== EPOCH 173 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.663162
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.050228
INFO:__main__:   • gene_density: 1.188447
INFO:__main__:   • operon_membership: 11.424487
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 173: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=33.3081, avg_loss=36.2291]
INFO:__main__:=== EPOCH 173 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.229133
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.922188
INFO:__main__:   • gene_density: 1.179628
INFO:__main__:   • operon_membership: 12.127316
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 173:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=38.4147, avg_loss=36.2625]Epoch 173: 100%|██████████| 11/11 [00:15<00:00,  1.50s/it, loss=38.4147, avg_loss=36.2625]Epoch 173: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.4147, avg_loss=36.2625]
INFO:__main__:=== EPOCH 173 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.262510
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.608065
INFO:__main__:   • gene_density: 1.179096
INFO:__main__:   • operon_membership: 11.475350
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 173:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=34.1763, avg_loss=35.7146]Epoch 173: 100%|██████████| 11/11 [00:15<00:00,  1.50s/it, loss=34.1763, avg_loss=35.7146]Epoch 173: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=34.1763, avg_loss=35.7146]
INFO:__main__:=== EPOCH 173 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.714611
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.057587
INFO:__main__:   • gene_density: 1.186020
INFO:__main__:   • operon_membership: 11.471003
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 174/681
INFO:__main__:Epoch 174/681
INFO:__main__:Epoch 174/681
INFO:__main__:Epoch 174/681
Epoch 174:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 174:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 174:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 174:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 174:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4202, avg_loss=35.4202]Epoch 174:   9%|▉         | 1/11 [00:01<00:15,  1.55s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.5021, avg_loss=38.5021]Epoch 174:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5545, avg_loss=35.5545]Epoch 174:   9%|▉         | 1/11 [00:01<00:15,  1.56s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.5915, avg_loss=38.5915]Epoch 174:   9%|▉         | 1/11 [00:01<00:15,  1.57s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:  18%|█▊        | 2/11 [00:02<00:12,  1.35s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  27%|██▋       | 3/11 [00:03<00:09,  1.18s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:  27%|██▋       | 3/11 [00:03<00:09,  1.18s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  27%|██▋       | 3/11 [00:03<00:09,  1.18s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:  27%|██▋       | 3/11 [00:03<00:09,  1.18s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:  36%|███▋      | 4/11 [00:04<00:07,  1.08s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:  36%|███▋      | 4/11 [00:04<00:07,  1.09s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  45%|████▌     | 5/11 [00:06<00:07,  1.21s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:  45%|████▌     | 5/11 [00:06<00:07,  1.22s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:  45%|████▌     | 5/11 [00:06<00:07,  1.21s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:  45%|████▌     | 5/11 [00:06<00:07,  1.22s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  55%|█████▍    | 6/11 [00:07<00:06,  1.29s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:  55%|█████▍    | 6/11 [00:07<00:06,  1.29s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:  55%|█████▍    | 6/11 [00:07<00:06,  1.29s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:  55%|█████▍    | 6/11 [00:07<00:06,  1.29s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:  64%|██████▎   | 7/11 [00:08<00:05,  1.34s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:  64%|██████▎   | 7/11 [00:09<00:05,  1.34s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  73%|███████▎  | 8/11 [00:10<00:04,  1.37s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:  73%|███████▎  | 8/11 [00:10<00:04,  1.37s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:  73%|███████▎  | 8/11 [00:10<00:04,  1.37s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:  73%|███████▎  | 8/11 [00:10<00:04,  1.37s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:  82%|████████▏ | 9/11 [00:11<00:02,  1.39s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=35.5545, avg_loss=35.5545]Epoch 174:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=38.5021, avg_loss=38.5021]Epoch 174:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=35.4202, avg_loss=35.4202]Epoch 174:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=38.5915, avg_loss=38.5915]Epoch 174:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.6039, avg_loss=36.8841]Epoch 174: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.6039, avg_loss=36.8841]Epoch 174:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=34.0348, avg_loss=35.2272]Epoch 174: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=34.0348, avg_loss=35.2272]Epoch 174:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.0823, avg_loss=34.8994]Epoch 174: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.6039, avg_loss=36.8841]Epoch 174: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.0823, avg_loss=34.8994]
Epoch 174: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.0348, avg_loss=35.2272]
Epoch 174: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.0823, avg_loss=34.8994]
INFO:__main__:=== EPOCH 174 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.884117
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.363036
INFO:__main__:   • gene_density: 1.181345
INFO:__main__:   • operon_membership: 12.339737
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 174 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.227182
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.149805
INFO:__main__:   • gene_density: 1.191525
INFO:__main__:   • operon_membership: 10.885852
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 174 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.899372
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.870210
INFO:__main__:   • gene_density: 1.182706
INFO:__main__:   • operon_membership: 10.846456
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 174:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.8591, avg_loss=36.0512]Epoch 174: 100%|██████████| 11/11 [00:14<00:00,  1.47s/it, loss=35.8591, avg_loss=36.0512]Epoch 174: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.8591, avg_loss=36.0512]
INFO:__main__:=== EPOCH 174 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.051152
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.308903
INFO:__main__:   • gene_density: 1.173769
INFO:__main__:   • operon_membership: 12.568480
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 175/681
INFO:__main__:Epoch 175/681
INFO:__main__:Epoch 175/681
INFO:__main__:Epoch 175/681
Epoch 175:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 175:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 175:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 175:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 175:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.5940, avg_loss=39.5940]Epoch 175:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7942, avg_loss=36.7942]Epoch 175:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7733, avg_loss=36.7733]Epoch 175:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8235, avg_loss=35.8235]Epoch 175:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  27%|██▋       | 3/11 [00:04<00:10,  1.37s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:  27%|██▋       | 3/11 [00:04<00:10,  1.37s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:  27%|██▋       | 3/11 [00:04<00:10,  1.37s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:  27%|██▋       | 3/11 [00:04<00:10,  1.37s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  36%|███▋      | 4/11 [00:05<00:08,  1.28s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:  36%|███▋      | 4/11 [00:05<00:08,  1.28s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:  36%|███▋      | 4/11 [00:05<00:08,  1.29s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:  36%|███▋      | 4/11 [00:05<00:08,  1.28s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  45%|████▌     | 5/11 [00:06<00:06,  1.16s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:  45%|████▌     | 5/11 [00:06<00:06,  1.16s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  45%|████▌     | 5/11 [00:06<00:06,  1.17s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:  45%|████▌     | 5/11 [00:06<00:06,  1.17s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:  55%|█████▍    | 6/11 [00:07<00:05,  1.05s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  55%|█████▍    | 6/11 [00:07<00:05,  1.06s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:  55%|█████▍    | 6/11 [00:07<00:05,  1.06s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:  55%|█████▍    | 6/11 [00:07<00:05,  1.06s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:  64%|██████▎   | 7/11 [00:08<00:04,  1.17s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:  64%|██████▎   | 7/11 [00:08<00:04,  1.17s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:  64%|██████▎   | 7/11 [00:08<00:04,  1.17s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:  64%|██████▎   | 7/11 [00:08<00:04,  1.18s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:  73%|███████▎  | 8/11 [00:10<00:03,  1.25s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  82%|████████▏ | 9/11 [00:11<00:02,  1.30s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:  82%|████████▏ | 9/11 [00:11<00:02,  1.31s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  91%|█████████ | 10/11 [00:12<00:01,  1.34s/it, loss=39.5940, avg_loss=39.5940]Epoch 175:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=36.7942, avg_loss=36.7942]Epoch 175:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=36.7733, avg_loss=36.7733]Epoch 175:  91%|█████████ | 10/11 [00:12<00:01,  1.35s/it, loss=35.8235, avg_loss=35.8235]Epoch 175:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=37.1091, avg_loss=35.5498]Epoch 175: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=37.1091, avg_loss=35.5498]Epoch 175:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=35.4731, avg_loss=35.5802]Epoch 175: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=37.1091, avg_loss=35.5498]
Epoch 175: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=35.4731, avg_loss=35.5802]Epoch 175: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.4731, avg_loss=35.5802]
INFO:__main__:=== EPOCH 175 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.549755
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.778442
INFO:__main__:   • gene_density: 1.203717
INFO:__main__:   • operon_membership: 11.567596
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 175 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.580242
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.058478
INFO:__main__:   • gene_density: 1.181108
INFO:__main__:   • operon_membership: 11.340656
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 175:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=36.9359, avg_loss=36.4377]Epoch 175: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=36.9359, avg_loss=36.4377]Epoch 175: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.9359, avg_loss=36.4377]
INFO:__main__:=== EPOCH 175 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.437672
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.723226
INFO:__main__:   • gene_density: 1.170751
INFO:__main__:   • operon_membership: 12.543696
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 175:  91%|█████████ | 10/11 [00:14<00:01,  1.35s/it, loss=36.4859, avg_loss=35.7755]Epoch 175: 100%|██████████| 11/11 [00:14<00:00,  1.42s/it, loss=36.4859, avg_loss=35.7755]Epoch 175: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=36.4859, avg_loss=35.7755]
INFO:__main__:=== EPOCH 175 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.775501
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.405013
INFO:__main__:   • gene_density: 1.178859
INFO:__main__:   • operon_membership: 11.191629
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.24it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.49it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.60it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.60it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.61it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]
INFO:__main__:=== EPOCH 175 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]INFO:__main__:📊 Individual Validation Modality Losses:

INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]
INFO:__main__:=== EPOCH 175 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:=== EPOCH 175 VALIDATION LOSSES ===
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]
INFO:__main__:=== EPOCH 175 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 176/681
INFO:__main__:Epoch 176/681
INFO:__main__:Epoch 176/681
INFO:__main__:Epoch 176/681
Epoch 176:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 176:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 176:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 176:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 176:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.6970, avg_loss=32.6970]Epoch 176:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4004, avg_loss=34.4004]Epoch 176:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.3102, avg_loss=38.3102]Epoch 176:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8722, avg_loss=33.8722]Epoch 176:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:  27%|██▋       | 3/11 [00:04<00:11,  1.40s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  27%|██▋       | 3/11 [00:04<00:11,  1.41s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:  36%|███▋      | 4/11 [00:05<00:09,  1.32s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  45%|████▌     | 5/11 [00:06<00:07,  1.19s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:  45%|████▌     | 5/11 [00:06<00:07,  1.18s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  45%|████▌     | 5/11 [00:06<00:07,  1.19s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:  45%|████▌     | 5/11 [00:06<00:07,  1.19s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:  55%|█████▍    | 6/11 [00:07<00:05,  1.10s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:  55%|█████▍    | 6/11 [00:07<00:05,  1.10s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:  55%|█████▍    | 6/11 [00:07<00:05,  1.10s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:  55%|█████▍    | 6/11 [00:07<00:05,  1.11s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  64%|██████▎   | 7/11 [00:08<00:04,  1.21s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:  64%|██████▎   | 7/11 [00:08<00:04,  1.21s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:  64%|██████▎   | 7/11 [00:08<00:04,  1.21s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:  64%|██████▎   | 7/11 [00:08<00:04,  1.22s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:  73%|███████▎  | 8/11 [00:10<00:03,  1.28s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:  73%|███████▎  | 8/11 [00:10<00:03,  1.29s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=32.6970, avg_loss=32.6970]Epoch 176:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=34.4004, avg_loss=34.4004]Epoch 176:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=38.3102, avg_loss=38.3102]Epoch 176:  91%|█████████ | 10/11 [00:13<00:01,  1.38s/it, loss=33.8722, avg_loss=33.8722]Epoch 176:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=37.9946, avg_loss=35.4994]Epoch 176: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=37.9946, avg_loss=35.4994]Epoch 176:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.4310, avg_loss=36.4172]Epoch 176: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=35.4310, avg_loss=36.4172]Epoch 176: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=37.9946, avg_loss=35.4994]
Epoch 176: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.4310, avg_loss=36.4172]
Epoch 176:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.8437, avg_loss=35.8329]Epoch 176: 100%|██████████| 11/11 [00:14<00:00,  1.45s/it, loss=35.8437, avg_loss=35.8329]Epoch 176: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.8437, avg_loss=35.8329]
INFO:__main__:=== EPOCH 176 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.499436
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.726118
INFO:__main__:   • gene_density: 1.180753
INFO:__main__:   • operon_membership: 11.592565
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 176 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.417182
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.644203
INFO:__main__:   • gene_density: 1.172230
INFO:__main__:   • operon_membership: 11.600749
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 176 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.832861
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.404044
INFO:__main__:   • gene_density: 1.197562
INFO:__main__:   • operon_membership: 11.231255
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 176:  91%|█████████ | 10/11 [00:14<00:01,  1.38s/it, loss=35.7079, avg_loss=35.0640]Epoch 176: 100%|██████████| 11/11 [00:14<00:00,  1.44s/it, loss=35.7079, avg_loss=35.0640]Epoch 176: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.7079, avg_loss=35.0640]
INFO:__main__:=== EPOCH 176 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.064029
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.926013
INFO:__main__:   • gene_density: 1.183771
INFO:__main__:   • operon_membership: 11.954244
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 177/681
INFO:__main__:Epoch 177/681
INFO:__main__:Epoch 177/681
INFO:__main__:Epoch 177/681
Epoch 177:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 177:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 177:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 177:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 177:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.7027, avg_loss=39.7027]Epoch 177:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8214, avg_loss=33.8214]Epoch 177:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.2912, avg_loss=37.2912]Epoch 177:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2112, avg_loss=34.2112]Epoch 177:   9%|▉         | 1/11 [00:01<00:16,  1.66s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  45%|████▌     | 5/11 [00:07<00:08,  1.35s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:  45%|████▌     | 5/11 [00:07<00:08,  1.35s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:  45%|████▌     | 5/11 [00:07<00:08,  1.35s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:  45%|████▌     | 5/11 [00:07<00:08,  1.35s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  55%|█████▍    | 6/11 [00:08<00:06,  1.28s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:  55%|█████▍    | 6/11 [00:08<00:06,  1.28s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:  55%|█████▍    | 6/11 [00:08<00:06,  1.28s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  55%|█████▍    | 6/11 [00:08<00:06,  1.28s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:  64%|██████▎   | 7/11 [00:09<00:04,  1.17s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  64%|██████▎   | 7/11 [00:09<00:04,  1.17s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:  64%|██████▎   | 7/11 [00:09<00:04,  1.18s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:  73%|███████▎  | 8/11 [00:10<00:03,  1.07s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:  73%|███████▎  | 8/11 [00:10<00:03,  1.07s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  73%|███████▎  | 8/11 [00:10<00:03,  1.07s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:  73%|███████▎  | 8/11 [00:10<00:03,  1.07s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:  82%|████████▏ | 9/11 [00:11<00:02,  1.17s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:  82%|████████▏ | 9/11 [00:11<00:02,  1.17s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:  82%|████████▏ | 9/11 [00:11<00:02,  1.17s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:  82%|████████▏ | 9/11 [00:11<00:02,  1.18s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  91%|█████████ | 10/11 [00:12<00:01,  1.25s/it, loss=33.8214, avg_loss=33.8214]Epoch 177:  91%|█████████ | 10/11 [00:12<00:01,  1.25s/it, loss=37.2912, avg_loss=37.2912]Epoch 177:  91%|█████████ | 10/11 [00:12<00:01,  1.25s/it, loss=39.7027, avg_loss=39.7027]Epoch 177:  91%|█████████ | 10/11 [00:12<00:01,  1.26s/it, loss=34.2112, avg_loss=34.2112]Epoch 177:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=35.4883, avg_loss=35.2985]Epoch 177: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.4883, avg_loss=35.2985]Epoch 177: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=35.4883, avg_loss=35.2985]
Epoch 177:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=32.5326, avg_loss=35.5918]Epoch 177: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=32.5326, avg_loss=35.5918]INFO:__main__:=== EPOCH 177 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.298492
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.167733
INFO:__main__:   • gene_density: 1.200698
Epoch 177: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it, loss=32.5326, avg_loss=35.5918]INFO:__main__:   • operon_membership: 11.930061

INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 177 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.591794
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.314273
INFO:__main__:   • gene_density: 1.168383
INFO:__main__:   • operon_membership: 11.109139
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 177:  91%|█████████ | 10/11 [00:14<00:01,  1.25s/it, loss=38.0834, avg_loss=36.5803]Epoch 177: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=38.0834, avg_loss=36.5803]Epoch 177: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=38.0834, avg_loss=36.5803]
INFO:__main__:=== EPOCH 177 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.580255
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.383636
INFO:__main__:   • gene_density: 1.175189
INFO:__main__:   • operon_membership: 12.021429
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 177:  91%|█████████ | 10/11 [00:14<00:01,  1.26s/it, loss=38.1457, avg_loss=35.5513]Epoch 177: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=38.1457, avg_loss=35.5513]Epoch 177: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=38.1457, avg_loss=35.5513]
INFO:__main__:=== EPOCH 177 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.551265
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.973275
INFO:__main__:   • gene_density: 1.188506
INFO:__main__:   • operon_membership: 11.389484
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 178/681
INFO:__main__:Epoch 178/681
INFO:__main__:Epoch 178/681
INFO:__main__:Epoch 178/681
Epoch 178:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 178:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 178:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 178:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 178:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.6276, avg_loss=34.6276]Epoch 178:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5140, avg_loss=35.5140]Epoch 178:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1228, avg_loss=36.1228]Epoch 178:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.7592, avg_loss=34.7592]Epoch 178:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  64%|██████▎   | 7/11 [00:10<00:05,  1.38s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:  64%|██████▎   | 7/11 [00:10<00:05,  1.38s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:  64%|██████▎   | 7/11 [00:10<00:05,  1.38s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:  64%|██████▎   | 7/11 [00:10<00:05,  1.38s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  73%|███████▎  | 8/11 [00:11<00:03,  1.31s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:  73%|███████▎  | 8/11 [00:11<00:03,  1.31s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:  73%|███████▎  | 8/11 [00:11<00:03,  1.31s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:  73%|███████▎  | 8/11 [00:11<00:03,  1.31s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:  82%|████████▏ | 9/11 [00:12<00:02,  1.25s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  82%|████████▏ | 9/11 [00:12<00:02,  1.26s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:  91%|█████████ | 10/11 [00:13<00:01,  1.12s/it, loss=34.7592, avg_loss=34.7592]Epoch 178:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=34.6276, avg_loss=34.6276]Epoch 178:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=35.5140, avg_loss=35.5140]Epoch 178:  91%|█████████ | 10/11 [00:13<00:01,  1.13s/it, loss=36.1228, avg_loss=36.1228]Epoch 178:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=37.2993, avg_loss=36.3623]Epoch 178: 100%|██████████| 11/11 [00:14<00:00,  1.27s/it, loss=37.2993, avg_loss=36.3623]Epoch 178: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=37.2993, avg_loss=36.3623]
INFO:__main__:=== EPOCH 178 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.362289
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.102240
INFO:__main__:   • gene_density: 1.183179
INFO:__main__:   • operon_membership: 12.076870
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 178:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=36.1546, avg_loss=35.5779]Epoch 178: 100%|██████████| 11/11 [00:14<00:00,  1.27s/it, loss=36.1546, avg_loss=35.5779]Epoch 178: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=36.1546, avg_loss=35.5779]
Epoch 178:  91%|█████████ | 10/11 [00:14<00:01,  1.13s/it, loss=36.2110, avg_loss=36.2983]Epoch 178: 100%|██████████| 11/11 [00:14<00:00,  1.27s/it, loss=36.2110, avg_loss=36.2983]Epoch 178: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=36.2110, avg_loss=36.2983]
INFO:__main__:=== EPOCH 178 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.577880
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.017322
INFO:__main__:   • gene_density: 1.164832
INFO:__main__:   • operon_membership: 11.395726
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 178 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.298319
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.825914
INFO:__main__:   • gene_density: 1.183120
INFO:__main__:   • operon_membership: 11.289285
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 178:  91%|█████████ | 10/11 [00:14<00:01,  1.12s/it, loss=35.0100, avg_loss=34.7925]Epoch 178: 100%|██████████| 11/11 [00:14<00:00,  1.27s/it, loss=35.0100, avg_loss=34.7925]Epoch 178: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.0100, avg_loss=34.7925]
INFO:__main__:=== EPOCH 178 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.792492
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.711334
INFO:__main__:   • gene_density: 1.200758
INFO:__main__:   • operon_membership: 11.880401
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 179/681
INFO:__main__:Epoch 179/681
INFO:__main__:Epoch 179/681
INFO:__main__:Epoch 179/681
Epoch 179:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 179:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 179:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 179:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 179:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1893, avg_loss=34.1893]Epoch 179:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7382, avg_loss=36.7382]Epoch 179:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.5074, avg_loss=34.5074]Epoch 179:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6473, avg_loss=37.6473]Epoch 179:   9%|▉         | 1/11 [00:01<00:17,  1.74s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  82%|████████▏ | 9/11 [00:13<00:02,  1.40s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:  82%|████████▏ | 9/11 [00:13<00:02,  1.40s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:  82%|████████▏ | 9/11 [00:13<00:02,  1.40s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:  82%|████████▏ | 9/11 [00:13<00:02,  1.39s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=36.7382, avg_loss=36.7382]Epoch 179:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=34.1893, avg_loss=34.1893]Epoch 179:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=34.5074, avg_loss=34.5074]Epoch 179:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=37.6473, avg_loss=37.6473]Epoch 179:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=35.1908, avg_loss=35.3264]Epoch 179: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=35.1908, avg_loss=35.3264]Epoch 179: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=35.1908, avg_loss=35.3264]
INFO:__main__:=== EPOCH 179 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.326391
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.014849
INFO:__main__:   • gene_density: 1.182706
INFO:__main__:   • operon_membership: 11.128836
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 179:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=33.4531, avg_loss=35.7921]Epoch 179: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=33.4531, avg_loss=35.7921]Epoch 179: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=33.4531, avg_loss=35.7921]
Epoch 179:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=36.1150, avg_loss=35.6314]Epoch 179: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=36.1150, avg_loss=35.6314]INFO:__main__:=== EPOCH 179 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.792134
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.669597
INFO:__main__:   • gene_density: 1.182765
INFO:__main__:   • operon_membership: 11.939771
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 179: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=36.1150, avg_loss=35.6314]
Epoch 179:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=37.8160, avg_loss=36.2435]Epoch 179: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=37.8160, avg_loss=36.2435]Epoch 179: 100%|██████████| 11/11 [00:15<00:00,  1.40s/it, loss=37.8160, avg_loss=36.2435]
INFO:__main__:=== EPOCH 179 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.631417
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.026736
INFO:__main__:   • gene_density: 1.188980
INFO:__main__:   • operon_membership: 11.415701
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 179 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.243511
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.042517
INFO:__main__:   • gene_density: 1.177853
INFO:__main__:   • operon_membership: 12.023140
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 180/681
INFO:__main__:Epoch 180/681
INFO:__main__:Epoch 180/681
INFO:__main__:Epoch 180/681
Epoch 180:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 180:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 180:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 180:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 180:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9864, avg_loss=35.9864]Epoch 180:   9%|▉         | 1/11 [00:01<00:16,  1.64s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3531, avg_loss=34.3531]Epoch 180:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.0417, avg_loss=36.0417]Epoch 180:   9%|▉         | 1/11 [00:01<00:16,  1.65s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8836, avg_loss=36.8836]Epoch 180:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:  36%|███▋      | 4/11 [00:05<00:10,  1.48s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:  55%|█████▍    | 6/11 [00:08<00:07,  1.46s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:  82%|████████▏ | 9/11 [00:13<00:02,  1.43s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=35.9864, avg_loss=35.9864]Epoch 180:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=34.3531, avg_loss=34.3531]Epoch 180:  91%|█████████ | 10/11 [00:14<00:01,  1.43s/it, loss=36.0417, avg_loss=36.0417]Epoch 180:  91%|█████████ | 10/11 [00:14<00:01,  1.42s/it, loss=36.8836, avg_loss=36.8836]Epoch 180:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=39.5056, avg_loss=36.1141]Epoch 180: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=39.5056, avg_loss=36.1141]Epoch 180: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=39.5056, avg_loss=36.1141]
INFO:__main__:=== EPOCH 180 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.114051
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.858933
INFO:__main__:   • gene_density: 1.173532
INFO:__main__:   • operon_membership: 12.081586
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 180:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.5433, avg_loss=35.2827]Epoch 180: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.5433, avg_loss=35.2827]Epoch 180: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=35.5433, avg_loss=35.2827]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 180 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.282687
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.360462
INFO:__main__:   • gene_density: 1.187204
INFO:__main__:   • operon_membership: 10.735021
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 180:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=40.5586, avg_loss=35.5944]Epoch 180: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=40.5586, avg_loss=35.5944]Epoch 180:  91%|█████████ | 10/11 [00:15<00:01,  1.42s/it, loss=35.7055, avg_loss=36.0397]Epoch 180: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.7055, avg_loss=36.0397]Epoch 180: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=40.5586, avg_loss=35.5944]
Epoch 180: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it, loss=35.7055, avg_loss=36.0397]
INFO:__main__:=== EPOCH 180 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.594383
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.459543
INFO:__main__:   • gene_density: 1.186612
INFO:__main__:   • operon_membership: 10.948228
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 180 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.039686
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.036547
INFO:__main__:   • gene_density: 1.187559
INFO:__main__:   • operon_membership: 12.815580
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.41it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.42it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.43it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.40it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.79it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.79it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.80it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.80it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.19it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.19it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.18it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  2.20it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  2.08it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  2.09it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  2.08it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  2.09it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.99it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.99it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.98it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.99it/s]

INFO:__main__:=== EPOCH 180 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 180 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 180 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 180 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_180.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_180.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_180.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_180.pt
INFO:__main__:Epoch 181/681
INFO:__main__:Epoch 181/681
INFO:__main__:Epoch 181/681
INFO:__main__:Epoch 181/681
Epoch 181:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 181:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 181:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 181:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 181:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.1546, avg_loss=36.1546]Epoch 181:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.5427, avg_loss=36.5427]Epoch 181:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.0555, avg_loss=37.0555]Epoch 181:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.5807, avg_loss=37.5807]Epoch 181:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  45%|████▌     | 5/11 [00:07<00:08,  1.38s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:  45%|████▌     | 5/11 [00:07<00:08,  1.38s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:  45%|████▌     | 5/11 [00:07<00:08,  1.38s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:  45%|████▌     | 5/11 [00:07<00:08,  1.38s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:  55%|█████▍    | 6/11 [00:08<00:06,  1.31s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:  64%|██████▎   | 7/11 [00:09<00:04,  1.19s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:  73%|███████▎  | 8/11 [00:10<00:03,  1.11s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:  82%|████████▏ | 9/11 [00:11<00:02,  1.21s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  91%|█████████ | 10/11 [00:13<00:01,  1.28s/it, loss=36.1546, avg_loss=36.1546]Epoch 181:  91%|█████████ | 10/11 [00:13<00:01,  1.28s/it, loss=36.5427, avg_loss=36.5427]Epoch 181:  91%|█████████ | 10/11 [00:13<00:01,  1.28s/it, loss=37.0555, avg_loss=37.0555]Epoch 181:  91%|█████████ | 10/11 [00:13<00:01,  1.28s/it, loss=37.5807, avg_loss=37.5807]Epoch 181:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=32.4938, avg_loss=35.4651]Epoch 181: 100%|██████████| 11/11 [00:14<00:00,  1.38s/it, loss=32.4938, avg_loss=35.4651]Epoch 181: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=32.4938, avg_loss=35.4651]
INFO:__main__:=== EPOCH 181 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.465137
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.754169
INFO:__main__:   • gene_density: 1.179392
INFO:__main__:   • operon_membership: 11.531576
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 181:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=34.4559, avg_loss=35.9198]Epoch 181: 100%|██████████| 11/11 [00:14<00:00,  1.38s/it, loss=34.4559, avg_loss=35.9198]Epoch 181: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.4559, avg_loss=35.9198]
INFO:__main__:=== EPOCH 181 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.919802
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.730994
INFO:__main__:   • gene_density: 1.199751
INFO:__main__:   • operon_membership: 10.989057
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 181:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=35.7893, avg_loss=36.8300]Epoch 181: 100%|██████████| 11/11 [00:14<00:00,  1.38s/it, loss=35.7893, avg_loss=36.8300]Epoch 181: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=35.7893, avg_loss=36.8300]
INFO:__main__:=== EPOCH 181 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.829970
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.514490
INFO:__main__:   • gene_density: 1.171934
INFO:__main__:   • operon_membership: 12.143546
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 181:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=34.8318, avg_loss=34.9840]Epoch 181: 100%|██████████| 11/11 [00:14<00:00,  1.38s/it, loss=34.8318, avg_loss=34.9840]Epoch 181: 100%|██████████| 11/11 [00:14<00:00,  1.35s/it, loss=34.8318, avg_loss=34.9840]
INFO:__main__:=== EPOCH 181 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.983962
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.792423
INFO:__main__:   • gene_density: 1.179451
INFO:__main__:   • operon_membership: 12.012089
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 182/681
INFO:__main__:Epoch 182/681
INFO:__main__:Epoch 182/681
INFO:__main__:Epoch 182/681
Epoch 182:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 182:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 182:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 182:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 182:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.6718, avg_loss=37.6718]Epoch 182:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.8088, avg_loss=34.8088]Epoch 182:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.2591, avg_loss=31.2591]Epoch 182:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.8001, avg_loss=36.8001]Epoch 182:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:  64%|██████▎   | 7/11 [00:09<00:05,  1.36s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:  73%|███████▎  | 8/11 [00:11<00:03,  1.29s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  82%|████████▏ | 9/11 [00:12<00:02,  1.20s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:  82%|████████▏ | 9/11 [00:12<00:02,  1.20s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  82%|████████▏ | 9/11 [00:12<00:02,  1.20s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:  82%|████████▏ | 9/11 [00:12<00:02,  1.20s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:  91%|█████████ | 10/11 [00:12<00:01,  1.09s/it, loss=34.8088, avg_loss=34.8088]Epoch 182:  91%|█████████ | 10/11 [00:12<00:01,  1.09s/it, loss=37.6718, avg_loss=37.6718]Epoch 182:  91%|█████████ | 10/11 [00:12<00:01,  1.09s/it, loss=36.8001, avg_loss=36.8001]Epoch 182:  91%|█████████ | 10/11 [00:12<00:01,  1.09s/it, loss=31.2591, avg_loss=31.2591]Epoch 182:  91%|█████████ | 10/11 [00:14<00:01,  1.09s/it, loss=35.7820, avg_loss=36.9671]Epoch 182:  91%|█████████ | 10/11 [00:14<00:01,  1.09s/it, loss=35.8499, avg_loss=35.5868]Epoch 182: 100%|██████████| 11/11 [00:14<00:00,  1.24s/it, loss=35.7820, avg_loss=36.9671]Epoch 182: 100%|██████████| 11/11 [00:14<00:00,  1.24s/it, loss=35.8499, avg_loss=35.5868]Epoch 182: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.7820, avg_loss=36.9671]Epoch 182: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.8499, avg_loss=35.5868]

INFO:__main__:=== EPOCH 182 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 182 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.586815
INFO:__main__:🔢 Total Loss: 36.967129
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.431533
INFO:__main__:   • gene_expression: 24.437849
INFO:__main__:   • gene_density: 1.187027
INFO:__main__:   • gene_density: 1.170869
INFO:__main__:   • operon_membership: 11.968255
INFO:__main__:   • operon_membership: 11.358412
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 182:  91%|█████████ | 10/11 [00:14<00:01,  1.09s/it, loss=30.6259, avg_loss=35.1524]Epoch 182: 100%|██████████| 11/11 [00:14<00:00,  1.25s/it, loss=30.6259, avg_loss=35.1524]Epoch 182: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=30.6259, avg_loss=35.1524]
INFO:__main__:=== EPOCH 182 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.152377
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.775052
INFO:__main__:   • gene_density: 1.193419
INFO:__main__:   • operon_membership: 11.183907
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 182:  91%|█████████ | 10/11 [00:14<00:01,  1.09s/it, loss=34.4741, avg_loss=35.1838]Epoch 182: 100%|██████████| 11/11 [00:14<00:00,  1.25s/it, loss=34.4741, avg_loss=35.1838]Epoch 182: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=34.4741, avg_loss=35.1838]
INFO:__main__:=== EPOCH 182 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.183824
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.845661
INFO:__main__:   • gene_density: 1.182410
INFO:__main__:   • operon_membership: 12.155753
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 183/681
INFO:__main__:Epoch 183/681
INFO:__main__:Epoch 183/681
INFO:__main__:Epoch 183/681
Epoch 183:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 183:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 183:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 183:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 183:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0249, avg_loss=34.0249]Epoch 183:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2889, avg_loss=35.2889]Epoch 183:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.4071, avg_loss=38.4071]Epoch 183:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5380, avg_loss=35.5380]Epoch 183:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:  27%|██▋       | 3/11 [00:04<00:11,  1.45s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  36%|███▋      | 4/11 [00:05<00:10,  1.44s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:  36%|███▋      | 4/11 [00:05<00:10,  1.45s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:  64%|██████▎   | 7/11 [00:10<00:05,  1.45s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:  73%|███████▎  | 8/11 [00:11<00:04,  1.45s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:  82%|████████▏ | 9/11 [00:12<00:02,  1.40s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=34.0249, avg_loss=34.0249]Epoch 183:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=38.4071, avg_loss=38.4071]Epoch 183:  91%|█████████ | 10/11 [00:14<00:01,  1.34s/it, loss=35.2889, avg_loss=35.2889]Epoch 183:  91%|█████████ | 10/11 [00:14<00:01,  1.33s/it, loss=35.5380, avg_loss=35.5380]Epoch 183:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=32.9257, avg_loss=35.7059]Epoch 183: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=32.9257, avg_loss=35.7059]Epoch 183: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=32.9257, avg_loss=35.7059]
Epoch 183:  91%|█████████ | 10/11 [00:15<00:01,  1.33s/it, loss=32.3039, avg_loss=35.6322]Epoch 183: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=32.3039, avg_loss=35.6322]Epoch 183: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=32.3039, avg_loss=35.6322]
INFO:__main__:=== EPOCH 183 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.705882
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.614238
INFO:__main__:   • gene_density: 1.187204
INFO:__main__:   • operon_membership: 10.904440
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 183 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.632213
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.754594
INFO:__main__:   • gene_density: 1.185133
INFO:__main__:   • operon_membership: 11.692487
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 183:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=35.5306, avg_loss=35.8352]Epoch 183: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=35.5306, avg_loss=35.8352]Epoch 183: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.5306, avg_loss=35.8352]
Epoch 183:  91%|█████████ | 10/11 [00:15<00:01,  1.34s/it, loss=35.9081, avg_loss=35.8289]Epoch 183: 100%|██████████| 11/11 [00:15<00:00,  1.25s/it, loss=35.9081, avg_loss=35.8289]Epoch 183: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.9081, avg_loss=35.8289]
INFO:__main__:=== EPOCH 183 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.835167
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.075305
INFO:__main__:   • gene_density: 1.186671
INFO:__main__:   • operon_membership: 11.573191
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 183 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.828872
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.150629
INFO:__main__:   • gene_density: 1.170336
INFO:__main__:   • operon_membership: 12.507907
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 184/681
INFO:__main__:Epoch 184/681
INFO:__main__:Epoch 184/681
INFO:__main__:Epoch 184/681
Epoch 184:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 184:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 184:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 184:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 184:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.6764, avg_loss=36.6764]Epoch 184:   9%|▉         | 1/11 [00:01<00:16,  1.62s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.9921, avg_loss=38.9921]Epoch 184:   9%|▉         | 1/11 [00:01<00:16,  1.61s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.9729, avg_loss=38.9729]Epoch 184:   9%|▉         | 1/11 [00:01<00:16,  1.62s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7969, avg_loss=35.7969]Epoch 184:   9%|▉         | 1/11 [00:01<00:16,  1.63s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:  18%|█▊        | 2/11 [00:03<00:13,  1.54s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:  27%|██▋       | 3/11 [00:04<00:12,  1.50s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:  36%|███▋      | 4/11 [00:05<00:10,  1.47s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:  36%|███▋      | 4/11 [00:06<00:10,  1.48s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:  45%|████▌     | 5/11 [00:07<00:08,  1.48s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  55%|█████▍    | 6/11 [00:08<00:07,  1.48s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:  55%|█████▍    | 6/11 [00:08<00:07,  1.48s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:  55%|█████▍    | 6/11 [00:08<00:07,  1.48s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:  55%|█████▍    | 6/11 [00:08<00:07,  1.48s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:  64%|██████▎   | 7/11 [00:10<00:05,  1.48s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:  82%|████████▏ | 9/11 [00:13<00:02,  1.46s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:  82%|████████▏ | 9/11 [00:13<00:02,  1.45s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=38.9729, avg_loss=38.9729]Epoch 184:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=36.6764, avg_loss=36.6764]Epoch 184:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=38.9921, avg_loss=38.9921]Epoch 184:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.7969, avg_loss=35.7969]Epoch 184:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.8385, avg_loss=36.0593]Epoch 184: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=35.8385, avg_loss=36.0593]Epoch 184: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=35.8385, avg_loss=36.0593]
Epoch 184:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=37.8337, avg_loss=35.7935]Epoch 184: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.8337, avg_loss=35.7935]Epoch 184: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=37.8337, avg_loss=35.7935]
INFO:__main__:=== EPOCH 184 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.059294
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.924611
INFO:__main__:   • gene_density: 1.181641
INFO:__main__:   • operon_membership: 11.953042
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 184:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=37.5138, avg_loss=35.7361]Epoch 184: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=37.5138, avg_loss=35.7361]Epoch 184:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=38.9375, avg_loss=35.5077]Epoch 184: 100%|██████████| 11/11 [00:15<00:00,  1.38s/it, loss=38.9375, avg_loss=35.5077]Epoch 184: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=37.5138, avg_loss=35.7361]
Epoch 184: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=38.9375, avg_loss=35.5077]
INFO:__main__:=== EPOCH 184 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.793509
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.078507
INFO:__main__:   • gene_density: 1.179451
INFO:__main__:   • operon_membership: 11.535552
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 184 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.507699
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.057975
INFO:__main__:   • gene_density: 1.175189
INFO:__main__:   • operon_membership: 11.274535
INFO:__main__:=== EPOCH 184 TRAINING LOSSES ===
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 35.736116
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.819063
INFO:__main__:   • gene_density: 1.195668
INFO:__main__:   • operon_membership: 11.721386
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 185/681
INFO:__main__:Epoch 185/681
INFO:__main__:Epoch 185/681
INFO:__main__:Epoch 185/681
Epoch 185:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 185:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 185:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 185:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 185:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.8330, avg_loss=33.8330]Epoch 185:   9%|▉         | 1/11 [00:01<00:12,  1.25s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.2125, avg_loss=31.2125]Epoch 185:   9%|▉         | 1/11 [00:01<00:12,  1.25s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.2145, avg_loss=34.2145]Epoch 185:   9%|▉         | 1/11 [00:01<00:12,  1.25s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.0385, avg_loss=38.0385]Epoch 185:   9%|▉         | 1/11 [00:01<00:12,  1.25s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  18%|█▊        | 2/11 [00:02<00:09,  1.01s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:  18%|█▊        | 2/11 [00:02<00:09,  1.01s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  18%|█▊        | 2/11 [00:02<00:09,  1.01s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:  18%|█▊        | 2/11 [00:02<00:09,  1.02s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:  27%|██▋       | 3/11 [00:03<00:09,  1.21s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  27%|██▋       | 3/11 [00:03<00:09,  1.22s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:  36%|███▋      | 4/11 [00:04<00:09,  1.30s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:  36%|███▋      | 4/11 [00:04<00:09,  1.30s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:  36%|███▋      | 4/11 [00:04<00:09,  1.30s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  36%|███▋      | 4/11 [00:05<00:09,  1.31s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  45%|████▌     | 5/11 [00:06<00:08,  1.36s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  55%|█████▍    | 6/11 [00:07<00:06,  1.39s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:  64%|██████▎   | 7/11 [00:09<00:05,  1.41s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:  73%|███████▎  | 8/11 [00:10<00:04,  1.42s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:  82%|████████▏ | 9/11 [00:12<00:02,  1.42s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:  82%|████████▏ | 9/11 [00:12<00:02,  1.43s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=31.2125, avg_loss=31.2125]Epoch 185:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=33.8330, avg_loss=33.8330]Epoch 185:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=38.0385, avg_loss=38.0385]Epoch 185:  91%|█████████ | 10/11 [00:13<00:01,  1.43s/it, loss=34.2145, avg_loss=34.2145]Epoch 185:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=34.3531, avg_loss=35.5083]Epoch 185: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=34.3531, avg_loss=35.5083]Epoch 185: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=34.3531, avg_loss=35.5083]
INFO:__main__:=== EPOCH 185 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.508324
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.140663
INFO:__main__:   • gene_density: 1.191939
INFO:__main__:   • operon_membership: 11.175723
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 185:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=39.5501, avg_loss=35.4893]Epoch 185: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=39.5501, avg_loss=35.4893]Epoch 185: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=39.5501, avg_loss=35.4893]
INFO:__main__:=== EPOCH 185 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.489341
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.965233
INFO:__main__:   • gene_density: 1.191170
INFO:__main__:   • operon_membership: 12.332940
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 185:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.2597, avg_loss=35.5052]Epoch 185: 100%|██████████| 11/11 [00:15<00:00,  1.49s/it, loss=35.2597, avg_loss=35.5052]Epoch 185: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.2597, avg_loss=35.5052]
Validation:   0%|          | 0/4 [00:00<?, ?it/s]INFO:__main__:=== EPOCH 185 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.505217
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.283645
INFO:__main__:   • gene_density: 1.162879
INFO:__main__:   • operon_membership: 11.058692
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 185:  91%|█████████ | 10/11 [00:15<00:01,  1.43s/it, loss=35.5506, avg_loss=36.1602]Epoch 185: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.5506, avg_loss=36.1602]Epoch 185: 100%|██████████| 11/11 [00:15<00:00,  1.39s/it, loss=35.5506, avg_loss=36.1602]
INFO:__main__:=== EPOCH 185 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.160206
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.010174
INFO:__main__:   • gene_density: 1.189453
INFO:__main__:   • operon_membership: 11.960579
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.34it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.34it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.33it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.34it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.74it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.75it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.74it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.74it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.92it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.92it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.91it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.92it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.78it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.78it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.78it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]
INFO:__main__:=== EPOCH 185 VALIDATION LOSSES ===
INFO:__main__:=== EPOCH 185 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 185 VALIDATION LOSSES ===
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.78it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]
INFO:__main__:=== EPOCH 185 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:__main__:Epoch 186/681
INFO:__main__:Epoch 186/681
INFO:__main__:Epoch 186/681
INFO:__main__:Epoch 186/681
Epoch 186:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 186:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 186:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 186:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 186:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.3468, avg_loss=39.3468]Epoch 186:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.5388, avg_loss=33.5388]Epoch 186:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:   0%|          | 0/11 [00:01<?, ?it/s, loss=31.7533, avg_loss=31.7533]Epoch 186:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.1704, avg_loss=35.1704]Epoch 186:   9%|▉         | 1/11 [00:01<00:11,  1.17s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  18%|█▊        | 2/11 [00:02<00:09,  1.10s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:  18%|█▊        | 2/11 [00:02<00:10,  1.11s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:  27%|██▋       | 3/11 [00:03<00:10,  1.26s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  27%|██▋       | 3/11 [00:03<00:10,  1.26s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:  27%|██▋       | 3/11 [00:03<00:10,  1.26s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:  27%|██▋       | 3/11 [00:03<00:10,  1.27s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:  45%|████▌     | 5/11 [00:06<00:08,  1.40s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:  45%|████▌     | 5/11 [00:06<00:08,  1.40s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  45%|████▌     | 5/11 [00:06<00:08,  1.40s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:  45%|████▌     | 5/11 [00:06<00:08,  1.40s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:  55%|█████▍    | 6/11 [00:08<00:07,  1.43s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:  64%|██████▎   | 7/11 [00:09<00:05,  1.45s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:  64%|██████▎   | 7/11 [00:09<00:05,  1.45s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:  64%|██████▎   | 7/11 [00:09<00:05,  1.45s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  64%|██████▎   | 7/11 [00:09<00:05,  1.45s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:  73%|███████▎  | 8/11 [00:11<00:04,  1.46s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:  82%|████████▏ | 9/11 [00:12<00:02,  1.45s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:  91%|█████████ | 10/11 [00:13<00:01,  1.44s/it, loss=35.1704, avg_loss=35.1704]Epoch 186:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=39.3468, avg_loss=39.3468]Epoch 186:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=33.5388, avg_loss=33.5388]Epoch 186:  91%|█████████ | 10/11 [00:13<00:01,  1.45s/it, loss=31.7533, avg_loss=31.7533]Epoch 186:  91%|█████████ | 10/11 [00:15<00:01,  1.44s/it, loss=35.0421, avg_loss=35.7987]Epoch 186: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=35.0421, avg_loss=35.7987]Epoch 186:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=30.5872, avg_loss=35.3435]Epoch 186: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=30.5872, avg_loss=35.3435]Epoch 186: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=35.0421, avg_loss=35.7987]
Epoch 186: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=30.5872, avg_loss=35.3435]
Epoch 186:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=37.1158, avg_loss=35.7115]INFO:__main__:=== EPOCH 186 TRAINING LOSSES ===
Epoch 186: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=37.1158, avg_loss=35.7115]INFO:__main__:🔢 Total Loss: 35.798652
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.001027
INFO:__main__:   • gene_density: 1.198864
INFO:__main__:=== EPOCH 186 TRAINING LOSSES ===
INFO:__main__:   • operon_membership: 11.598761
INFO:__main__:👥 Samples processed: 22
INFO:__main__:🔢 Total Loss: 35.343477
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.507805
INFO:__main__:   • gene_density: 1.178326
INFO:__main__:   • operon_membership: 11.657345
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 186: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=37.1158, avg_loss=35.7115]
INFO:__main__:=== EPOCH 186 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.711473
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.184562
INFO:__main__:   • gene_density: 1.177557
INFO:__main__:   • operon_membership: 12.349354
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 186:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=33.8218, avg_loss=36.0127]Epoch 186: 100%|██████████| 11/11 [00:15<00:00,  1.46s/it, loss=33.8218, avg_loss=36.0127]Epoch 186: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=33.8218, avg_loss=36.0127]
INFO:__main__:=== EPOCH 186 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.012707
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.674222
INFO:__main__:   • gene_density: 1.177143
INFO:__main__:   • operon_membership: 11.161342
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 187/681
INFO:__main__:Epoch 187/681
INFO:__main__:Epoch 187/681
INFO:__main__:Epoch 187/681
Epoch 187:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 187:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 187:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 187:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 187:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1320, avg_loss=34.1320]Epoch 187:   9%|▉         | 1/11 [00:01<00:14,  1.44s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9612, avg_loss=33.9612]Epoch 187:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0908, avg_loss=34.0908]Epoch 187:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.4171, avg_loss=34.4171]Epoch 187:   9%|▉         | 1/11 [00:01<00:14,  1.45s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  18%|█▊        | 2/11 [00:02<00:11,  1.23s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:  18%|█▊        | 2/11 [00:02<00:11,  1.23s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  18%|█▊        | 2/11 [00:02<00:11,  1.23s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:  18%|█▊        | 2/11 [00:02<00:11,  1.23s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:  27%|██▋       | 3/11 [00:03<00:08,  1.05s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:  27%|██▋       | 3/11 [00:03<00:08,  1.05s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:  27%|██▋       | 3/11 [00:03<00:08,  1.05s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:  27%|██▋       | 3/11 [00:03<00:08,  1.05s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  36%|███▋      | 4/11 [00:04<00:08,  1.17s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:  36%|███▋      | 4/11 [00:04<00:08,  1.17s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:  36%|███▋      | 4/11 [00:04<00:08,  1.17s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:  36%|███▋      | 4/11 [00:04<00:08,  1.18s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  45%|████▌     | 5/11 [00:06<00:07,  1.27s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:  45%|████▌     | 5/11 [00:06<00:07,  1.28s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:  55%|█████▍    | 6/11 [00:07<00:06,  1.34s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:  55%|█████▍    | 6/11 [00:07<00:06,  1.33s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:  55%|█████▍    | 6/11 [00:07<00:06,  1.34s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:  64%|██████▎   | 7/11 [00:09<00:05,  1.37s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  73%|███████▎  | 8/11 [00:10<00:04,  1.39s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:  73%|███████▎  | 8/11 [00:10<00:04,  1.39s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:  73%|███████▎  | 8/11 [00:10<00:04,  1.40s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:  82%|████████▏ | 9/11 [00:11<00:02,  1.41s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=34.1320, avg_loss=34.1320]Epoch 187:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=33.9612, avg_loss=33.9612]Epoch 187:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=34.0908, avg_loss=34.0908]Epoch 187:  91%|█████████ | 10/11 [00:13<00:01,  1.41s/it, loss=34.4171, avg_loss=34.4171]Epoch 187:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=35.2308, avg_loss=36.9156]Epoch 187:  91%|█████████ | 10/11 [00:14<00:01,  1.41s/it, loss=39.7982, avg_loss=35.9924]Epoch 187: 100%|██████████| 11/11 [00:14<00:00,  1.48s/it, loss=35.2308, avg_loss=36.9156]Epoch 187: 100%|██████████| 11/11 [00:14<00:00,  1.48s/it, loss=39.7982, avg_loss=35.9924]Epoch 187: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.2308, avg_loss=36.9156]
Epoch 187: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=39.7982, avg_loss=35.9924]
INFO:__main__:=== EPOCH 187 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 187 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.915632
INFO:__main__:🔢 Total Loss: 35.992385
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.852550
INFO:__main__:   • gene_expression: 23.447653
INFO:__main__:   • gene_density: 1.182588
INFO:__main__:   • gene_density: 1.182528
INFO:__main__:   • operon_membership: 11.880494
INFO:__main__:   • operon_membership: 11.362203
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
Epoch 187:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=33.0830, avg_loss=35.0876]Epoch 187: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=33.0830, avg_loss=35.0876]Epoch 187: 100%|██████████| 11/11 [00:15<00:00,  1.36s/it, loss=33.0830, avg_loss=35.0876]
INFO:__main__:=== EPOCH 187 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.087641
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.815150
INFO:__main__:   • gene_density: 1.182351
INFO:__main__:   • operon_membership: 12.090140
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 187:  91%|█████████ | 10/11 [00:15<00:01,  1.41s/it, loss=35.3796, avg_loss=35.0235]Epoch 187: 100%|██████████| 11/11 [00:15<00:00,  1.48s/it, loss=35.3796, avg_loss=35.0235]Epoch 187: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=35.3796, avg_loss=35.0235]
INFO:__main__:=== EPOCH 187 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.023468
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.610998
INFO:__main__:   • gene_density: 1.183712
INFO:__main__:   • operon_membership: 11.228758
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 188/681
INFO:__main__:Epoch 188/681
INFO:__main__:Epoch 188/681
INFO:__main__:Epoch 188/681
Epoch 188:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 188:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 188:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 188:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 188:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5583, avg_loss=35.5583]Epoch 188:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.6010, avg_loss=33.6010]Epoch 188:   9%|▉         | 1/11 [00:01<00:16,  1.70s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5429, avg_loss=35.5429]Epoch 188:   9%|▉         | 1/11 [00:01<00:17,  1.70s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.2314, avg_loss=35.2314]Epoch 188:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:  18%|█▊        | 2/11 [00:02<00:12,  1.44s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:  18%|█▊        | 2/11 [00:02<00:13,  1.45s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:  27%|██▋       | 3/11 [00:04<00:10,  1.33s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  36%|███▋      | 4/11 [00:05<00:08,  1.17s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:  36%|███▋      | 4/11 [00:05<00:08,  1.17s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  36%|███▋      | 4/11 [00:05<00:08,  1.17s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:  36%|███▋      | 4/11 [00:05<00:08,  1.18s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:  45%|████▌     | 5/11 [00:06<00:06,  1.10s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:  45%|████▌     | 5/11 [00:06<00:06,  1.10s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:  45%|████▌     | 5/11 [00:06<00:06,  1.10s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:  45%|████▌     | 5/11 [00:06<00:06,  1.11s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:  55%|█████▍    | 6/11 [00:07<00:06,  1.21s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:  64%|██████▎   | 7/11 [00:08<00:05,  1.27s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:  64%|██████▎   | 7/11 [00:08<00:05,  1.28s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  73%|███████▎  | 8/11 [00:10<00:03,  1.31s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:  73%|███████▎  | 8/11 [00:10<00:03,  1.31s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:  73%|███████▎  | 8/11 [00:10<00:03,  1.31s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:  73%|███████▎  | 8/11 [00:10<00:03,  1.32s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  82%|████████▏ | 9/11 [00:11<00:02,  1.34s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:  82%|████████▏ | 9/11 [00:11<00:02,  1.35s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=35.5583, avg_loss=35.5583]Epoch 188:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=33.6010, avg_loss=33.6010]Epoch 188:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=35.5429, avg_loss=35.5429]Epoch 188:  91%|█████████ | 10/11 [00:13<00:01,  1.37s/it, loss=35.2314, avg_loss=35.2314]Epoch 188:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=37.8412, avg_loss=36.3562]Epoch 188: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=37.8412, avg_loss=36.3562]Epoch 188: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=37.8412, avg_loss=36.3562]
INFO:__main__:=== EPOCH 188 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.356199
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.942550
INFO:__main__:   • gene_density: 1.176610
INFO:__main__:   • operon_membership: 12.237040
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 188:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=32.8867, avg_loss=35.2907]Epoch 188: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=32.8867, avg_loss=35.2907]Epoch 188: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=32.8867, avg_loss=35.2907]
Epoch 188:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=39.7382, avg_loss=36.2429]Epoch 188: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=39.7382, avg_loss=36.2429]Epoch 188: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=39.7382, avg_loss=36.2429]
INFO:__main__:=== EPOCH 188 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.290687
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.568848
INFO:__main__:   • gene_density: 1.182588
INFO:__main__:   • operon_membership: 11.539251
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:=== EPOCH 188 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.242902
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.917063
INFO:__main__:   • gene_density: 1.186553
INFO:__main__:   • operon_membership: 11.139286
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 188:  91%|█████████ | 10/11 [00:14<00:01,  1.37s/it, loss=33.9554, avg_loss=35.0445]Epoch 188: 100%|██████████| 11/11 [00:14<00:00,  1.43s/it, loss=33.9554, avg_loss=35.0445]Epoch 188: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=33.9554, avg_loss=35.0445]
INFO:__main__:=== EPOCH 188 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.044494
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.463473
INFO:__main__:   • gene_density: 1.182706
INFO:__main__:   • operon_membership: 11.398316
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 189/681
INFO:__main__:Epoch 189/681
INFO:__main__:Epoch 189/681
INFO:__main__:Epoch 189/681
Epoch 189:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 189:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 189:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 189:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 189:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.5066, avg_loss=38.5066]Epoch 189:   9%|▉         | 1/11 [00:01<00:16,  1.67s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.4434, avg_loss=33.4434]Epoch 189:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:   0%|          | 0/11 [00:01<?, ?it/s, loss=39.2704, avg_loss=39.2704]Epoch 189:   9%|▉         | 1/11 [00:01<00:16,  1.68s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.8248, avg_loss=34.8248]Epoch 189:   9%|▉         | 1/11 [00:01<00:16,  1.69s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:  18%|█▊        | 2/11 [00:03<00:13,  1.51s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:  18%|█▊        | 2/11 [00:03<00:13,  1.52s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:  18%|█▊        | 2/11 [00:03<00:13,  1.53s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:  27%|██▋       | 3/11 [00:04<00:11,  1.48s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:  36%|███▋      | 4/11 [00:05<00:09,  1.39s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  55%|█████▍    | 6/11 [00:08<00:06,  1.23s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:  55%|█████▍    | 6/11 [00:08<00:06,  1.23s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  55%|█████▍    | 6/11 [00:08<00:06,  1.24s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:  55%|█████▍    | 6/11 [00:08<00:06,  1.24s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:  64%|██████▎   | 7/11 [00:08<00:04,  1.10s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:  64%|██████▎   | 7/11 [00:08<00:04,  1.11s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:  64%|██████▎   | 7/11 [00:08<00:04,  1.10s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  64%|██████▎   | 7/11 [00:08<00:04,  1.10s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:  73%|███████▎  | 8/11 [00:10<00:03,  1.14s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  82%|████████▏ | 9/11 [00:11<00:02,  1.23s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:  82%|████████▏ | 9/11 [00:11<00:02,  1.23s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:  82%|████████▏ | 9/11 [00:11<00:02,  1.23s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:  82%|████████▏ | 9/11 [00:11<00:02,  1.23s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  91%|█████████ | 10/11 [00:12<00:01,  1.30s/it, loss=38.5066, avg_loss=38.5066]Epoch 189:  91%|█████████ | 10/11 [00:12<00:01,  1.30s/it, loss=39.2704, avg_loss=39.2704]Epoch 189:  91%|█████████ | 10/11 [00:12<00:01,  1.30s/it, loss=33.4434, avg_loss=33.4434]Epoch 189:  91%|█████████ | 10/11 [00:12<00:01,  1.30s/it, loss=34.8248, avg_loss=34.8248]Epoch 189:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=33.4010, avg_loss=35.8849]Epoch 189: 100%|██████████| 11/11 [00:14<00:00,  1.39s/it, loss=33.4010, avg_loss=35.8849]Epoch 189: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=33.4010, avg_loss=35.8849]
INFO:__main__:=== EPOCH 189 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.884905
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.230200
INFO:__main__:   • gene_density: 1.173947
INFO:__main__:   • operon_membership: 11.480759
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 189:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=33.7938, avg_loss=35.8648]Epoch 189: 100%|██████████| 11/11 [00:14<00:00,  1.40s/it, loss=33.7938, avg_loss=35.8648]Epoch 189: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=33.7938, avg_loss=35.8648]
INFO:__main__:=== EPOCH 189 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.864768
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.680599
INFO:__main__:   • gene_density: 1.185310
INFO:__main__:   • operon_membership: 10.998859
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 189:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=35.1705, avg_loss=35.3339]Epoch 189: 100%|██████████| 11/11 [00:14<00:00,  1.40s/it, loss=35.1705, avg_loss=35.3339]Epoch 189: 100%|██████████| 11/11 [00:14<00:00,  1.32s/it, loss=35.1705, avg_loss=35.3339]
INFO:__main__:=== EPOCH 189 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.333915
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.924846
INFO:__main__:   • gene_density: 1.175959
INFO:__main__:   • operon_membership: 12.233110
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 189:  91%|█████████ | 10/11 [00:14<00:01,  1.30s/it, loss=38.2343, avg_loss=36.0617]Epoch 189: 100%|██████████| 11/11 [00:14<00:00,  1.40s/it, loss=38.2343, avg_loss=36.0617]Epoch 189: 100%|██████████| 11/11 [00:14<00:00,  1.33s/it, loss=38.2343, avg_loss=36.0617]
INFO:__main__:=== EPOCH 189 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.061665
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.948948
INFO:__main__:   • gene_density: 1.194306
INFO:__main__:   • operon_membership: 11.918409
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 190/681
INFO:__main__:Epoch 190/681
INFO:__main__:Epoch 190/681
INFO:__main__:Epoch 190/681
Epoch 190:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 190:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 190:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 190:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 190:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.4609, avg_loss=36.4609]Epoch 190:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.0801, avg_loss=34.0801]Epoch 190:   9%|▉         | 1/11 [00:01<00:17,  1.71s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3560, avg_loss=34.3560]Epoch 190:   9%|▉         | 1/11 [00:01<00:17,  1.72s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.8244, avg_loss=34.8244]Epoch 190:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:  18%|█▊        | 2/11 [00:03<00:14,  1.57s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:  27%|██▋       | 3/11 [00:04<00:12,  1.51s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:  27%|██▋       | 3/11 [00:04<00:12,  1.52s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:  36%|███▋      | 4/11 [00:06<00:10,  1.49s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:  45%|████▌     | 5/11 [00:07<00:08,  1.47s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:  55%|█████▍    | 6/11 [00:08<00:07,  1.42s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:  55%|█████▍    | 6/11 [00:08<00:07,  1.41s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  64%|██████▎   | 7/11 [00:10<00:05,  1.34s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:  64%|██████▎   | 7/11 [00:10<00:05,  1.34s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:  64%|██████▎   | 7/11 [00:10<00:05,  1.34s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:  64%|██████▎   | 7/11 [00:10<00:05,  1.34s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  73%|███████▎  | 8/11 [00:11<00:03,  1.23s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:  73%|███████▎  | 8/11 [00:11<00:03,  1.23s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:  73%|███████▎  | 8/11 [00:11<00:03,  1.23s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  73%|███████▎  | 8/11 [00:11<00:03,  1.23s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:  82%|████████▏ | 9/11 [00:11<00:02,  1.12s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=34.3560, avg_loss=34.3560]Epoch 190:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=36.4609, avg_loss=36.4609]Epoch 190:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=34.0801, avg_loss=34.0801]Epoch 190:  91%|█████████ | 10/11 [00:13<00:01,  1.22s/it, loss=34.8244, avg_loss=34.8244]Epoch 190:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=34.5553, avg_loss=35.4180]Epoch 190:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=35.8122, avg_loss=36.6219]Epoch 190: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=34.5553, avg_loss=35.4180]Epoch 190: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=35.8122, avg_loss=36.6219]Epoch 190: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=34.5553, avg_loss=35.4180]Epoch 190: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.8122, avg_loss=36.6219]

Epoch 190:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=32.9715, avg_loss=35.6394]Epoch 190: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=32.9715, avg_loss=35.6394]Epoch 190: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=32.9715, avg_loss=35.6394]
INFO:__main__:=== EPOCH 190 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 190 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.621851
INFO:__main__:🔢 Total Loss: 35.418004
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.538669
INFO:__main__:   • gene_expression: 22.855531
INFO:__main__:   • gene_density: 1.178090
INFO:__main__:   • gene_density: 1.188802
INFO:__main__:   • operon_membership: 11.905092
INFO:__main__:   • operon_membership: 11.373670
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:========================================
INFO:__main__:=== EPOCH 190 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.639416
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.302914
INFO:__main__:   • gene_density: 1.183061
INFO:__main__:   • operon_membership: 12.153441
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 190:  91%|█████████ | 10/11 [00:14<00:01,  1.22s/it, loss=35.3027, avg_loss=35.2550]Epoch 190: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=35.3027, avg_loss=35.2550]Epoch 190: 100%|██████████| 11/11 [00:14<00:00,  1.36s/it, loss=35.3027, avg_loss=35.2550]
INFO:__main__:=== EPOCH 190 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.255014
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.194819
INFO:__main__:   • gene_density: 1.178504
INFO:__main__:   • operon_membership: 10.881690
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Validation:   0%|          | 0/4 [00:00<?, ?it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]Validation:  25%|██▌       | 1/4 [00:00<00:02,  1.21it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.48it/s]Validation:  50%|█████     | 2/4 [00:01<00:01,  1.47it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.59it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.59it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.59it/s]Validation:  75%|███████▌  | 3/4 [00:01<00:00,  1.58it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]
INFO:__main__:=== EPOCH 190 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 37.380408
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:=== EPOCH 190 VALIDATION LOSSES ===
INFO:__main__:   • gene_expression: 23.996329
INFO:__main__:   • gene_density: 1.164714
INFO:__main__:   • operon_membership: 12.219366
INFO:__main__:🔢 Total Validation Loss: 37.703973
INFO:__main__:=== EPOCH 190 VALIDATION LOSSES ===
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:========================================
INFO:__main__:🔢 Total Validation Loss: 38.128592
INFO:__main__:   • gene_expression: 24.111331
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_density: 1.130534
INFO:__main__:   • gene_expression: 24.718487
INFO:__main__:   • operon_membership: 12.462108
INFO:__main__:   • gene_density: 1.157552
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:   • operon_membership: 12.252554
INFO:__main__:========================================
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]Validation: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]
INFO:__main__:=== EPOCH 190 VALIDATION LOSSES ===
INFO:__main__:🔢 Total Validation Loss: 38.320839
INFO:__main__:📊 Individual Validation Modality Losses:
INFO:__main__:   • gene_expression: 24.854753
INFO:__main__:   • gene_density: 1.162923
INFO:__main__:   • operon_membership: 12.303162
INFO:__main__:👥 Validation samples processed: 8
INFO:__main__:========================================
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_190.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_190.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_190.pt
INFO:bactagenome.training.trainer:Saved checkpoint: checkpoints/phase1_regulondb/checkpoint_regulondb_epoch_190.pt
INFO:__main__:Epoch 191/681
INFO:__main__:Epoch 191/681
INFO:__main__:Epoch 191/681
INFO:__main__:Epoch 191/681
Epoch 191:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 191:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 191:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 191:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 191:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7219, avg_loss=36.7219]Epoch 191:   9%|▉         | 1/11 [00:01<00:15,  1.50s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.4393, avg_loss=33.4393]Epoch 191:   9%|▉         | 1/11 [00:01<00:15,  1.51s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.7404, avg_loss=32.7404]Epoch 191:   9%|▉         | 1/11 [00:01<00:15,  1.51s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.7559, avg_loss=35.7559]Epoch 191:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  18%|█▊        | 2/11 [00:02<00:11,  1.24s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:  18%|█▊        | 2/11 [00:02<00:11,  1.25s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:  18%|█▊        | 2/11 [00:02<00:11,  1.24s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  18%|█▊        | 2/11 [00:02<00:11,  1.28s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:  27%|██▋       | 3/11 [00:03<00:08,  1.08s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:  27%|██▋       | 3/11 [00:03<00:08,  1.09s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:  27%|██▋       | 3/11 [00:03<00:08,  1.09s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:  27%|██▋       | 3/11 [00:03<00:08,  1.09s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  36%|███▋      | 4/11 [00:04<00:08,  1.22s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:  36%|███▋      | 4/11 [00:04<00:08,  1.22s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:  36%|███▋      | 4/11 [00:04<00:08,  1.23s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:  45%|████▌     | 5/11 [00:06<00:07,  1.30s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:  45%|████▌     | 5/11 [00:06<00:07,  1.31s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:  55%|█████▍    | 6/11 [00:07<00:06,  1.35s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:  64%|██████▎   | 7/11 [00:09<00:05,  1.38s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:  73%|███████▎  | 8/11 [00:10<00:03,  1.26s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:  73%|███████▎  | 8/11 [00:10<00:03,  1.27s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:  82%|████████▏ | 9/11 [00:11<00:02,  1.14s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:  82%|████████▏ | 9/11 [00:11<00:02,  1.13s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  91%|█████████ | 10/11 [00:12<00:01,  1.14s/it, loss=36.7219, avg_loss=36.7219]Epoch 191:  91%|█████████ | 10/11 [00:12<00:01,  1.15s/it, loss=33.4393, avg_loss=33.4393]Epoch 191:  91%|█████████ | 10/11 [00:12<00:01,  1.15s/it, loss=32.7404, avg_loss=32.7404]Epoch 191:  91%|█████████ | 10/11 [00:12<00:01,  1.15s/it, loss=35.7559, avg_loss=35.7559]Epoch 191:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=32.4420, avg_loss=34.8619]Epoch 191: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it, loss=32.4420, avg_loss=34.8619]Epoch 191: 100%|██████████| 11/11 [00:13<00:00,  1.24s/it, loss=32.4420, avg_loss=34.8619]
INFO:__main__:=== EPOCH 191 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.861890
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 21.842185
INFO:__main__:   • gene_density: 1.190814
INFO:__main__:   • operon_membership: 11.828891
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 191:  91%|█████████ | 10/11 [00:13<00:01,  1.14s/it, loss=33.1164, avg_loss=35.8383]Epoch 191: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it, loss=33.1164, avg_loss=35.8383]Epoch 191:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=37.5006, avg_loss=36.6534]Epoch 191: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it, loss=37.5006, avg_loss=36.6534]Epoch 191: 100%|██████████| 11/11 [00:13<00:00,  1.24s/it, loss=33.1164, avg_loss=35.8383]
Epoch 191: 100%|██████████| 11/11 [00:13<00:00,  1.24s/it, loss=37.5006, avg_loss=36.6534]
INFO:__main__:=== EPOCH 191 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.838345
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.061017
INFO:__main__:   • gene_density: 1.180694
INFO:__main__:   • operon_membership: 11.596634
INFO:__main__:=== EPOCH 191 TRAINING LOSSES ===
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:🔢 Total Loss: 36.653416
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.981936
INFO:__main__:   • gene_density: 1.166075
INFO:__main__:   • operon_membership: 11.505405
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 191:  91%|█████████ | 10/11 [00:13<00:01,  1.15s/it, loss=38.5232, avg_loss=35.5906]Epoch 191: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it, loss=38.5232, avg_loss=35.5906]Epoch 191: 100%|██████████| 11/11 [00:13<00:00,  1.24s/it, loss=38.5232, avg_loss=35.5906]
INFO:__main__:=== EPOCH 191 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.590570
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.818968
INFO:__main__:   • gene_density: 1.190874
INFO:__main__:   • operon_membership: 11.580728
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 192/681
INFO:__main__:Epoch 192/681
INFO:__main__:Epoch 192/681
INFO:__main__:Epoch 192/681
Epoch 192:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 192:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 192:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 192:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 192:   0%|          | 0/11 [00:01<?, ?it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:   9%|▉         | 1/11 [00:01<00:11,  1.13s/it, loss=36.7909, avg_loss=36.7909]Epoch 192:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:   9%|▉         | 1/11 [00:01<00:11,  1.13s/it, loss=35.8317, avg_loss=35.8317]Epoch 192:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:   9%|▉         | 1/11 [00:01<00:11,  1.13s/it, loss=34.1191, avg_loss=34.1191]Epoch 192:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:   9%|▉         | 1/11 [00:01<00:11,  1.13s/it, loss=37.7012, avg_loss=37.7012]Epoch 192:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:  18%|█▊        | 2/11 [00:01<00:08,  1.05it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:  18%|█▊        | 2/11 [00:01<00:08,  1.04it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:  27%|██▋       | 3/11 [00:02<00:07,  1.10it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:  36%|███▋      | 4/11 [00:03<00:06,  1.14it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:  36%|███▋      | 4/11 [00:03<00:06,  1.13it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:  45%|████▌     | 5/11 [00:04<00:05,  1.16it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:  55%|█████▍    | 6/11 [00:05<00:04,  1.17it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:  64%|██████▎   | 7/11 [00:06<00:03,  1.18it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:  73%|███████▎  | 8/11 [00:06<00:02,  1.18it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:  73%|███████▎  | 8/11 [00:06<00:02,  1.19it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:  73%|███████▎  | 8/11 [00:07<00:02,  1.18it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:  73%|███████▎  | 8/11 [00:07<00:02,  1.18it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:  82%|████████▏ | 9/11 [00:07<00:01,  1.18it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:  82%|████████▏ | 9/11 [00:07<00:01,  1.17it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, loss=36.7909, avg_loss=36.7909]Epoch 192:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, loss=37.7012, avg_loss=37.7012]Epoch 192:  91%|█████████ | 10/11 [00:08<00:00,  1.14it/s, loss=35.8317, avg_loss=35.8317]Epoch 192:  91%|█████████ | 10/11 [00:08<00:00,  1.13it/s, loss=34.1191, avg_loss=34.1191]Epoch 192:  91%|█████████ | 10/11 [00:10<00:00,  1.14it/s, loss=32.8473, avg_loss=34.6483]Epoch 192: 100%|██████████| 11/11 [00:10<00:00,  1.10s/it, loss=32.8473, avg_loss=34.6483]Epoch 192: 100%|██████████| 11/11 [00:10<00:00,  1.06it/s, loss=32.8473, avg_loss=34.6483]
Epoch 192:  91%|█████████ | 10/11 [00:10<00:00,  1.14it/s, loss=38.0326, avg_loss=36.1435]Epoch 192: 100%|██████████| 11/11 [00:10<00:00,  1.10s/it, loss=38.0326, avg_loss=36.1435]INFO:__main__:=== EPOCH 192 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 34.648267
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.276725
INFO:__main__:   • gene_density: 1.192768
INFO:__main__:   • operon_membership: 11.178774
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 192: 100%|██████████| 11/11 [00:10<00:00,  1.06it/s, loss=38.0326, avg_loss=36.1435]
INFO:__main__:=== EPOCH 192 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.143496
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.568670
INFO:__main__:   • gene_density: 1.173828
INFO:__main__:   • operon_membership: 11.400998
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 192:  91%|█████████ | 10/11 [00:10<00:00,  1.14it/s, loss=35.9125, avg_loss=36.2017]Epoch 192: 100%|██████████| 11/11 [00:10<00:00,  1.10s/it, loss=35.9125, avg_loss=36.2017]Epoch 192: 100%|██████████| 11/11 [00:10<00:00,  1.06it/s, loss=35.9125, avg_loss=36.2017]
INFO:__main__:=== EPOCH 192 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.201679
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.393290
INFO:__main__:   • gene_density: 1.178741
INFO:__main__:   • operon_membership: 11.629648
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 192:  91%|█████████ | 10/11 [00:10<00:00,  1.13it/s, loss=37.5386, avg_loss=36.3002]Epoch 192: 100%|██████████| 11/11 [00:10<00:00,  1.10s/it, loss=37.5386, avg_loss=36.3002]Epoch 192: 100%|██████████| 11/11 [00:10<00:00,  1.06it/s, loss=37.5386, avg_loss=36.3002]
INFO:__main__:=== EPOCH 192 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.300209
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.695519
INFO:__main__:   • gene_density: 1.186671
INFO:__main__:   • operon_membership: 12.418019
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 193/681
INFO:__main__:Epoch 193/681
INFO:__main__:Epoch 193/681
INFO:__main__:Epoch 193/681
Epoch 193:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 193:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 193:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 193:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 193:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.3408, avg_loss=32.3408]Epoch 193:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=32.3408, avg_loss=32.3408]Epoch 193:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.5787, avg_loss=35.5787]Epoch 193:   0%|          | 0/11 [00:01<?, ?it/s, loss=34.3580, avg_loss=34.3580]Epoch 193:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:   9%|▉         | 1/11 [00:01<00:17,  1.73s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.2483, avg_loss=38.2483]Epoch 193:   9%|▉         | 1/11 [00:01<00:17,  1.75s/it, loss=38.2483, avg_loss=38.2483]Epoch 193:  18%|█▊        | 2/11 [00:03<00:13,  1.55s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=32.3408, avg_loss=32.3408]Epoch 193:  18%|█▊        | 2/11 [00:03<00:14,  1.56s/it, loss=38.2483, avg_loss=38.2483]Epoch 193:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:  27%|██▋       | 3/11 [00:04<00:11,  1.49s/it, loss=32.3408, avg_loss=32.3408]Epoch 193:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:  27%|██▋       | 3/11 [00:04<00:11,  1.50s/it, loss=38.2483, avg_loss=38.2483]Epoch 193:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=32.3408, avg_loss=32.3408]Epoch 193:  36%|███▋      | 4/11 [00:06<00:10,  1.46s/it, loss=38.2483, avg_loss=38.2483][rank0]:[W717 21:35:53.985572169 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45686, remote=[::ffff:127.0.0.1]:29500): failed to recv, got 0 bytes
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:678 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7effff2ab5e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f003eec8bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baaf40 (0x7f003eecaf40 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5bab84a (0x7f003eecb84a in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x2a9 (0x7f003eec52a9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f00005c49f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f0058927bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f005bcaf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f005bbd4353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[W717 21:35:53.997350390 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: failed to recv, got 0 bytes
[rank1]:[W717 21:35:53.081231747 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): failed to recv, got 0 bytes
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:678 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baaf40 (0x7fcd4da17f40 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5bab84a (0x7fcd4da1884a in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x2a9 (0x7fcd4da122a9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:35:53.092892610 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: failed to recv, got 0 bytes
Epoch 193:  45%|████▌     | 5/11 [00:07<00:08,  1.44s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=32.3408, avg_loss=32.3408]Epoch 193:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=38.2483, avg_loss=38.2483][rank3]:[W717 21:35:54.484248596 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): failed to recv, got 0 bytes
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:678 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baaf40 (0x7f3a2f247f40 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5bab84a (0x7f3a2f24884a in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x2a9 (0x7f3a2f2422a9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:35:54.494626866 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: failed to recv, got 0 bytes
[rank2]:[W717 21:35:54.486372078 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45704, remote=[::ffff:127.0.0.1]:29500): failed to recv, got 0 bytes
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:678 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fea3efc15e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fea7ebdebfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baaf40 (0x7fea7ebe0f40 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5bab84a (0x7fea7ebe184a in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x2a9 (0x7fea7ebdb2a9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fea402da9f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fea9863dbf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fea9b9c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fea9b8ea353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W717 21:35:54.498018004 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: failed to recv, got 0 bytes
Epoch 193:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=32.3408, avg_loss=32.3408]Epoch 193:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:  55%|█████▍    | 6/11 [00:08<00:07,  1.44s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=38.2483, avg_loss=38.2483][rank1]:[W717 21:35:56.093187005 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:35:56.096929406 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 193:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=32.3408, avg_loss=32.3408]Epoch 193:  64%|██████▎   | 7/11 [00:10<00:05,  1.44s/it, loss=38.2483, avg_loss=38.2483][rank0]:[W717 21:35:57.997737404 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45686, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7effff2ab5e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f003eec8bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f003eeca458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f003eecbc3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f003eec5298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f00005c49f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f0058927bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f005bcaf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f005bbd4353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[W717 21:35:57.009079862 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:35:57.495052999 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:35:57.498652379 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank2]:[W717 21:35:57.498521222 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45704, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fea3efc15e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fea7ebdebfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fea7ebe0458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fea7ebe1c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fea7ebdb298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fea402da9f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fea9863dbf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fea9b9c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fea9b8ea353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W717 21:35:57.506468086 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 193:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:  73%|███████▎  | 8/11 [00:11<00:04,  1.44s/it, loss=32.3408, avg_loss=32.3408]Epoch 193:  73%|███████▎  | 8/11 [00:11<00:04,  1.43s/it, loss=38.2483, avg_loss=38.2483]Epoch 193:  82%|████████▏ | 9/11 [00:12<00:02,  1.36s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:  82%|████████▏ | 9/11 [00:12<00:02,  1.36s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:  82%|████████▏ | 9/11 [00:12<00:02,  1.36s/it, loss=32.3408, avg_loss=32.3408]Epoch 193:  82%|████████▏ | 9/11 [00:12<00:02,  1.35s/it, loss=38.2483, avg_loss=38.2483][rank3]:[W717 21:35:59.499063790 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:00.510103480 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 193:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=34.3580, avg_loss=34.3580]Epoch 193:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=35.5787, avg_loss=35.5787]Epoch 193:  91%|█████████ | 10/11 [00:14<00:01,  1.28s/it, loss=38.2483, avg_loss=38.2483]Epoch 193:  91%|█████████ | 10/11 [00:14<00:01,  1.29s/it, loss=32.3408, avg_loss=32.3408][rank0]:[W717 21:36:01.009526033 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45686, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7effff2ab5e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f003eec8bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f003eeca458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f003eecbc3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f003eec5298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f00005c49f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f0058927bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f005bcaf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f005bbd4353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[W717 21:36:01.014076511 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W717 21:36:01.097610504 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:36:01.102270615 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 193:  91%|█████████ | 10/11 [00:15<00:01,  1.28s/it, loss=42.4430, avg_loss=36.4192]Epoch 193: 100%|██████████| 11/11 [00:15<00:00,  1.22s/it, loss=42.4430, avg_loss=36.4192]Epoch 193: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=42.4430, avg_loss=36.4192]
INFO:__main__:=== EPOCH 193 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 36.419153
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.288626
INFO:__main__:   • gene_density: 1.181877
INFO:__main__:   • operon_membership: 11.948650
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 193:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=32.6828, avg_loss=35.4085]Epoch 193:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=31.9209, avg_loss=35.3466]Epoch 193: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=32.6828, avg_loss=35.4085]Epoch 193: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=31.9209, avg_loss=35.3466]Epoch 193:  91%|█████████ | 10/11 [00:15<00:01,  1.29s/it, loss=34.5163, avg_loss=35.8567]Epoch 193: 100%|██████████| 11/11 [00:15<00:00,  1.23s/it, loss=34.5163, avg_loss=35.8567]Epoch 193: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=31.9209, avg_loss=35.3466]Epoch 193: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=32.6828, avg_loss=35.4085]

Epoch 193: 100%|██████████| 11/11 [00:15<00:00,  1.37s/it, loss=34.5163, avg_loss=35.8567]
INFO:__main__:=== EPOCH 193 TRAINING LOSSES ===
INFO:__main__:=== EPOCH 193 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.408531
INFO:__main__:🔢 Total Loss: 35.346554
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.799121
INFO:__main__:   • gene_expression: 23.017234
INFO:__main__:=== EPOCH 193 TRAINING LOSSES ===
INFO:__main__:   • gene_density: 1.189039
INFO:__main__:   • gene_density: 1.188092
INFO:__main__:   • operon_membership: 11.420372
INFO:__main__:   • operon_membership: 11.141228
INFO:__main__:🔢 Total Loss: 35.856741
INFO:__main__:👥 Samples processed: 22
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:========================================
INFO:__main__:   • gene_expression: 22.551828
INFO:__main__:   • gene_density: 1.172881
INFO:__main__:   • operon_membership: 12.132032
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 194/681
INFO:__main__:Epoch 194/681
INFO:__main__:Epoch 194/681
INFO:__main__:Epoch 194/681
Epoch 194:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 194:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 194:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 194:   0%|          | 0/11 [00:00<?, ?it/s][rank0]:[W717 21:36:02.014384829 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45686, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7effff2ab5e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f003eec8bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f003eeca458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f003eecbc3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f003eec5298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f00005c49f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f0058927bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f005bcaf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f005bbd4353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[W717 21:36:02.025835042 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:03.510650038 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:03.521987488 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.9774, avg_loss=35.9774]Epoch 194:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.0862, avg_loss=37.0862]Epoch 194:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:   0%|          | 0/11 [00:01<?, ?it/s, loss=32.4544, avg_loss=32.4544]Epoch 194:   9%|▉         | 1/11 [00:01<00:15,  1.52s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:   0%|          | 0/11 [00:01<?, ?it/s, loss=35.4691, avg_loss=35.4691]Epoch 194:   9%|▉         | 1/11 [00:01<00:15,  1.54s/it, loss=35.4691, avg_loss=35.4691][rank0]:[W717 21:36:04.026143447 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45686, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7effff2ab5e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f003eec8bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f003eeca458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f003eecbc3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f003eec5298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f00005c49f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f0058927bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f005bcaf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f005bbd4353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[W717 21:36:04.034900120 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  18%|█▊        | 2/11 [00:02<00:13,  1.48s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:  18%|█▊        | 2/11 [00:02<00:13,  1.48s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:  18%|█▊        | 2/11 [00:02<00:13,  1.48s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:  18%|█▊        | 2/11 [00:02<00:13,  1.49s/it, loss=35.4691, avg_loss=35.4691][rank0]:[W717 21:36:05.035146638 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45686, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7effff2ab5e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f003eec8bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f003eeca458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f003eecbc3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f003eec5298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f00005c49f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f0058927bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f005bcaf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f005bbd4353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[W717 21:36:05.046126699 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W717 21:36:05.102870279 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:36:05.106522289 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:  27%|██▋       | 3/11 [00:04<00:11,  1.46s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:  27%|██▋       | 3/11 [00:04<00:11,  1.47s/it, loss=35.4691, avg_loss=35.4691][rank2]:[W717 21:36:07.507677761 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45704, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fea3efc15e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fea7ebdebfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fea7ebe0458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fea7ebe1c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fea7ebdb298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fea402da9f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fea9863dbf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fea9b9c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fea9b8ea353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W717 21:36:07.518281471 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:07.522425687 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:07.526700159 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:  36%|███▋      | 4/11 [00:05<00:10,  1.46s/it, loss=35.4691, avg_loss=35.4691][rank1]:[W717 21:36:08.106993363 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:36:08.117687565 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:  45%|████▌     | 5/11 [00:07<00:08,  1.46s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:  45%|████▌     | 5/11 [00:07<00:08,  1.45s/it, loss=35.4691, avg_loss=35.4691][rank2]:[W717 21:36:10.518712646 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45704, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fea3efc15e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fea7ebdebfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fea7ebe0458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fea7ebe1c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fea7ebdb298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fea402da9f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fea9863dbf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fea9b9c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fea9b8ea353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W717 21:36:10.529594063 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:10.527139708 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:10.536903624 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:  55%|█████▍    | 6/11 [00:08<00:07,  1.45s/it, loss=35.4691, avg_loss=35.4691][rank1]:[W717 21:36:11.118214932 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:36:11.128583132 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:  64%|██████▎   | 7/11 [00:10<00:05,  1.46s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:  64%|██████▎   | 7/11 [00:10<00:05,  1.47s/it, loss=35.4691, avg_loss=35.4691][rank1]:[W717 21:36:12.128824577 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:36:12.141206338 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank2]:[W717 21:36:13.530021935 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45704, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fea3efc15e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fea7ebdebfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fea7ebe0458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fea7ebe1c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fea7ebdb298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fea402da9f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fea9863dbf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fea9b9c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fea9b8ea353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W717 21:36:13.541309936 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:13.537291907 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:13.549297060 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:  73%|███████▎  | 8/11 [00:11<00:04,  1.47s/it, loss=35.4691, avg_loss=35.4691][rank0]:[W717 21:36:14.047172105 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45686, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7effff2ab5e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f003eec8bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f003eeca458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f003eecbc3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f003eec5298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f00005c49f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f0058927bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f005bcaf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f005bbd4353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[W717 21:36:14.057787469 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W717 21:36:14.141544229 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:36:14.153082368 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  82%|████████▏ | 9/11 [00:13<00:02,  1.47s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:  82%|████████▏ | 9/11 [00:13<00:02,  1.47s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:  82%|████████▏ | 9/11 [00:13<00:02,  1.47s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:  82%|████████▏ | 9/11 [00:13<00:02,  1.47s/it, loss=35.4691, avg_loss=35.4691][rank2]:[W717 21:36:16.541692229 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45704, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fea3efc15e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fea7ebdebfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fea7ebe0458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fea7ebe1c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fea7ebdb298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fea402da9f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fea9863dbf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fea9b9c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fea9b8ea353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W717 21:36:16.552860319 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:16.549706477 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:16.566216326 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=32.4544, avg_loss=32.4544]Epoch 194:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=35.9774, avg_loss=35.9774]Epoch 194:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=37.0862, avg_loss=37.0862]Epoch 194:  91%|█████████ | 10/11 [00:14<00:01,  1.45s/it, loss=35.4691, avg_loss=35.4691][rank2]:[W717 21:36:17.553095884 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45704, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fea3efc15e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fea7ebdebfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fea7ebe0458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fea7ebe1c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fea7ebdb298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fea402da9f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fea9863dbf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fea9b9c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fea9b8ea353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W717 21:36:17.564865792 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:17.566346302 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:17.570588356 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 194:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=33.8525, avg_loss=35.7249]Epoch 194: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=33.8525, avg_loss=35.7249]Epoch 194:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=35.8041, avg_loss=36.0993]Epoch 194: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=35.8041, avg_loss=36.0993]Epoch 194: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=33.8525, avg_loss=35.7249]
Epoch 194: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=35.8041, avg_loss=36.0993]
INFO:__main__:=== EPOCH 194 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.724873
INFO:__main__:=== EPOCH 194 TRAINING LOSSES ===
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.825258
INFO:__main__:🔢 Total Loss: 36.099260
INFO:__main__:   • gene_density: 1.181049
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • operon_membership: 11.718565
INFO:__main__:   • gene_expression: 22.796680
INFO:__main__:👥 Samples processed: 22
INFO:__main__:   • gene_density: 1.179332
INFO:__main__:========================================
INFO:__main__:   • operon_membership: 12.123247
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 194:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=36.2329, avg_loss=35.4976]Epoch 194: 100%|██████████| 11/11 [00:15<00:00,  1.42s/it, loss=36.2329, avg_loss=35.4976]Epoch 194: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=36.2329, avg_loss=35.4976]
INFO:__main__:=== EPOCH 194 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.497575
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 22.685978
INFO:__main__:   • gene_density: 1.179037
INFO:__main__:   • operon_membership: 11.632561
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
Epoch 194:  91%|█████████ | 10/11 [00:15<00:01,  1.45s/it, loss=36.6158, avg_loss=35.8400]Epoch 194: 100%|██████████| 11/11 [00:15<00:00,  1.41s/it, loss=36.6158, avg_loss=35.8400]Epoch 194: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it, loss=36.6158, avg_loss=35.8400]
INFO:__main__:=== EPOCH 194 TRAINING LOSSES ===
INFO:__main__:🔢 Total Loss: 35.840018
INFO:__main__:📊 Individual Modality Losses:
INFO:__main__:   • gene_expression: 23.613679
INFO:__main__:   • gene_density: 1.189749
INFO:__main__:   • operon_membership: 11.036590
INFO:__main__:👥 Samples processed: 22
INFO:__main__:========================================
INFO:__main__:Epoch 195/681
INFO:__main__:Epoch 195/681
INFO:__main__:Epoch 195/681
INFO:__main__:Epoch 195/681
Epoch 195:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 195:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 195:   0%|          | 0/11 [00:00<?, ?it/s]Epoch 195:   0%|          | 0/11 [00:00<?, ?it/s][rank1]:[W717 21:36:18.154793843 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:36:18.165706712 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 195:   0%|          | 0/11 [00:01<?, ?it/s, loss=37.4047, avg_loss=37.4047]Epoch 195:   9%|▉         | 1/11 [00:01<00:11,  1.15s/it, loss=37.4047, avg_loss=37.4047]Epoch 195:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.9703, avg_loss=33.9703]Epoch 195:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=33.9703, avg_loss=33.9703]Epoch 195:   0%|          | 0/11 [00:01<?, ?it/s, loss=33.0270, avg_loss=33.0270]Epoch 195:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=33.0270, avg_loss=33.0270]Epoch 195:   0%|          | 0/11 [00:01<?, ?it/s, loss=38.1882, avg_loss=38.1882]Epoch 195:   9%|▉         | 1/11 [00:01<00:11,  1.16s/it, loss=38.1882, avg_loss=38.1882][rank1]:[W717 21:36:19.165925941 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:36:19.177706223 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 195:  18%|█▊        | 2/11 [00:02<00:10,  1.15s/it, loss=37.4047, avg_loss=37.4047]Epoch 195:  18%|█▊        | 2/11 [00:02<00:10,  1.15s/it, loss=33.9703, avg_loss=33.9703]Epoch 195:  18%|█▊        | 2/11 [00:02<00:10,  1.16s/it, loss=38.1882, avg_loss=38.1882]Epoch 195:  18%|█▊        | 2/11 [00:02<00:10,  1.17s/it, loss=33.0270, avg_loss=33.0270][rank2]:[W717 21:36:21.565489693 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45704, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fea3efc15e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fea7ebdebfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fea7ebe0458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fea7ebe1c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fea7ebdb298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fea402da9f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fea9863dbf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fea9b9c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fea9b8ea353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W717 21:36:21.577309029 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:21.571057725 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:21.580275382 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 195:  27%|██▋       | 3/11 [00:03<00:10,  1.28s/it, loss=37.4047, avg_loss=37.4047]Epoch 195:  27%|██▋       | 3/11 [00:03<00:10,  1.28s/it, loss=38.1882, avg_loss=38.1882]Epoch 195:  27%|██▋       | 3/11 [00:03<00:10,  1.28s/it, loss=33.9703, avg_loss=33.9703]Epoch 195:  27%|██▋       | 3/11 [00:03<00:10,  1.29s/it, loss=33.0270, avg_loss=33.0270][rank3]:[W717 21:36:22.580508302 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:22.591668893 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank0]:[W717 21:36:22.058858277 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45686, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7effff2ab5e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f003eec8bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f003eeca458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f003eecbc3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f003eec5298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f00005c49f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f0058927bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f005bcaf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f005bbd4353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[W717 21:36:22.069874346 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 195:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=37.4047, avg_loss=37.4047]Epoch 195:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=33.9703, avg_loss=33.9703]Epoch 195:  36%|███▋      | 4/11 [00:05<00:09,  1.34s/it, loss=38.1882, avg_loss=38.1882]Epoch 195:  36%|███▋      | 4/11 [00:05<00:09,  1.35s/it, loss=33.0270, avg_loss=33.0270][rank2]:[W717 21:36:24.577784764 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45704, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fea3efc15e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fea7ebdebfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fea7ebe0458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fea7ebe1c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fea7ebdb298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fea402da9f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fea9863dbf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fea9b9c5609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fea9b8ea353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W717 21:36:24.588948105 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:24.591988939 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:24.602395965 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 195:  45%|████▌     | 5/11 [00:06<00:08,  1.38s/it, loss=33.9703, avg_loss=33.9703]Epoch 195:  45%|████▌     | 5/11 [00:06<00:08,  1.38s/it, loss=37.4047, avg_loss=37.4047]Epoch 195:  45%|████▌     | 5/11 [00:06<00:08,  1.38s/it, loss=38.1882, avg_loss=38.1882]Epoch 195:  45%|████▌     | 5/11 [00:06<00:08,  1.38s/it, loss=33.0270, avg_loss=33.0270]Epoch 195:  55%|█████▍    | 6/11 [00:08<00:06,  1.40s/it, loss=37.4047, avg_loss=37.4047]Epoch 195:  55%|█████▍    | 6/11 [00:08<00:06,  1.40s/it, loss=33.9703, avg_loss=33.9703]Epoch 195:  55%|█████▍    | 6/11 [00:08<00:06,  1.40s/it, loss=38.1882, avg_loss=38.1882]Epoch 195:  55%|█████▍    | 6/11 [00:08<00:07,  1.40s/it, loss=33.0270, avg_loss=33.0270][rank0]:[W717 21:36:26.070418927 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45686, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7effff2ab5e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f003eec8bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f003eeca458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f003eecbc3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f003eec5298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f00005c49f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f0058927bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f005bcaf609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f005bbd4353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[W717 21:36:26.081197241 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 0] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W717 21:36:26.178357474 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45674, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fcd0ddf85e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7fcd4da15bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7fcd4da17458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7fcd4da18c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7fcd4da12298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7fcd0f1119f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7fcd67474bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7fcd6a7fc609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7fcd6a721353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W717 21:36:26.186857527 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
Epoch 195:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=37.4047, avg_loss=37.4047]Epoch 195:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=33.9703, avg_loss=33.9703]Epoch 195:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=38.1882, avg_loss=38.1882]Epoch 195:  64%|██████▎   | 7/11 [00:09<00:05,  1.40s/it, loss=33.0270, avg_loss=33.0270][rank3]:[W717 21:36:28.602947363 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:28.613282144 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:29.613632125 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:29.627457018 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:30.627704743 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:30.637804535 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:31.638123724 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:31.651895338 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:32.652133665 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:32.660310581 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:33.660522123 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:33.670739585 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:34.671015339 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:34.681721947 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:35.681971269 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:35.693245360 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:36.693497788 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:36.705624066 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:37.705880172 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:37.717895023 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:38.718140127 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:38.729479539 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:39.729745391 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:39.741920509 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:40.742096301 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:40.749523763 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:41.749789577 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:41.761836171 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:42.762116103 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:42.773976143 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:43.774235538 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:43.786048025 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:44.786369965 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:44.800156692 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:45.800477112 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:45.813593856 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:46.813867137 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:46.825827392 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:47.826163349 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:47.837675154 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:48.837940028 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:48.849980280 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:49.850253700 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:49.862030004 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:50.862308046 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:50.874056107 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:51.874314165 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:51.884754772 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:52.885014142 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:52.896895988 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:53.897115590 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:53.906076264 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:54.906346336 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:54.917415641 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:55.917782822 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:55.929149605 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:56.929472406 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:56.938874780 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:57.939092933 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:57.950212018 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:58.950451464 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:58.961339777 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:36:59.961603622 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:36:59.973871650 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:00.974082475 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:00.982303404 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:01.982606492 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:01.993588373 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:02.993823322 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:02.005347420 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:03.005558589 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:03.017693100 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:04.017910713 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:04.028101074 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:05.028345941 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:05.041359734 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:06.041631609 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:06.046806842 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:07.047066909 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:07.058320393 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:08.058582535 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:08.069760835 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:09.069992675 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:09.081912401 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:10.082140813 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:10.090975957 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank3]:[W717 21:37:11.091190036 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=11, addr=[::ffff:127.0.0.1]:45698, remote=[::ffff:127.0.0.1]:29500): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7f39ef6285e8 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5ba8bfe (0x7f3a2f245bfe in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5baa458 (0x7f3a2f247458 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5babc3e (0x7f3a2f248c3e in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x298 (0x7f3a2f242298 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::heartbeatMonitor() + 0x379 (0x7f39f09419f9 in /home/yunuo/projectnvme/miniconda3/envs/bacta/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7f3a48ca4bf4 in /nvme-data2/yunuo/miniconda3/envs/bacta/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x8609 (0x7f3a4c02c609 in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #8: clone + 0x43 (0x7f3a4bf51353 in /lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[W717 21:37:11.101008336 ProcessGroupNCCL.cpp:1662] [PG ID 0 PG GUID 0(default_pg) Rank 3] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
